% This file was created with JabRef 2.4.2.
% Encoding: Cp1252

@INPROCEEDINGS{Aganj2007,
  author = {Aganj, E. and Pons, J.-P. and Segonne, F. and Keriven, R.},
  title = {Spatio-Temporal Shape from Silhouette using Four-Dimensional Delaunay
	Meshing},
  booktitle = {Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference
	on},
  year = {2007},
  pages = {1-8},
  month = {Oct.},
  note = {3D Reconstruction},
  abstract = {We propose a novel method for computing a four-dimensional (4D) representation
	of the spatio-temporal visual hull of a dynamic scene, based on an
	extension of a recent provably correct Delaunay meshing algorithm.
	By considering time as an additional dimension, our approach exploits
	seamlessly the time coherence between different frames to produce
	a compact and high-quality 4D mesh representation of the visual hull.
	The 3D visual hull at a given time instant is easily obtained by
	intersecting this 4D mesh with a temporal plane, thus enabling interpolation
	of objects' shape between consecutive frames. In addition, our approach
	offers easy and extensive control over the size and quality of the
	output mesh as well as over its associated re- projection error.
	Our numerical experiments demonstrate the effectiveness and flexibility
	of our approach for generating compact, high-quality, time-coherent
	visual hull representations from real silhouette image data.},
  doi = {10.1109/ICCV.2007.4409016},
  file = {:./Aganj2007/07iccv_b.pdf:PDF},
  issn = {1550-5499},
  journal = {Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference
	on},
  keywords = {image representation, interpolation, mesh generation, spatiotemporal
	phenomenafour-dimensional Delaunay meshing algorithm, image representation,
	interpolation, silhouette image data, spatio-temporal visual hull},
  owner = {apinzonf},
  review = {Utilizan la coherencia temporal que debe exister cuando los cambios
	en el tiempo de la malla 3d son bajos.
	
	
	Clasificaciones:
	
	 - Shape from silhouette: Reconstruccion de un objeto desde multiples
	vistas.
	
	
	Visual Hull, origenes en B. Baumgart. Geometric Modeling for Computer
	Vision. Phd Tesis. 1974
	
	Se divide en:
	
	 * Volume Based: Usan la subdivision de espacio, dentro de regiones
	elementales tipicamente voxeles (AQUI SE PODRIA UTILIZAR TABLAS HASH
	PARA INDEXAR LAS REGIONES DEL ESPACIO), En estos metodos usan los
	algoritmos de extraccion de isosuperficies como el de marching cubes
	
	 * Surface Based},
  timestamp = {2009.04.01}
}

@MASTERSTHESIS{Aguiar2003,
  author = {de Aguiar, Edilson},
  title = {Character Animation from a Motion Capture Database},
  school = {Universit{\"a}t des Saarlandes},
  year = {2003},
  month = {November},
  note = {Thesis},
  abstract = {With the advent of photo-realism in Computer Graphics, life-like character
	animations that capture fine details of a motion have become more
	important. We have studied methods [1] that use the information contained
	in a motion capture database to assist in the creation of a realistic
	character animation. Starting with an animation sketch, where only
	a small number of keyframes for some degrees of freedom are set,
	the motion capture data is used to enhance the initial motion.},
  file = {:./Aguiar2003/deAguiar_masterthesis.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{Aguiar2008,
  author = {de Aguiar,, Edilson and Stoll,, Carsten and Theobalt,, Christian
	and Ahmed,, Naveed and Seidel,, Hans-Peter and Thrun,, Sebastian},
  title = {Performance capture from sparse multi-view video},
  booktitle = {SIGGRAPH '08: ACM SIGGRAPH 2008 papers},
  year = {2008},
  pages = {1--10},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {3D Reconstruction},
  abstract = {This paper proposes a new marker-less approach to capturing human
	performances from multi-view video. Our algorithm can jointly reconstruct
	spatio-temporally coherent geometry, motion and textural surface
	appearance of actors that perform complex and rapid moves. Furthermore,
	since our algorithm is purely meshbased and makes as few as possible
	prior assumptions about the type of subject being tracked, it can
	even capture performances of people wearing wide apparel, such as
	a dancer wearing a skirt. To serve this purpose our method efficiently
	and effectively combines the power of surface- and volume-based shape
	deformation techniques with a new mesh-based analysis-through-synthesis
	framework. This framework extracts motion constraints from video
	and makes the laser-scan of the tracked subject mimic the recorded
	performance. Also small-scale time-varying shape detail is recovered
	by applying model-guided multi-view stereo to refine the model surface.
	Our method delivers captured performance data at higher level of
	detail, is highly versatile, and is applicable to many complex types
	of scenes that could not be handled by alternative marker-based or
	marker-free recording techniques.},
  doi = {http://doi.acm.org/10.1145/1399504.1360697},
  file = {:./Aguiar2008/pcmv_preprint.pdf:PDF},
  location = {Los Angeles, California},
  owner = {apinzonf},
  review = {Usan un modelo obtenido desde un escaner 3D (visu smart).
	
	Usan el modelo escaneado lo mayan, y lo deforman con elementos finitios,
	hasta aproximarse a la forma de las sluetas obtenidas desde las 8
	vistas.},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Aguiar2005,
  author = {de Aguiar, Edilson and Theobalt, Christian and Magnor, Marcus and
	Seidel, Hans-Peter},
  title = {Reconstructing Human Shape and Motion from Multi-View Video},
  booktitle = {2nd European Conference on Visual Media Production (CVMP)},
  year = {2005},
  pages = {42--49},
  address = {London, UK},
  month = {December},
  publisher = {The IEE},
  note = {3D Reconstruction},
  abstract = {In model-based free-viewpoint video, a detailed representation of
	the time-varying geometry of a real-word scene is used to generate
	renditions of it from novel viewpoints. In this paper, we present
	a method for reconstructing such a dynamic geometry model of a human
	actor from multi-view video. In a two-step procedure, ?rst the spatio-temporally
	consistent shape and poses of a generic human body model are estimated
	by means of a silhouette-based analysis-by-synthesis method.
	
	In a second step, subtle details in surface geometry that are speci?c
	to each particular time step are recovered by enforcing a color-consistency
	criterion. By this means, we generate a realistic representation
	of the time-varying geometry of a
	
	moving person that also reproduces these dynamic surface variations.},
  file = {:./Aguiar2005/deAguiar_cvmp05.pdf:PDF},
  isbn = {0-86341-583-0},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{Aguiar2004,
  author = {de Aguiar, Edilson and Theobalt, Christian and Magnor, Marcus and
	Theisel, Holger and Seidel, Hans-Peter},
  title = {M3 : Marker-free Model Reconstruction and Motion Tracking from 3D
	Voxel Data},
  booktitle = {12th Pacific Conference on Computer Graphics and Applications, PG
	2004},
  year = {2004},
  editor = {Cohen-Or, Daniel and Ko, Hyeong-Seok and Terzopoulos, Demetri and
	Warren, Joe},
  pages = {101--110},
  address = {Seoul, Korea},
  month = {October},
  organization = {IEEE},
  publisher = {IEEE},
  note = {Skeleton Extraction},
  abstract = {In computer animation, human motion capture from video is a widely
	used technique to acquire motion parameters. The acquisition process
	typically requires an intrusion into the scene in the form of optical
	markers which are used to estimate the parameters of motion as well
	as the kinematic structure of the performer. Marker-free optical
	motion capture approaches exist, but due to their dependence on a
	specific type of a-priori model they can hardly be used to track
	other subjects, e.g. animals. To bridge the gap between the generality
	of marker-based methods and the applicability of marker-free methods
	we study a flexible nonintrusive approach that estimates both, a
	kinematic model and its parameters of motion from a sequence of voxel-volumes.
	The volume sequences are reconstructed from multi-view video data
	by means of a shape from-silhouette technique. The method [1] is
	well-suited for but not limited to motion capture of human subjects,
	as presented in [2].},
  file = {:./Aguiar2004/deAguiar_pg2004.pdf:PDF},
  isbn = {0-7695-2234-3},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{Aguiar2007,
  author = {de Aguiar, E. and Theobalt, C. and Stoll, C. and Seidel, H. P.},
  title = {Marker-less Deformable Mesh Tracking for Human Shape and Motion Capture},
  booktitle = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference
	on},
  year = {2007},
  pages = {1--8},
  note = {3D Reconstruction},
  abstract = {We present a novel algorithm to jointly capture the motion and the
	dynamic shape of humans from multiple video streams without using
	optical markers. Instead of relying on kinematic skeletons, as traditional
	motion capture methods, our approach uses a deformable high-quality
	mesh of a human as scene representation. It jointly uses an image-based
	3D correspondence estimation algorithm and a fast Laplacian mesh
	deformation scheme to capture both motion and surface deformation
	of the actor from the input video footage. As opposed to many related
	methods, our algorithm can track people wearing wide apparel, it
	can straightforwardly be applied to any type of subject, e.g. animals,
	and it preserves the connectivity of the mesh over time. We demonstrate
	the performance of our approach using synthetic and captured real-world
	video sequences and validate its accuracy by comparison to the ground
	truth.},
  citeulike-article-id = {3646236},
  doi = {http://dx.doi.org/10.1109/CVPR.2007.383296},
  file = {:./Aguiar2007/deAguiar_cvpr07.pdf:PDF},
  journal = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference
	on},
  keywords = {capture, cg},
  owner = {apinzonf},
  posted-at = {2008-11-21 12:41:02},
  priority = {2},
  timestamp = {2009.03.18},
  url = {http://dx.doi.org/10.1109/CVPR.2007.383296}
}

@INPROCEEDINGS{Ahmed2005,
  author = {Ahmed, Naveed and de Aguiar, Edilson and Theobalt, Christian and
	Magnor, Marcus and Seidel, Hans-Peter},
  title = {Automatic Generation of Personalized Human Avatars from Multi-View
	Video},
  booktitle = {VRST '05: Proceedings of the ACM symposium on Virtual reality software
	and technology},
  year = {2005},
  pages = {257--260},
  address = {Monterey, USA},
  month = {December},
  organization = {Association for Computing Machinery (ACM)},
  publisher = {ACM},
  note = {Motion Capture},
  abstract = {In multi-user virtual environments, like online games or 3D chat rooms,
	real-world people interact via digital avatars. In order to make
	the step from the real world onto the virtual stage convincing the
	digital equivalent of the user has to be personalized. It should
	reflect the shape and proportions, the kinematic properties, as well
	as the textural appearance of its real-world equivalent. In [1] we
	present a novel easy-to-use and fully-automatic approach to create
	a personalized avatar from multi-view video data of a moving person.
	An adaptable generic human body model is scaled and deformed until
	its shape and skeletal dimensions match the real human shown in the
	video footage. A consistent surface texture for the model is generated
	using multi-view video frames from different camera views and different
	body poses. With our proposed method photo-realistic human avatars
	can be robustly generated.},
  file = {:./Ahmed2005/deAguiar_vrst05.pdf:PDF},
  isbn = {1-59593-098-1},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{AitAider2006,
  author = {Ait Aider, O. and Andreff, N. and Lavest, J.M. and Martinet, P.},
  title = {Simultaneous Object Pose and Velocity Computation Using a Single
	View from a Rolling Shutter Camera},
  booktitle = ECCV06,
  year = {2006},
  pages = {II: 56-68},
  note = {3D Reconstruction},
  abstract = {An original method for computing instantaneous 3D pose and velocity
	of fast moving objects using a single view is presented. It exploits
	image deformations induced by rolling shutter in CMOS image sensors.
	First of all, a general perspective projection model of a moving
	3D point is presented. A solution for the pose and velocity recovery
	problem is then described. The method is based on bundle adjustment
	and uses point correspondences. The resulting algorithm enables to
	transform a CMOS low cost and low power camera into an original velocity
	sensor. Finally, experimental results with real data confirm the
	relevance of the approach.},
  bibsource = {http://www.visionbib.com/bibliography/motion-i789.html#TT68081},
  file = {:./AitAider2006/simultaneous_object_pose_and_velocity_computation_using_a_single_view_from_a_rolling_shutter_camera.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{Amenta2001,
  author = {Amenta,, Nina and Choi,, Sunghee and Kolluri,, Ravi Krishna},
  title = {The power crust},
  booktitle = {SMA '01: Proceedings of the sixth ACM symposium on Solid modeling
	and applications},
  year = {2001},
  pages = {249--266},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Skeleton Extraction},
  abstract = {The medial axis transform (or MAT) is a representation of an object
	as an infinite union of balls. We consider approximating the MAT
	of a three-dimensional object, and its complement, with a finite
	union of balls. Using this approximate MAT we define a new piecewise-linear
	approximation to the object surface, which we call the power crust.
	We assume that we are given as input a suficiently dense sample of
	points from the object surface. We select a subset of the Voronoi
	balls of the sample, the polar balls, as the union of balls representation.
	We bound the geometric error of the union, and of the corresponding
	power crust, and show that both representations are topologically
	correct as well. Thus, our results provide a new algorithm for surface
	reconstruction from sample points. By construction, the power crust
	is always the boundary of a solid, so we avoid the hole-filling or
	manifold extraction steps used in previous algorithms. The union
	of balls representation and the power crust have corresponding piecewise-linear
	dual representations, which in some sense approximate the medial
	axis. We show a geometric relationship between these duals and the
	medial axis by proving that, as the sampling density goes to infinity,
	the set of poles, the centers of the polar balls, converge to the
	medial axis},
  doi = {http://doi.acm.org/10.1145/376957.376986},
  file = {:./Amenta2001/power.pdf:PDF},
  isbn = {1-58113-366-9},
  location = {Ann Arbor, Michigan, United States},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{AndreiSharf2007,
  author = {Andrei Sharf, Thomas Lewiner, Ariel Shamir, Leif Kobbelt},
  title = {On-the-fly Curve-skeleton Computation for 3D Shapes},
  booktitle = {Computer Graphics Forum},
  year = {2007},
  volume = {26},
  number = {3},
  series = {323-328},
  address = {School of Computer Science, Tel Aviv University; Departament of Mathematics,
	PUCRio de Janiero; Efi Arazi School of Computer Science, The Interdisciplinary
	Center, Herzliya; Computer Graphics Group, RWTH Aachen},
  note = {Skeleton Extraction},
  abstract = {The curve-skeleton of a 3D object is an abstract geometrical and topological
	representation of its 3D shape. It maps the spatial relation of geometrically
	meaningful parts to a graph structure. Each arc of this graph represents
	a part of the object with roughly constant diameter or thickness,
	and approximates its centerline. This makes the curve-skeleton suitable
	to describe and handle articulated objects such as characters for
	animation. We present an algorithm to extract such a skeleton on-the-fly,
	both from point clouds and polygonal meshes. The algorithm is based
	on a deformable model evolution that captures the object's volumetric
	shape. The deformable model involves multiple competing fronts which
	evolve inside the object in a coarse-to-fine manner. We first track
	these fronts' centers, and then merge and filter the resulting arcs
	to obtain a curve-skeleton of the object. The process inherits the
	robustness of the reconstruction technique, being able to cope with
	noisy input, intricate geometry and complex topology. It creates
	a natural segmentation of the object and computes a center curve
	for each segment while maintaining a full correspondence between
	the skeleton and the boundary of the object.},
  doi = {10.1111/j.1467-8659.2007.01054.x},
  file = {:./AndreiSharf2007/skeleblob_eg.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.30},
  url = {http://dx.doi.org/10.1111/j.1467-8659.2007.01054.x}
}

@INPROCEEDINGS{Aouada2009,
  author = {Aouada, D. and Krim, H.},
  title = {Novel similarity invariant for space curves using turning angles
	and its application to object recognition},
  booktitle = {Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE
	International Conference on},
  year = {2009},
  pages = {1277-1280},
  month = {April},
  note = {Other},
  abstract = {We present a new similarity invariant signature for space curves.
	This signature is based on the information contained in the turning
	angles of both the tangent and the binormal vectors at each point
	on the curve. For an accurate comparison of these signatures, we
	define a Riemannian metric on the space of the invariant. We show
	through relevant examples that, unlike classical invariants, the
	one we define in this paper enjoys multiple important properties
	at the same time, namely, a high discrimination level, independence
	of any reference point, uniqueness property, as well as a good preservation
	of the correspondence between curves. Moreover, we illustrate how
	to match 3D objects by extracting and comparing the invariant signatures
	of their curved skeletons.},
  doi = {10.1109/ICASSP.2009.4959824},
  file = {:./Aouada2009/Aouada2009.pdf:PDF},
  issn = {1520-6149},
  keywords = {curve fitting, object recognitionbinormal vector, object recognition,
	similarity invariant signature, space curve, tangent vector, turning
	angle},
  owner = {apinzonf},
  timestamp = {2009.10.19}
}

@ARTICLE{Attali2007,
  author = {D. Attali and J.-D. Boissonnat and H. Edelsbrunner},
  title = {Stability and Computation of the Medial Axis --- a State-of-the-Art
	Report},
  journal = {Mathematical Foundations of Scientific Visualization, Computer Graphics,
	and Massive Data Exploration},
  year = {2007},
  volume = {1},
  pages = {-},
  note = {Skeleton Extraction survey},
  abstract = {The medial axis of a geometric shape captures its connectivity. In
	spite of its inherent instability, it has found applications in a
	number of areas that deal with shapes. In this survey paper, we focus
	on results that shed light on this in-
	
	stability and use the new insights to generate simplied and stable
	versions of the medial axis},
  editor = {Springer-Verlag},
  file = {:./Attali2007/survey-medialaxis.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{Attali2003,
  author = {Attali,, Dominique and Boissonnat,, Jean-Daniel and Lieutier,, Andr\'{e}},
  title = {Complexity of the delaunay triangulation of points on surfaces the
	smooth case},
  booktitle = {SCG '03: Proceedings of the nineteenth annual symposium on Computational
	geometry},
  year = {2003},
  pages = {201--210},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {3D Reconstruction},
  abstract = {It is well known that the complexity of the Delaunay triangulation
	of N points in R 3, i.e. the number of its faces, can be O (N2).
	The case of points distributed on a surface is of great practical
	importance in reverse engineering since most surface reconstruction
	algorithms first construct the Delaunay triangulation of a set of
	points measured on a surface.In this paper, we bound the complexity
	of the Delaunay triangulation of points distributed on generic smooth
	surfaces of R 3. Under a mild uniform sampling condition, we show
	that the complexity of the 3D Delaunay triangulation of the points
	is O(N log N).},
  doi = {http://doi.acm.org/10.1145/777792.777823},
  file = {:./Attali2003/geometrica2.pdf:PDF},
  isbn = {1-58113-663-3},
  location = {San Diego, California, USA},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@ARTICLE{Au2008,
  author = {Oscar Kin-Chung Au and Chiew-Lan Tai and Hung-Kuo Chu and Daniel
	Cohen-Or and Tong-Yee Lee},
  title = {Skeleton Extraction by Mesh Contraction},
  journal = {ACM Transactions on Graphics},
  year = {2008},
  volume = {27},
  pages = {10},
  number = {3},
  note = {Skeleton Extraction},
  abstract = {Extraction of curve-skeletons is a fundamental problem with many applications
	in computer graphics and visualization. In this paper, we present
	a simple and robust skeleton extraction method based on mesh contraction.
	The method works directly on the mesh domain, without pre-sampling
	the mesh model into a volumetric representation. The method first
	contracts the mesh geometry into a zero-volume skeletal shape by
	applying implicit Laplacian smoothing with global positional constraints.
	The contraction does not alter the mesh connectivity and retains
	the key features of the original mesh. The contracted mesh is then
	converted into a 1D curve-skeleton through a connectivity surgery
	process to remove all the collapsed faces while preserving the shape
	of the contracted mesh and the original topology. The centeredness
	of the skeleton is refined by exploiting the induced skeleton-mesh
	mapping. The contraction process generates valuable information about
	the object's geometry, in particular, the skeleton-vertex correspondence
	and the local thickness, which are useful for various applications.
	We demonstrate its effectiveness in mesh segmentation and skinning
	animation.},
  file = {:./Au2008/skeleton_sig08.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@ARTICLE{Bergh2009,
  author = {Bergh,, Michael and Koller-Meier,, Esther and Gool,, Luc},
  title = {Real-Time Body Pose Recognition Using 2D or 3D Haarlets},
  journal = {Int. J. Comput. Vision},
  year = {2009},
  volume = {83},
  pages = {72--84},
  number = {1},
  note = {Motion Capture},
  abstract = {This article presents a novel approach to markerless real-time pose
	recognition in a multicamera setup. Body pose is retrieved using
	example-based classification based on Haar wavelet-like features
	to allow for real-time pose recognition. Average Neighborhood Margin
	Maximization (ANMM) is introduced as a powerful new technique to
	train Haar-like features. The rotation invariant approach is implemented
	for both 2D classification based on silhouettes, and 3D classification
	based on visual hulls.},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1007/s11263-009-0218-0},
  file = {:./Bergh2009/bergh2009.pdf:PDF},
  issn = {0920-5691},
  owner = {apinzonf},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2009.04.30}
}

@ARTICLE{Bitter2001,
  author = {Bitter, I. and Kaufman, A. E. and Sato, M. },
  title = {Penalized-distance volumetric skeleton algorithm},
  journal = {Transactions on Visualization and Computer Graphics},
  year = {2001},
  volume = {7},
  pages = {195--206},
  number = {3},
  note = {Skeleton Extraction},
  abstract = {Introduces a refined general definition of a skeleton that is based
	on a penalized distance function and that cannot create any of the
	degenerate cases of the earlier CEASAR (Center-line Extraction Algorithm-Smooth,
	Accurate and Robust) and TEASAR (Tree-structure Extraction Algorithm
	for Skeletons-Accurate and Robust) algorithms. Additionally, we provide
	an algorithm that finds the skeleton accurately and rapidly. Our
	solution is fully automatic, which frees the user from having to
	engage in manual data pre-processing. We present the accurate skeletons
	computed on a number of test data sets. The algorithm is very efficient,
	as demonstrated by the running times, which were all below seven
	minutes},
  booktitle = {Transactions on Visualization and Computer Graphics},
  citeulike-article-id = {2230601},
  doi = {10.1109/2945.942688},
  file = {:./Bitter2001/Bitter2001.pdf:PDF},
  keywords = {distance-field, skeleton},
  owner = {apinzonf},
  posted-at = {2008-01-14 14:19:06},
  priority = {2},
  timestamp = {2009.04.30},
  url = {http://dx.doi.org/10.1109/2945.942688}
}

@ARTICLE{blum1967,
  author = {Blum, Harry},
  title = {A Transformation for Extracting New Descriptors of Shape},
  journal = {Models for the Perception of Speech and Visual Form},
  year = {1967},
  volume = {1},
  pages = {362--380},
  note = {Skeleton Extraction},
  address = {Cambridge, MA},
  citeulike-article-id = {4807998},
  citeulike-linkout-0 = {http://pageperso.lif.univ-mrs.fr/~edouard.thiel/rech/1967-blum.pdf},
  editor = {Wathen-Dunn, Weiant},
  file = {:./Blum1967/1967-blum.pdf:PDF},
  keywords = {voronoi},
  owner = {apinzonf},
  posted-at = {2009-06-11 06:14:45},
  priority = {2},
  publisher = {MIT Press},
  timestamp = {2009.08.24},
  url = {http://pageperso.lif.univ-mrs.fr/~edouard.thiel/rech/1967-blum.pdf}
}

@INPROCEEDINGS{Boehnen2009,
  author = {Chris Boehnen and Tanya Peters and Patrick Flynn},
  title = {3D Signatures for Fast 3D Face Recognition},
  booktitle = {Proceedings of International Conference on Biometrics (ICB) 2009},
  year = {2009},
  note = {Face Recognition},
  abstract = {We propose a vector representation (called a 3D signature) for 3D
	face shape in biometrics applications. Elements of the vector correspond
	to fixed surface points in a face-centered coordinate system. Since
	the elements are registered to the face comparisons of vectors to
	produce match scores can be performed without a probe to gallery
	alignment step such as an invocation of the iterated closest point
	(ICPalgorithm in the calculation of each match score. The proposed
	3D face recognition method employing the 3D signature ran more than
	three orders of magnitude faster than a traditional ICP based distance
	implementation, without sacrificing accuracy. As a result, it is
	feasible to apply distance based 3D face biometrics to recognition
	scenarios that, because of computational constraints, may have previously
	been limited to verification. Our use of more complex shape regions,
	which is a trivial task with the use of 3D signatures, improves biometric
	performance over simple spherical cut regions used previously [1].
	Experimental results with a large database of 3D images demonstrate
	the technique and its advantages.},
  file = {:./Boehnen2009/3D Signatures ICB.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@ARTICLE{Botsch2008,
  author = {Botsch,, Mario and Sorkine,, Olga},
  title = {On Linear Variational Surface Deformation Methods},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  year = {2008},
  volume = {14},
  pages = {213--230},
  number = {1},
  note = {Skeleton Extraction},
  abstract = {This survey reviews the recent advances in linear variational mesh
	deformation techniques. These methods were developed for editing
	detailed high-resolution meshes, like those produced by scanning
	real-world objects. The challenge of manipulating such complex surfaces
	is three-fold: the deformation technique has to be sufficiently fast,
	robust, and intuitive and easy to control to be useful for interactive
	applications. An intuitive, and thus predictable, deformation tool
	should provide physically plausible and aesthetically pleasing surface
	deformations, which in particular requires its geometric details
	to be preserved. The methods we survey generally formulate surface
	deformation as a global variational optimization problem that addresses
	the differential properties of the edited surface. Efficiency and
	robustness are achieved by linearizing the underlying objective functional,
	such that the global optimization amounts to solving a sparse linear
	system of equations. We review the different deformation energies
	and detail preservation techniques that were proposed in the recent
	years, together with the various techniques to rectify the linearization
	artifacts. Our goal is to provide the reader with a systematic classification
	and comparative description of the different techniques, revealing
	the strengths and weaknesses of each approach in common editing scenarios.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/TVCG.2007.1054},
  file = {:./Botsch2008/IEEEXplore.pdf:PDF},
  issn = {1077-2626},
  owner = {apinzonf},
  publisher = {IEEE Educational Activities Department},
  timestamp = {2009.04.07}
}

@ARTICLE{Bottino2004,
  author = {Bottino, A. and Laurentini, A.},
  title = {The visual hull of smooth curved objects},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {2004},
  volume = {26},
  pages = { 1622-1632},
  number = {12},
  month = {Dec.},
  note = {3D Reconstruction},
  abstract = { The visual hull is a geometric entity that relates the shape of an
	object to its silhouettes or shadows. This paper develops the theory
	of the visual hull of generic smooth objects. We show that the visual
	hull can be constructed using surfaces which partition the viewpoint
	space of the aspect graph of the object. The surfaces are those generated
	by the visual events tangent crossing and triple point. An analysis
	based on the shape of the object at the tangency points of these
	surfaces allows pruning away many surfaces and patches not relevant
	to the construction. An algorithm for computing the visual hull is
	outlined.},
  doi = {10.1109/TPAMI.2004.130},
  file = {:./Bottino2004/bottino2004.pdf:PDF},
  issn = {0162-8828},
  keywords = { computer vision, geometry, graph theory, image reconstruction computer
	vision, generic smooth objects, geometric entity, graph theory, image
	reconstruction, object silhouettes, smooth curved objects, visual
	events, visual hull computing},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@ARTICLE{Bottino2003,
  author = {Bottino, A. and Laurentini, A.},
  title = {Introducing a new problem: shape-from-silhouette when the relative
	positions of the viewpoints is unknown},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {2003},
  volume = {25},
  pages = { 1484-1493},
  number = {11},
  month = {Nov.},
  note = {3D Reconstruction},
  abstract = { 3D shapes can be reconstructed from 2D silhouettes by back-projecting
	them from the corresponding viewpoints and intersecting the resulting
	solid cones. However, in many practical cases as observing an aircraft
	or an asteroid, the positions of the viewpoints with respect to the
	object are not known. In these cases, the relative position of the
	solid cones is not known and the intersection cannot be performed.
	The purpose of this paper is introducing and stating in a theoretical
	framework the problem of understanding 3D shapes from silhouettes
	when the relative positions of the viewpoints are unknown. The results
	presented provide a first insight into the problem. In particular,
	the case of orthographic viewing directions parallel to the same
	plane is thoroughly discussed, and sets of inequalities are presented
	which allow determining objects compatible with the silhouettes.},
  doi = {10.1109/TPAMI.2003.1240121},
  file = {:./Bottino2003/botino2003.pdf:PDF},
  issn = {0162-8828},
  keywords = { computer vision, image reconstruction computer vision, object reconstruction,
	shape-from-silhouette, viewpoints, visual hull, volume intersection},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@ARTICLE{Bradley2008,
  author = {Derek Bradley and Tiberiu Popa and Alla Sheffer and Wolfgang Heidrich
	and Tamy Boubekeur},
  title = {Markerless Garment Capture},
  journal = {ACM Trans. Graphics (Proc. SIGGRAPH)},
  year = {2008},
  volume = {27},
  pages = {99},
  number = {3},
  note = {3D Reconstruction},
  abstract = {A lot of research has recently focused on the problem of capturing
	the geometry and motion of garments. Such work usually relies on
	special markers printed on the fabric to establish temporally coherent
	correspondences between points on the garment’s surface at different
	times. Unfortunately, this approach is tedious and prevents the capture
	of off-the-shelf clothing made from interesting fabrics.
	
	
	In this paper, we describe a marker-free approach to capturing garment
	motion that avoids these downsides. We establish temporally coherent
	parameterizations between incomplete geometries that we extract at
	each timestep with a multiview stereo algorithm. We then fill holes
	in the geometry using a template. This approach, for the first time,
	allows us to capture the geometry and motion of unpatterned, off-the-shelf
	garments made from a range of different fabrics.},
  file = {:./Bradley2008/MarkerlessGarmentCapture.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Brand2004,
  author = {Brand, M. and Kongbin Kang and Cooper, D.B.},
  title = {Algebraic solution for the visual hull},
  booktitle = {Computer Vision and Pattern Recognition},
  year = {2004},
  volume = {1},
  pages = { I-30-I-35 Vol.1},
  month = {June-2 July},
  note = {3D Reconstruction},
  abstract = { We introduce an algebraic dual-space method for reconstructing the
	visual hull of a three-dimensional object from occluding contours
	observed in 2D images. The method exploits the differential structure
	of the manifold rather than parallax geometry, and therefore requires
	no correspondences. We begin by observing that the set of 2D contour
	tangents determines a surface in a dual space where each point represents
	a tangent plane to the original surface. The primal and dual surfaces
	have a symmetric algebra: A point on one is orthogonal to its dual
	point and tangent basis on the other. Thus the primal surface can
	be reconstructed if the local dual tangent basis can be estimated.
	Typically this is impossible because the dual surface is noisy and
	riddled with tangent singularities due to self-crossings. We identify
	a directionally-indexed local tangent basis that is well-defined
	and estimable everywhere on the dual surface. The estimation procedure
	handles singularities in the dual surface and degeneracies arising
	from measurement noise. The resulting method has O(N) complexity
	for N observed contour points and gives asymptotically exact reconstructions
	of surfaces that are totally observable from occluding contours.},
  doi = {10.1109/CVPR.2004.1315010},
  file = {:./Brand2004/brand2004.pdf:PDF},
  issn = {1063-6919 },
  journal = {Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings
	of the 2004 IEEE Computer Society Conference on},
  keywords = { algebra, computational complexity, computational geometry, differential
	geometry, image reconstruction 2D contour tangents, O(N) complexity,
	algebraic dual space method, algebraic solution, directionally indexed
	local tangent basis, image reconstruction, measurement noise, occluding
	contours, parallax geometry, symmetric algebra, three dimensional
	object, visual hull reconstruction},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Brito2008,
  author = {Brito, D.N. and Padua, F.L.C. and Carceroni, R.L. and Pereira, G.},
  title = {Synchronizing Video Cameras with Non-overlapping Fields of View},
  booktitle = {Computer Graphics and Image Processing, 2008. SIBGRAPI '08. XXI Brazilian
	Symposium on},
  year = {2008},
  pages = {37-44},
  month = {Oct.},
  note = {Synchronizing Video Cameras},
  abstract = {This paper describes a method to estimate the temporal alignment between
	N unsynchronized video sequences captured by cameras with non-overlapping
	fields of view. The sequences are recorded by stationary video cameras,
	with fixed intrinsic and extrinsic parameters. The proposed approach
	reduces the problem of synchronizing N non-overlapping sequences
	to the robust estimation of a single line in RN+1. This line captures
	all temporal relations between the sequences and a moving sensor
	in the scene, whose locations in the world coordinate system may
	be estimated at a constant sampling rate. Experimental results with
	real-world sequences show that our method can accurately align the
	videos.},
  doi = {10.1109/SIBGRAPI.2008.28},
  file = {:./Brito2008/Brito2008.PDF:PDF},
  issn = {1530-1834},
  keywords = {image sequences, synchronisation, video camerasnonoverlapping fields,
	single line robust estimation, synchronisation, video cameras, video
	sequences},
  owner = {apinzonf},
  timestamp = {2009.10.20}
}

@ARTICLE{Caillette2008,
  author = {Caillette,, Fabrice and Galata,, Aphrodite and Howard,, Toby},
  title = {Real-time 3-D human body tracking using learnt models of behaviour},
  journal = {Comput. Vis. Image Underst.},
  year = {2008},
  volume = {109},
  pages = {112--125},
  number = {2},
  note = {Motion Capture},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/j.cviu.2007.05.005},
  file = {:./Caillette2008/CGH_cviu.pdf:PDF},
  issn = {1077-3142},
  owner = {apinzonf},
  publisher = {Elsevier Science Inc.},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{Caillette2005,
  author = {Fabrice Caillette and Aphrodite Galata and Toby Howard},
  title = {Real-Time 3-D Human Body Tracking Using Variable Length Markov Models},
  booktitle = {In British Machine Vision Conf},
  year = {2005},
  pages = {469--478},
  note = {Motion Capture},
  abstract = {In this paper, we introduce a 3-D human-body tracker capable of handling
	fast and complex motions in real-time. The parameter space, augmented
	with first order derivatives, is automatically partitioned into Gaussian
	clusters each representing an elementary motion: hypothesis propagation
	inside each cluster is therefore accurate and efficient. The transitions
	between clusters use the predictions of a Variable Length Markov
	Model which can explain highlevel behaviours over a long history.
	Using Monte-Carlo methods, evaluation of model candidates is critical
	for both speed and robustness. We present a new evaluation scheme
	based on volumetric reconstruction and blobs-fitting, where appearance
	models and image evidences are represented by Gaussian mixtures.
	We demonstrate the application of our tracker to long video sequences
	exhibiting rapid and diverse movements.},
  file = {:./Caillette2005/CGH-bmvc05.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@PHDTHESIS{Campos2006,
  author = {Teo?lo Em?dio de Campos},
  title = {3D Visual Tracking of Articulated Objects and Hands},
  school = {Department of Engineering Science - University of Oxford},
  year = {2006},
  note = {Visual Tracking},
  abstract = {The ability to track multiple and articulated objects is an important
	one, not least in the areas of autonomous and teleoperated robotics,
	visual surveillance and human motion analysis. This thesis is concerned
	with marker-free real-time detection and tracking of articulated
	objects, targeting human hands with the aim to study methods that
	can be applied to enhance the interaction between humans and 3D (real
	or virtual) objects.
	
	
	A survey summarises methods used to approach this and related problems
	in the literature. It indicates that, despite the large body of research
	in this field over twenty or so years, the area still proves challenging.
	Two main approaches have been identified. The first, known as generative
	tracking, uses an explicit kinematical representation of linkages
	or constraints between object parts and tracks by minimising error
	of projected control points. The second, known as discriminative
	approach, little is specified beforehand, but training data is used
	in order to create a map between image observations and 3D poses.
	This thesis describes novel work in both areas.
	
	
	In the generative area, a method for tracking of articulated objects
	is described. It is a new extension of a method for tracking rigid
	objects in which the motion constraints between parts of the object
	are imposed up-front within the tracking process. The inter-frame
	pose update is derived as the solution of a linear system. This method
	has been applied to track articulated objects, including hands and
	multiple objects with motion constraints.
	
	
	An alternative method is that based on estimating the motion of each
	subpart independently, thereby introducing redundant degrees of freedom,
	and imposing constraints later in a lower dimensional subspace. This
	method is reviewed and a comparison between this and the aforementioned
	method is presented in terms of accuracy, efficiency and robustness.
	
	
	In the discriminative area, an inference-based approach is adopted
	in which a non-parametric relation between global image measurements
	and 3D poses is learnt using a multivariate regressor based on Relevance
	Vector Machine. This relation is a continuous map that allows fast
	and efficient pose estimation from static images. This method can
	detect and estimate the 3D pose of hands from static images, so it
	can be applied to (re-)initialise the generative tracker.
	
	
	In this thesis, the use of multiple view is adopted as a solution
	to reduce the ambiguities for both generative and discriminative
	methods. Experiments with single and multiple views are described
	and a novel extension of the discriminative method for multiple views
	is proposed and evaluated.},
  file = {:./Campos2006/teo_decampos__thesis_print.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@ARTICLE{Campos2006a,
  author = {Teofilo E. de Campos and David W. Murray},
  title = {Regression-based Hand Pose Estimation from Multiple Cameras},
  journal = {Computer Vision and Pattern Recognition, IEEE Computer Society Conference
	on},
  year = {2006},
  volume = {1},
  pages = {782-789},
  note = {Motion Capture},
  abstract = {The RVM-based learning method for whole body pose estimation proposed
	by Agarwal and Triggs is adapted to hand pose recovery. To help overcome
	the difficulties presented by the greater degree of self-occlusion
	and the wider range of poses exhibited in hand imagery, the adaptation
	proposes a method for combining multiple views. Comparisons of performance
	using single versus multiple views are reported for both synthesized
	and real imagery, and the effects of the number of image measurements
	and the number of training samples on performance are explored.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.252},
  file = {:./Campos2006/decampos_murray_cvpr2006.pdf:PDF},
  issn = {1063-6919},
  owner = {apinzonf},
  publisher = {IEEE Computer Society},
  timestamp = {2009.04.02}
}

@ARTICLE{Chai2005,
  author = {Chai,, Jinxiang and Hodgins,, Jessica K.},
  title = {Performance animation from low-dimensional control signals},
  journal = {ACM Trans. Graph.},
  year = {2005},
  volume = {24},
  pages = {686--696},
  number = {3},
  note = {Motion Capture},
  abstract = {This paper introduces an approach to performance animation that employs
	video cameras and a small set of retro-reflective markers to create
	a low-cost, easy-to-use system that might someday be practical for
	home use. The low-dimensional control signals from the user's performance
	are supplemented by a database of pre-recorded human motion. At run
	time, the system automatically learns a series of local models from
	a set of motion capture examples that are a close match to the marker
	locations captured by the cameras. These local models are then used
	to reconstruct the motion of the user as a full-body animation. We
	demonstrate the power of this approach with real-time control of
	six different behaviors using two video cameras and a small set of
	retro-reflective markers. We compare the resulting animation to animation
	from commercial motion capture equipment with a full set of markers.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1073204.1073248},
  file = {:./Chai2005/jchai_pa.pdf:PDF},
  issn = {0730-0301},
  owner = {apinzonf},
  publisher = {ACM},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Chen2008a,
  author = {Chen, Hongqian and Huang, Tianyu and Li, Fengxia and Zhan, Shouyi},
  title = {Shape Manipulation on GPU},
  booktitle = {Image and Signal Processing, 2008. CISP '08. Congress on},
  year = {2008},
  volume = {3},
  pages = {518-522},
  month = {May},
  note = {Other},
  abstract = {This paper proposes a novel hardware-accelerating deformation algorithm
	based on curve-skeleton model for 2D shape manipulation. The deformation
	algorithm can achieve real-time interactive shape manipulation without
	any pre-computing step. The deforming regions of shapes are demarcated
	with a simple skeleton frame and are simulated by a curve-skeleton
	model consisting of triangle-strips. The algorithm obtains two properties
	that smooth flexion and preservation of area. Smooth flexion is guaranteed
	due to the continuous derivative of the curve function, and preservation
	of area is achieved via adjusting the parameters of the control curves.
	GPGPU technique is adopted to reduce the workload on CPU and to accelerate
	the rendering. Our algorithm can be used to 2D shape manipulation,
	character animation and cartoon-like objects deformation. It has
	been proved feasible and valid by our experiments.},
  doi = {10.1109/CISP.2008.443},
  file = {:./Chen2008a/Chen2008a.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.10.19}
}

@ARTICLE{Chen2008,
  author = {Chen, Mang and Liu, Yun-cai},
  title = {Connection skeleton extraction based on contour connectedness},
  journal = {Journal of Shanghai Jiaotong University (Science)},
  year = {2008},
  volume = {13},
  pages = {521--527},
  number = {5},
  month = oct,
  note = {Skeleton Extraction},
  abstract = {Abstract&nbsp;&nbsp;A stable skeleton is very important to some applications
	such as vehicle navigation, object represent and pattern recognition.
	The connection skeleton is just one that not only can be computed
	stably but also can figure the connectivity structure of contour.
	A new method named continuous connectivity detection and a new model
	named approximate regular polygon (ARP) were proposed for connection
	skeleton extraction. Both the method and the model were tested by
	the real maps of road network including flyovers, interchanges and
	other common object contours. Satisfactory results were obtained.},
  file = {:./Chen2008/fulltext.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.03},
  url = {http://dx.doi.org/10.1007/s12204-008-0521-x}
}

@INPROCEEDINGS{Cheng2006,
  author = {Cheng,, Zhanglin and Zhang,, Xiaopeng and Fourcaud,, Thierry},
  title = {Tree Skeleton Extraction from a Single Range Image},
  booktitle = {PMA '06: Proceedings of the 2006 International Symposium on Plant
	Growth Modeling, Simulation, Visualization and Applications},
  year = {2006},
  pages = {274--281},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  note = {Skeleton Extraction},
  abstract = {Tree skeleton computation is of significance in the ge- ometric modeling
	of botanic trees and in the application of forestry. This paper describes
	an approach to extract branch skeletons from a single range image
	of a tree. A ba- sis of this approach is that the trunk and branches
	are mod- eled by generalized circular cylinders, and the tree skeleton
	is defined as the connected curve-axes of these cylinders. In the
	proposed system, the range image is partitioned into patches at first
	based on the discontinuity of depth and axis direction, where each
	patch only contains points from the same branch. Then each patch
	is fitted with a series of cir- cular cylinders. Finally the tree
	skeleton is generated by se- quentially connecting the skeleton points
	of fitted cylinders. This work shows that cylinder fitting can be
	used to han- dle the incompleteness of input data, and generate accurate
	skeleton points and corresponding radii. The main contri- bution
	of this paper is that we proposed a new definition and computation
	of tree skeletons and introduced an effi- cient and robust cylinder
	fitting method. Experiment shows the effectiveness of this approach.},
  doi = {http://dx.doi.org/10.1109/PMA.2006.28},
  file = {:./Cheng2006/cheng2006.pdf:PDF},
  isbn = {978-0-7695-2851-9},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@INPROCEEDINGS{Cheung2003a,
  author = {Cheung, G.K.M. and Baker, S. and Kanade, T.},
  title = {Visual hull alignment and refinement across time: a 3D reconstruction
	algorithm combining shape-from-silhouette with stereo},
  booktitle = {Computer Vision and Pattern Recognition, 2003. Proceedings. 2003
	IEEE Computer Society Conference on},
  year = {2003},
  volume = {2},
  pages = { II-375-82 vol.2},
  month = {June},
  note = {3D Reconstruction},
  abstract = {Visual hull (VH) construction from silhouette images is a popular
	method of shape estimation. The method, also known as shape-from-silhouette
	(SFS), is used in many applications such as non-invasive 3D model
	acquisition, obstacle avoidance, and more recently human motion tracking
	and analysis. One of the limitations of SFS, however, is that the
	approximated shape can be very coarse when there are only a few cameras.
	In this paper, we propose an algorithm to improve the shape approximation
	by combining multiple silhouette images captured across time. The
	improvement is achieved by first estimating the rigid motion between
	the visual hulls formed at different time instants (visual hull alignment)
	and then combining them (visual hull refinement) to get a tighter
	bound on the object's shape. Our algorithm first constructs a representation
	of the VHs called the bounding edge representation. Utilizing a fundamental
	property of visual hulls, which states that each bounding edge must
	touch the object at at least one point, we use multi-view stereo
	to extract points called colored surface points (CSP) on the surface
	of the object. These CSPs are then used in a 3D image alignment algorithm
	to find the 6 DOF rigid motion between two visual hulls. Once the
	rigid motion across time is known, all of the silhouette images are
	treated as being captured at the same time instant and the shape
	of the object is refined. We validate our algorithm on both synthetic
	and real data and compare it with space carving.},
  doi = {10.1109/CVPR.2003.1211493},
  file = {:./Cheung2003a/VisualHull.pdf:PDF},
  issn = {1063-6919 },
  journal = {Computer Vision and Pattern Recognition, 2003. Proceedings. 2003
	IEEE Computer Society Conference on},
  keywords = { computer vision, edge detection, image colour analysis, image reconstruction,
	motion estimation, object detection, stereo image processing 3D image
	alignment algorithm, 3D reconstruction algorithm, 6 DOF rigid motion,
	algorithm validation, bounding edge representation, camera, colored
	surface points, computer vision, human motion tracking, motion analysis,
	multiview stereo, noninvasive 3D model acquisition, object shape,
	object surface, obstacle avoidance, real data, rigid motion estimation,
	shape approximation, shape estimation, shape-from-silhouette, silhouette
	image, space carving, stereo image, synthetic data, time instant,
	visual hull alignment, visual hull refinement},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Cheung2003,
  author = {Cheung, K.M.G. and Baker, S. and Kanade, T.},
  title = {Shape-from-silhouette of articulated objects and its use for human
	body kinematics estimation and motion capture},
  booktitle = {Computer Vision and Pattern Recognition, 2003. Proceedings. 2003
	IEEE Computer Society Conference on},
  year = {2003},
  volume = {1},
  pages = { I-77-I-84 vol.1},
  month = {June},
  note = {3D Reconstruction},
  abstract = { Shape-from-silhouette (SFS), also known as visual hull (VH) construction,
	is a popular 3D reconstruction method, which estimates the shape
	of an object from multiple silhouette images. The original SFS formulation
	assumes that the entire silhouette images are captured either at
	the same time or while the object is static. This assumption is violated
	when the object moves or changes shape. Hence the use of SFS with
	moving objects has been restricted to treating each time instant
	sequentially and independently. Recently we have successfully extended
	the traditional SFS formulation to refine the shape of a rigidly
	moving object over time. We further extend SFS to apply to dynamic
	articulated objects. Given silhouettes of a moving articulated object,
	the process of recovering the shape and motion requires two steps:
	(1) correctly segmenting (points on the boundary of) the silhouettes
	to each articulated part of the object, (2) estimating the motion
	of each individual part using the segmented silhouette. In this paper,
	we propose an iterative algorithm to solve this simultaneous assignment
	and alignment problem. Once we have estimated the shape and motion
	of each part of the object, the articulation points between each
	pair of rigid parts are obtained by solving a simple motion constraint
	between the connected parts. To validate our algorithm, we first
	apply it to segment the different body parts and estimate the joint
	positions of a person. The acquired kinematic (shape and joint) information
	is then used to track the motion of the person in new video sequences.},
  doi = {10.1109/CVPR.2003.1211340},
  file = {:./Cheung2003/cheung_kong_man_2003_1.pdf:PDF},
  issn = {1063-6919 },
  journal = {Computer Vision and Pattern Recognition, 2003. Proceedings. 2003
	IEEE Computer Society Conference on},
  keywords = { edge detection, image reconstruction, image segmentation, image sequences,
	iterative methods, kinematics, motion estimation, object detection,
	optical tracking, stereo image processing, video signal processing
	3D reconstruction, dynamic articulated object, human body kinematics
	estimation, iterative algorithm, joint position estimation, motion
	capture, motion estimation, motion recovery, motion tracking, moving
	articulated object, multiple silhouette images, object shape estimation,
	shape recovery, shape-from-silhouette, silhouette image segmentation,
	video sequence, visual hull construction},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@PHDTHESIS{Cheung2003b,
  author = {Kong Man Cheung},
  title = {Visual Hull Construction, Alignment and Refinement for Human Kinematic
	Modeling, Motion Tracking and Rendering},
  school = {Robotics Institute, Carnegie Mellon University},
  year = {2003},
  address = {Pittsburgh, PA},
  month = {October},
  note = {3D Reconstruction},
  abstract = {The abilities to build precise human kinematic models and to perform
	accurate human motion tracking are essential in a wide variety of
	applications. Due to the complexity of the human bodies and the problem
	of self-occlusion, modeling and tracking humans using cameras are
	challenging tasks. In this thesis, we develop algorithms to perform
	these two tasks based on the shape estimation method Shape-From-Silhouette
	(SFS) which constructs a shape estimate (known as Visual Hull) of
	an object using its silhouettes images.
	
	
	In the first half of this thesis we extend the traditional SFS algorithm
	so that it can be used effectively for the human related applications.
	To perform SFS in real-time, we propose a fast testing/projection
	algorithm for voxel-based SFS algorithms. Moreover, we combine silhouette
	information over time to effectively increase the number of cameras
	(and hence reconstruction details) for SFS without physically adding
	new cameras. We first propose a new Visual Hull representation called
	Bounding Edges. We then analyze the ambiguity problem of aligning
	two Visual Hulls. Based on the analysis, we develop an algorithm
	to align Visual Hulls over time using stereo and an important property
	of the Shape-From-Silhouette principle. This temporal SFS algorithm
	combines both geometric constraints and photometric consistency to
	align Colored Surface Points of the object extracted from the silhouette
	and color images. Once the Visual Hulls are aligned, they are refined
	by compensating for the motion of the object. The algorithm is developed
	for both rigid and articulated objects.
	
	
	In the second half of this thesis we show how the improved SFS algorithms
	are used to perform the tasks of human modeling and motion tracking.
	First we build a system to acquire human kinematic models consisting
	of precise shape and joint locations. Once the kinematic models are
	built, they are used to track the motion of the person in new video
	sequences. The tracking algorithm is based on the Visual Hull alignment
	idea used in the temporal SFS algorithms. Finally we demonstrate
	how the kinematic model and the tracked motion data can be used for
	image-based rendering and motion transfer between two people.},
  file = {:./Cheung2003b/cheung_kong_man_2003_3.pdf:PDF},
  number = {CMU-RI-TR-03-44},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Cornea2005b,
  author = { Cornea, N.D. and Demirci, M.F. and Silver, D. and Shokoufandeh and
	Dickinson, S.J. and Kantor, P.B.},
  title = {3D object retrieval using many-to-many matching of curve skeletons},
  booktitle = {Shape Modeling and Applications, 2005 International Conference},
  year = {2005},
  pages = { 366-371},
  month = {June},
  note = {Skeleton Extraction},
  abstract = {We present a 3D matching framework based on a many-to-many matching
	algorithm that works with skeletal representations of 3D volumetric
	objects. We demonstrate the performance of this approach on a large
	database of 3D objects containing more than 1000 exemplars. The method
	is especially suited to matching objects with distinct part structure
	and is invariant to part articulation. Skeletal matching has an intuitive
	quality that helps in defining the search and visualizing the results.
	In particular, the matching algorithm produces a direct correspondence
	between two skeletons and their parts, which can be used for registration
	and juxtaposition.},
  doi = {10.1109/SMI.2005.1},
  file = {:./Cornea2005b/cornea2005b.pdf:PDF},
  keywords = { curve fitting, data visualisation, image matching, image registration,
	object recognition, very large databases 3D object retrieval, 3D
	volumetric objects, curve skeletons, large database, many-to-many
	matching, scientific visualization},
  owner = {apinzonf},
  timestamp = {2009.10.19}
}

@INPROCEEDINGS{Cornea2005a,
  author = {Cornea, N.D. and Silver, D. and Min, P.},
  title = {Curve-skeleton applications},
  booktitle = {Visualization, 2005. VIS 05. IEEE},
  year = {2005},
  pages = { 95-102},
  month = {Oct.},
  note = {Skeleton Extraction Survey},
  abstract = {Curve-skeletons are a 1D subset of the medial surface of a 3D object
	and are useful for many visualization tasks including virtual navigation,
	reduced-model formulation, visualization improvement, mesh repair,
	animation, etc. There are many algorithms in the literature describing
	extraction methodologies for different applications; however, it
	is unclear how general and robust they are. In this paper, we provide
	an overview of many curve-skeleton applications and compile a set
	of desired properties of such representations. We also give a taxonomy
	of methods and analyze the advantages and drawbacks of each class
	of algorithms.},
  doi = {10.1109/VISUAL.2005.1532783},
  file = {:./Cornea2005/vis05.pdf:PDF},
  keywords = { computational geometry, curve fitting, data visualisation, image
	representation, image thinning, set theory, solid modelling 1D subset,
	3D object, curve-skeleton applications, medial surface, visualization
	tasks},
  owner = {apinzonf},
  timestamp = {2009.10.19}
}

@ARTICLE{Cornea2007,
  author = {Cornea,, Nicu D. and Min,, Patrick},
  title = {Curve-Skeleton Properties, Applications, and Algorithms},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  year = {2007},
  volume = {13},
  pages = {530--548},
  number = {3},
  note = {Skeleton Extraction Survey Member-Silver,, Deborah},
  abstract = {Curve-skeletons are thinned 1D representations of 3D objects useful
	for many visualization tasks including virtual
	
	navigation, reduced-model formulation, visualization improvement,
	animation, etc. There are many algorithms in the literature
	
	describing extraction methodologies for different applications; however,
	it is unclear how general and robust they are. In this paper, we
	
	provide an overview of many curve-skeleton applications and compile
	a set of desired properties of such representations. We also give
	
	a taxonomy of methods and analyze the advantages and drawbacks of
	each class of algorithms},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/TVCG.2007.1002},
  file = {:./Cornea2007/Cornea2007.pdf:PDF},
  issn = {1077-2626},
  owner = {apinzonf},
  publisher = {IEEE Educational Activities Department},
  timestamp = {2009.04.28}
}

@ARTICLE{Cornea2005,
  author = {Cornea, Nicu D. and Silver, Deborah and Yuan, Xiaosong and Balasubramanian,
	Raman},
  title = {Computing hierarchical curve-skeletons of 3D objects},
  journal = {The Visual Computer},
  year = {2005},
  volume = {21},
  pages = {945--955},
  number = {11},
  month = oct,
  note = {Skeleton Extraction},
  abstract = {A curve-skeleton of a 3D object is a stick-like figure or centerline
	representation of that object. It is used for diverse applications,
	including virtual colonoscopy and animation. In this paper, we introduce
	the concept of hierarchical curve-skeletons and describe a general
	and robust methodology that computes a family of increasingly detailed
	curve-skeletons. The algorithm is based upon computing a repulsive
	force field over a discretization of the 3D object and using topological
	characteristics of the resulting vector field, such as critical points
	and critical curves, to extract the curve-skeleton. We demonstrate
	this method on many different types of 3D objects (volumetric, polygonal
	and scattered point sets) and discuss various extensions of this
	approach.},
  file = {:./Cornea2005/fulltext.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.03},
  url = {http://dx.doi.org/10.1007/s00371-005-0308-0}
}

@INPROCEEDINGS{Curless1996,
  author = {Curless,, Brian and Levoy,, Marc},
  title = {A volumetric method for building complex models from range images},
  booktitle = {SIGGRAPH '96: Proceedings of the 23rd annual conference on Computer
	graphics and interactive techniques},
  year = {1996},
  pages = {303--312},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {3D Reconstruction},
  abstract = {A number of techniques have been developed for reconstructing surfaces
	by integrating groups of aligned range images. A desirable set of
	properties for such algorithms includes: incremental updating, representation
	of directional uncertainty, the ability to fill gaps in the reconstruction,
	and robustness in the presence of outliers. Prior algorithms possess
	subsets of these properties. In this paper, we present a volumetric
	method for integrating range images that possesses all of these properties.
	
	
	Our volumetric representation consists of a cumulative weighted signed
	distance function. Working with one range image at a time, we first
	scan-convert it to a distance function, then combine this with the
	data already acquired using a simple additive scheme. To achieve
	space efficiency, we employ a run-length encoding of the volume.
	To achieve time efficiency, we resample the range image to align
	with the voxel grid and traverse the range and voxel scanlines synchronously.
	We generate the final manifold by extracting an isosurface from the
	volumetric grid. We show that under certain assumptions, this isosurface
	is optimal in the least squares sense. To fill gaps in the model,
	we tessellate over the boundaries between regions seen to be empty
	and regions never observed.
	
	
	Using this method, we are able to integrate a large number of range
	images (as many as 70) yielding seamless, high-detail models of up
	to 2.6 million triangles.},
  doi = {http://doi.acm.org/10.1145/237170.237269},
  file = {:./Curless1996/volrange.pdf:PDF},
  isbn = {0-89791-746-4},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Daubney2008,
  author = {Daubney, B. and Gibson, D. and Campbell, N.},
  title = {Real-time pose estimation of articulated objects using low-level
	motion},
  booktitle = CVPR08,
  year = {2008},
  pages = {1-8},
  note = {Motion Capture},
  abstract = {We present a method that is capable of tracking and estimating pose
	of articulated objects in real-time. This is achieved by using a
	bottom-up approach to detect instances of the object in each frame,
	these detections are then linked together using a high-level a priori
	motion model. Unlike other approaches that rely on appearance, our
	method is entirely dependent on motion; initial low-level part detection
	is based on how a region moves as opposed to its appearance. This
	work is best described as pictorial structures using motion. A sparse
	cloud of points extracted using a standard feature tracker are used
	as observational data, this data contains noise that is not Gaussian
	in nature but systematic due to tracking errors. Using a probabilistic
	framework we are able to overcome both corrupt and missing data whilst
	still inferring new poses from a generative model. Our approach requires
	no manual initialisation and we show results for a number of complex
	scenes and different classes of articulated object, this demonstrates
	both the robustness and versatility of the presented technique.},
  bibsource = {http://www.visionbib.com/bibliography/people923.html#TT84369},
  file = {:./Daubney2008/daubney2008.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{Deng2009,
  author = {Z. Deng and Q. Gu and Q. Li},
  title = {Perceptually Consistent Example-based Human Motion Retrieval},
  booktitle = {Proc. of ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
  year = {2009},
  pages = {191-198},
  month = {Feb},
  note = {Other},
  abstract = {Large amount of human motion capture data have been increasingly recorded
	and used in animation and gaming applications. Efficient retrieval
	of logically similar motions from a large data repository thereby
	serves as a fundamental basis for these motion data based applications.
	In this paper we present a perceptually consistent, example-based
	human motion retrieval approach that is capable of efficiently searching
	for and ranking similar motion sequences given a query motion input.
	Our method employs a motion pattern discovery and matching scheme
	that breaks human motions into a part-based, hierarchical motion
	representation. Building upon this representation, a fast string
	match algorithm is used for efficient runtime motion query processing.
	Finally, we conducted comparative user studies to evaluate the accuracy
	and perceptual-consistency of our approach by comparing it with the
	state of the art example-based human motion search algorithms.},
  file = {:./Deng2009/I3D09_motionretrieval_preprint.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Desbrun1999,
  author = {Desbrun,, Mathieu and Meyer,, Mark and Schr\"{o}der,, Peter and Barr,,
	Alan H.},
  title = {Implicit fairing of irregular meshes using diffusion and curvature
	flow},
  booktitle = {SIGGRAPH '99: Proceedings of the 26th annual conference on Computer
	graphics and interactive techniques},
  year = {1999},
  pages = {317--324},
  address = {New York, NY, USA},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  note = {Skeleton Extraction},
  abstract = {In this paper, we develop methods to rapidly remove rough features
	from irregularly triangulated data intended to portray a smooth surface.
	The main task is to remove undesirable noise and uneven edges while
	retaining desirable geometric features. The problem arises mainly
	when creating high-?delity computer graphics objects using imperfectly-measured
	data from the real world. Our approach contains three novel features:
	an implicit integration method to achieve ef?ciency, stability, and
	large time-steps; a scale-dependent Laplacian operator to improve
	the diffusion process; and ?nally, a robust curvature ?ow operator
	that achieves a smoothing of the shape itself, distinct from any
	parameterization. Additional features of the algorithm include automatic
	exact volume preservation, and hard and soft constraints on the positions
	of the points in the mesh. We compare our method to previous operators
	and related algorithms, and prove that our curvature and Laplacian
	operators have several mathematically-desirable qualities that improve
	the appearance of the resulting surface. In consequence, the user
	can easily select the appropriate operator according to the desired
	type of fairing. Finally, we provide a series of examples to graphically
	and numerically demonstrate the quality of our results},
  doi = {http://doi.acm.org/10.1145/311535.311576},
  file = {:./Desbrun1999/ImplicitFairing.pdf:PDF},
  isbn = {0-201-48560-5},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{Dey2006,
  author = {Dey,, Tamal K. and Sun,, Jian},
  title = {Defining and computing curve-skeletons with medial geodesic function},
  booktitle = {SGP '06: Proceedings of the fourth Eurographics symposium on Geometry
	processing},
  year = {2006},
  pages = {143--152},
  address = {Aire-la-Ville, Switzerland, Switzerland},
  publisher = {Eurographics Association},
  note = {Skeleton Extraction},
  abstract = {Many applications in geometric modeling, computer graphics, visualization
	and computer vision benet from a reduced representation called curve-skeletons
	of a shape. These are curves possibly with branches which compactly
	represent the shape geometry and topology. The lack of a proper mathematical
	denition has been a bottleneck in developing and applying the the
	curve-skeletons. A set of desirable properties of these skeletons
	has been identied and the existing algorithms try to satisfy these
	properties mainly through a procedural denition. We dene a function
	called medial geodesic on the medial axis which leads to a methematical
	denition and an approximation algorithm for curve-skeletons. Empirical
	study shows that the algorithm is robust against noise, operates
	well with a single user parameter , and produces curve-skeletons
	with the desirable properties. Moreover , the curve-skeletons can
	be associated with additional attributes that follow naturally from
	the denition. These attributes capture shape eccentricity, a local
	measure of how far a shape is away from a tubular one},
  file = {:./Dey2006/skeleton.pdf:PDF},
  isbn = {30905673-36-3},
  location = {Cagliari, Sardinia, Italy},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{Erol2005,
  author = {Erol, A. and Bebis, G. and Boyle, R.D. and Nicolescu, M.},
  title = {Visual Hull Construction Using Adaptive Sampling},
  booktitle = {computer vision},
  year = {2005},
  volume = {1},
  pages = {234-241},
  month = {Jan.},
  note = {3D Reconstruction},
  abstract = {Volumetric visual hulls have become very popular in many computer
	vision applications including human body pose estimation and virtualized
	reality. In these applications, the visual hull is used to approximate
	the 3D geometry of an object. Existing volumetric visual hull construction
	techniques, however, produce a 3-color volume data that merely serves
	as a bounding volume. In other words it lacks an accurate surface
	representation. Polygonization can produce satisfactory results only
	at high resolutions. In this study we extend the binary visual hull
	to an implicit surface in order to capture the geometry of the visual
	hull itself. In particular, we introduce an octree-based visual hull
	specific adaptive sampling algorithm to obtain a volumetric representation
	that provides accuracy proportional to the level of detail. Moreover,
	we propose a method to process the resulting octree to extract a
	crack-free polygonal visual hull surface. Experimental results illustrate
	the performance of the algorithm.},
  doi = {10.1109/ACVMOT.2005.123},
  file = {:./Erol2005/erol2005.pdf:PDF},
  journal = {Application of Computer Vision, 2005. WACV/MOTIONS '05 Volume 1.
	Seventh IEEE Workshops on},
  keywords = {computer vision, image representation, image sampling, image sequences,
	octrees, pose estimation, virtual realityadaptive sampling, computer
	vision, crack-free polygonal surface, human body pose estimation,
	octree-based visual hull, polygonization, surface representation,
	virtualized reality, visual hull construction},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Flagg2009,
  author = {Flagg,, Matthew and Nakazawa,, Atsushi and Zhang,, Qiushuang and
	Kang,, Sing Bing and Ryu,, Young Kee and Essa,, Irfan and Rehg,,
	James M.},
  title = {Human video textures},
  booktitle = {I3D '09: Proceedings of the 2009 symposium on Interactive 3D graphics
	and games},
  year = {2009},
  pages = {199--206},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Other},
  abstract = {This paper describes a data-driven approach for generating photorealistic
	animations of human motion. Each animation sequence follows a user-choreographed
	path and plays continuously by seamlessly transitioning between different
	segments of the captured data. To produce these animations, we capitalize
	on the complementary characteristics of motion capture data and video.
	We customize our capture system to record motion capture data that
	are synchronized with our video source. Candidate transition points
	in video clips are identified using a new similarity metric based
	on 3-D marker trajectories and their 2-D projections into video.
	Once the transitions have been identified, a video-based motion graph
	is constructed. We further exploit hybrid motion and video data to
	ensure that the transitions are seamless when generating animations.
	Motion capture marker projections serve as control points for segmentation
	of layers and nonrigid transformation of regions. This allows warping
	and blending to generate seamless in-between frames for animation.
	We show a series of choreographed animations of walks and martial
	arts scenes as validation of our approach.},
  doi = {http://doi.acm.org/10.1145/1507149.1507182},
  file = {:./Flagg2009/HVT.pdf:PDF},
  isbn = {978-1-60558-429-4},
  location = {Boston, Massachusetts},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@OTHER{Forbes2006,
  note = {3D Reconstruction},
  abstract = {Two planar mirrors are positioned to show five views of an object,
	and snapshots are captured from different viewpoints. We present
	closed form solutions for calculating the focal length, principal
	point, mirror and camera poses directly from the silhouette outlines
	of the object and its reflections. In the noisy case, these equations
	are used to form initial parameter estimates that are refined using
	iterative minimisation. The self-calibration allows the visual cones
	from each silhouette to be specified in a common reference frame
	so that the visual hull can be constructed. The proposed setup provides
	a simple method for creating 3D multimedia content that does not
	rely on specialised equipment. Experimental results demonstrate the
	reconstruction of a toy horse and a locust from real images. Synthetic
	images are used to quantify the sensitivity of the self-calibration
	to quantisation noise. In terms of the silhouette calibration ratio,
	degradation in silhouette quality has a greater effect on silhouette
	set consistency than computed calibration parameters.},
  author = {Forbes, Keith and Nicolls, Fred and de Jager, Gerhard and Voigt,
	Anthon},
  file = {:./Forbes2006/ForbesPosterEccv2006.pdf:PDF},
  journal = {Computer Vision â€“ ECCV 2006},
  owner = {apinzonf},
  pages = {165--178},
  timestamp = {2009.04.01},
  title = {Shape-from-Silhouette with Two Mirrors and an Uncalibrated Camera},
  url = {http://dx.doi.org/10.1007/11744047_13},
  year = {2006}
}

@ARTICLE{Franco2009,
  author = {Franco, J.-S. and Boyer, E.},
  title = {Efficient Polyhedral Modeling from Silhouettes},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {2009},
  volume = {31},
  pages = {414-427},
  number = {3},
  month = {March },
  note = {3D Reconstruction},
  abstract = {Modeling from silhouettes is a popular and useful topic in computer
	vision. Many methods exist to compute the surface of the visual hull
	from silhouettes, but few address the problem of ensuring good topological
	properties of the surface, such as manifoldness. This article provides
	an efficient algorithm to compute such a surface in the form of a
	polyhedral mesh. It relies on a small number of geometric operations
	to compute a visual hull polyhedron in a single pass. Such simplicity
	enables the algorithm to combine the advantages of being fast, producing
	pixel-exact surfaces, and repeatably yield manifold and watertight
	polyhedra in general experimental conditions with real data, as verified
	with all datasets tested. The algorithm is fully described, its complexity
	analyzed and modeling results given.},
  doi = {10.1109/TPAMI.2008.104},
  file = {:./Franco2009/franco2009.pdf:PDF},
  issn = {0162-8828},
  keywords = {computational complexity, computational geometry, computer vision,
	mesh generation, solid modelling, surface fittingcomputational complexity,
	computer vision, geometric operation, polyhedral mesh, silhouette
	polyhedral modeling, topological property, visual hull surface},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Franco2006,
  author = {Franco, J.-S. and Lapierre, M. and Boyer, E.},
  title = {Visual Shapes of Silhouette Sets},
  booktitle = {3D Data Processing},
  year = {2006},
  pages = {397-404},
  month = {June},
  note = {3D Reconstruction},
  abstract = {Shape from silhouette methods are extensively used to model dynamic
	and non-rigid objects using binary foreground-background images.
	Since the problem of reconstructing shapes from silhouettes is ambiguous,
	a number of solutions exist and several approaches only consider
	the one with a maximal volume, called the visual hull. However, the
	visual hull is not always a good approximation of shapes, in particular
	when observing smooth surfaces with few cameras. In this paper, we
	consider instead a class of solutions to the silhouette reconstruction
	problem that we call visual shapes. Such a class includes the visual
	hull, but also better approximations of the observed shapes which
	can take into account local assumptions such as smoothness, among
	others. Our contributions with respect to existing works is first
	to identify silhouette consistent shapes different from the visual
	hull, and second to give a practical way to estimate such shapes
	in real time. Experiments on various sets of data including human
	body silhouettes are shown to illustrate the principle and the interests
	of visual shapes.},
  doi = {10.1109/3DPVT.2006.148},
  file = {:./Franco2006/franco2006.pdf:PDF},
  journal = {3D Data Processing, Visualization, and Transmission, Third International
	Symposium on},
  keywords = {image reconstruction3D model, binary foreground-background image,
	image representation, image texture, shape reconstruction, silhouette
	method, silhouette reconstruction problem, visual hull, visual shapes},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Fujiwara1995,
  author = {Koji Fujiwara},
  title = {Eigenvalues of Laplacians on a closed riemannian manifold and its
	nets},
  booktitle = {AMS},
  year = {1995},
  volume = {123},
  number = {8},
  pages = {2585-2594},
  note = {Skeleton Extraction},
  abstract = {We study the relation betwen the eigenvalues of the Laplacian of a
	Riemannian manifold and the combinatorial Laplacians of an approximating
	sequence of nets in the manifold.},
  file = {:./Fujiwara1995/net.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{Fujiyoshi1998,
  author = {Hironobu Fujiyoshi and Alan J. Lipton},
  title = {Real-Time Human Motion Analysis By Image Skeletonization},
  booktitle = {In Proceedings of IEEE WACV98},
  year = {1998},
  pages = {15--21},
  note = {Motion Capture},
  abstract = {In this paper, a process is described for analysing the motion of
	a human target in a video stream. Moving targets are detected and
	their boundaries extracted. From these, a "star" skeleton is produced.
	Two motion cues are determined from this skeletonization: body posture,
	and cyclic motion of skeleton segments. These cues are used to determine
	human activities such as walking or running, and even potentially,
	the target's gait. Unlike other methods, this does not require an
	a priori human model, or a large number of "pixels on target". Furthermore,
	it is computationally inexpensive, and thus ideal for real-world
	video applications such as outdoor video surveillance.},
  file = {:./Fujiyoshi1998/wacv98_skeleton.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{Furukawa2008,
  author = {Furukawa, Y. and Ponce, J.},
  title = {Dense 3D motion capture from synchronized video streams},
  booktitle = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference
	on},
  year = {2008},
  pages = {1-8},
  month = {June},
  note = {3D Reconstruction},
  abstract = {This paper proposes a novel approach to non-rigid, markerless motion
	capture from synchronized video streams acquired by calibrated cameras.
	The instantaneous geometry of the observed scene is represented by
	a polyhedral mesh with fixed topology. The initial mesh is constructed
	in the first frame using the publicly available PMVS software for
	multi-view stereo [7]. Its deformation is captured by tracking its
	vertices over time, using two optimization processes at each frame:
	a local one using a rigid motion model in the neighborhood of each
	vertex, and a global one using a regularized nonrigid model for the
	whole mesh. Qualitative and quantitative experiments using seven
	real datasets show that our algorithm effectively handles complex
	nonrigid motions and severe occlusions.},
  doi = {10.1109/CVPR.2008.4587495},
  file = {:./Furukawa2008/Furukawa2008.PDF:PDF},
  issn = {1063-6919},
  keywords = {cameras, image motion analysis, stereo image processing, video streamingcomplex
	nonrigid motions, dense 3D motion capture, fixed topology, multiview
	stereo software, rigid motion model, video stream synchronization},
  owner = {apinzonf},
  timestamp = {2009.10.20}
}

@ARTICLE{Gagvani1999,
  author = {Nikhil Gagvani and Deborah Silver},
  title = {Parameter-Controlled Volume Thinning},
  journal = {Graphical Models and Image Processing},
  year = {1999},
  volume = {61},
  pages = {149 - 164},
  number = {3},
  note = {Other},
  abstract = {The availability of large 3D datasets has made volume thinning essential
	for compact representation of shapes. The density of the skeletal
	structure resulting from the thinning process depends on the application.
	Current thinning techniques do not allow control over the density
	and can therefore address only specific applications. In this paper,
	we describe an algorithm which uses a thinness parameter to control
	the thinning process and thus the density of the skeletal structure.
	We present applications from CFD and medical visualization and show
	how the skeletal structure can be used in these domains. We also
	illustrate a technique for constructing a centerline for surgical
	navigation.},
  doi = {DOI: 10.1006/gmip.1999.0495},
  file = {:./Gagvani1999/Gagvani1999.pdf:PDF},
  issn = {1077-3169},
  owner = {apinzonf},
  timestamp = {2009.10.19},
  url = {http://www.sciencedirect.com/science/article/B6WG4-45GMD54-B/2/7dd0819187eafc80d84ce0cc9d880a28}
}

@ARTICLE{Gavrila1999,
  author = {Gavrila,, D. M.},
  title = {The visual analysis of human movement: a survey},
  journal = {Comput. Vis. Image Underst.},
  year = {1999},
  volume = {73},
  pages = {82--98},
  number = {1},
  note = {Motion Capture Survey},
  abstract = {The ability to recognize humans and their activities by vision is
	key for a machine to interact intelligently and effortlessly with
	a human-inhabited environment. Because of many potentially important
	applications, “looking at people” is currently one of the most active
	application domains in computer vision. This survey identifies a
	number of promising applications and provides an overview of recent
	developments in this domain. The scope of this survey is limited
	to work on whole-body or hand motion; it does not include work on
	human faces. The emphasis is on discussing the various methodologies;
	they are grouped in 2-D approaches with or without explicit shape
	models and 3-D approaches. Where appropriate, systems are reviewed.
	We conclude with some thoughts about future directions.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1006/cviu.1998.0716},
  file = {:./Gavrila1999/sdarticle.pdf:PDF},
  issn = {1077-3142},
  owner = {apinzonf},
  publisher = {Elsevier Science Inc.},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{Gong2009,
  author = {Faming Gong and Cui Kang},
  title = {3D Mesh Skeleton Extraction Based on Feature Points},
  booktitle = {Computer Engineering and Technology},
  year = {2009},
  volume = {1},
  pages = {326-329},
  month = {Jan.},
  note = {Skeleton Extraction},
  abstract = {A novel efficient skeleton extraction algorithm is proposed, which
	is based on feature points extraction and Reeb graph theories. Because
	of the topological facility of feature points, a model can be divided
	into several branches according to them. One feature point can present
	one branch. So we just extract the other point of the branch - that
	could be skeleton point, connect these points with their corresponding
	feature points, then we can get all branch skeletons. Finally, connecting
	branch skeletons through connecting skeleton points according the
	topological relationship of each skeleton point preserving, then
	3D modelpsilas skeleton can be extracted.Without pre-processing stages
	and without input parameters, this algorithm can automatically extract
	the skeleton of 3D models. Theoretical analyses and experimental
	results show that our method has a lower computing complexity, and
	meets the requirement of extracting nice-looking and affine-invariant
	skeletons efficiently.},
  doi = {10.1109/ICCET.2009.71},
  file = {:./Gong2009/gong2009.pdf:PDF},
  journal = {Computer Engineering and Technology, 2009. ICCET '08. International
	Conference on},
  keywords = {computational complexity, feature extraction3D mesh skeleton extraction,
	Reeb graph theories, affine-invariant skeletons, computing complexity,
	feature points extraction},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@INPROCEEDINGS{Grauman2003,
  author = {Grauman, K. and Shakhnarovich, G. and Darrell, T.},
  title = {A Bayesian approach to image-based visual hull reconstruction},
  booktitle = {Computer Vision and Pattern Recognition},
  year = {2003},
  volume = {1},
  pages = { I-187-I-194 vol.1},
  month = {June},
  note = {3D Reconstruction},
  abstract = { We present a Bayesian approach to image-based visual hull reconstruction.
	The 3D (three-dimensional) shape of an object of a known class is
	represented by sets of silhouette views simultaneously observed from
	multiple cameras. We show how the use of a class-specific prior in
	a visual hull reconstruction can reduce the effect of segmentation
	errors from the silhouette extraction process. In our representation,
	3D information is implicit in the joint observations of multiple
	contours from known viewpoints. We model the prior density using
	a probabilistic principal components analysis-based technique and
	estimate a maximum a posteriori reconstruction of multi-view contours.
	The proposed method is applied to a dataset of pedestrian images,
	and improvements in the approximate 3D models under various noise
	conditions are shown.},
  doi = {10.1109/CVPR.2003.1211353},
  file = {:./Grauman2003/grauman2003.pdf:PDF},
  issn = {1063-6919 },
  journal = {Computer Vision and Pattern Recognition, 2003. Proceedings. 2003
	IEEE Computer Society Conference on},
  keywords = { Bayes methods, computer vision, edge detection, image denoising,
	image reconstruction, image representation, image segmentation, principal
	component analysis, stereo image processing 3D model, 3D object shape,
	Bayesian approach, image reconstruction, image representation, image
	segmentation, image-based visual hull reconstruction, maximum a posteriori
	reconstruction, multiple cameras, multiple contours, multiview contour,
	pedestrian image, probabilistic principal component analysis, silhouette
	extraction, silhouette view},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Guan2006,
  author = {Li Guan and Sinha, S. and Franco, J.-S. and Pollefeys, M.},
  title = {Visual Hull Construction in the Presence of Partial Occlusion},
  booktitle = {computational complexity},
  year = {2006},
  pages = {413-420},
  month = {June},
  note = {3D Reconstruction},
  abstract = {In this paper, we propose a visual hull algorithm, which guarantees
	a correct construction even in the presence of partial occlusion,
	while "correct" here means that the real shape is located inside
	the visual hull. The algorithm is based on a new idea of the "extended
	silhouette", which requires the silhouette from background subtraction
	and the "occlusion mask" of the same view. In order to prepare the
	occlusion mask, we also propose a novel concept of "effective boundary"
	of moving foreground objects in a video obtained from a static camera.
	The accumulation of the effective boundary through time automatically
	gives robust occluder boundaries. We theoretically prove that our
	algorithm deterministically computes the tightest, correct visual
	hull in the presence of occlusion. Both synthetic and real examples
	are given as a demonstration of the correctness of the algorithm.
	Finally we analyze that this new algorithm is still within the time
	complexity of the traditional method.},
  doi = {10.1109/3DPVT.2006.147},
  file = {:K\:\\personal\\maestria\\tesis\\estado_del_arte\\listado_inicial\\Guan2006\\guan2006.pdf:PDF},
  journal = {3D Data Processing, Visualization, and Transmission, Third International
	Symposium on},
  keywords = {computational complexity, image denoisingbackground subtraction, extended
	silhouette, occlusion mask, partial occlusion, time complexity, visual
	hull construction},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@ARTICLE{Gyulassy2007,
  author = {Gyulassy, A.G. and Duchaineau, M.A. and Vijay Natarajan and Pascucci,
	V. and Bringa, E.M. and Higginbotham, A. and Hamann, B.},
  title = {Topologically Clean Distance Fields},
  journal = {Visualization and Computer Graphics, IEEE Transactions on},
  year = {2007},
  volume = {13},
  pages = {1432-1439},
  number = {6},
  month = {Nov.-Dec. },
  note = {Skeleton Extraction},
  abstract = {Analysis of the results obtained from material simulations is important
	in the physical sciences. Our research was motivated by the need
	to investigate the properties of a simulated porous solid as it is
	hit by a projectile. This paper describes two techniques for the
	generation of distance fields containing a minimal number of topological
	features, and we use them to identify features of the material. We
	focus on distance fields defined on a volumetric domain considering
	the distance to a given surface embedded within the domain. Topological
	features of the field are characterized by its critical points. Our
	first method begins with a distance field that is computed using
	a standard approach, and simplifies this field using ideas from Morse
	theory. We present a procedure for identifying and extracting a feature
	set through analysis of the MS complex, and apply it to find the
	invariants in the clean distance field. Our second method proceeds
	by advancing a front, beginning at the surface, and locally controlling
	the creation of new critical points. We demonstrate the value of
	topologically clean distance fields for the analysis of filament
	structures in porous solids. Our methods produce a curved skeleton
	representation of the filaments that helps material scientists to
	perform a detailed qualitative and quantitative analysis of pores,
	and hence infer important material properties. Furthermore, we provide
	a set of criteria for finding the "difference" between two skeletal
	structures, and use this to examine how the structure of the porous
	solid changes over several timesteps in the simulation of the particle
	impact.},
  doi = {10.1109/TVCG.2007.70603},
  file = {:./Gyulassy2007/Gyulassy2007.pdf:PDF},
  issn = {1077-2626},
  keywords = {computational geometry, curve fitting, topologyMS complex, Morse theory,
	curved skeleton representation, filament structures, porous solids,
	simulated porous solid, topologically clean distance fields, volumetric
	domain},
  owner = {apinzonf},
  timestamp = {2009.10.19}
}

@INPROCEEDINGS{Hachet2005,
  author = {Hachet, Martin and Pouderoux, Joachim and Guitton, Pascal},
  title = {A Camera-Based Interface for Interaction with Mobile Handheld Computers},
  booktitle = {Proceedings of I3D'05 - ACM SIGGRAPH 2005 Symposium on Interactive
	3D Graphics and Games},
  year = {2005},
  pages = {65--71},
  publisher = {ACM Press},
  note = {Other},
  abstract = {Recent advances in mobile computing allow the users to deal with 3D
	interactive graphics on handheld computers. Although the computing
	resources and screen resolutions grow steadily, user interfaces for
	handheld computers do not change significantly. Consequently, we
	designed a new 3-DOF interface adapted to the characteristics of
	handheld computers. This interface tracks the movement of a target
	that the user holds behind the screen by analyzing the video stream
	of the handheld computer camera. The position of the target is directly
	inferred from the color-codes that are printed on it using an efficient
	algorithm. The users can easily interact in real-time in a mobile
	setting. The visualization of the data is good as the target does
	not occlude the screen and the interaction techniques are not dependent
	on the orientation of the handheld computer. We used the interface
	in several test applications for the visualization of large images
	such as maps, the manipulation of 3D models, and the navigation in
	3D scenes. This new interface favors the development of 2D and 3D
	interactive applications on handheld computers.},
  file = {:./Hachet2005/hachet_i3d.pdf:PDF},
  keywords = {User interfaces, Interaction, PDA},
  owner = {apinzonf},
  timestamp = {2009.03.18},
  url = {http://iparla.labri.fr/publications/2005/HPG05}
}

@OTHER{Hasinoff2006,
  note = {3D Reconstruction},
  abstract = {We present confocal stereo, a new method for computing 3D shape by
	controlling the focus and aperture of a lens. The method is specifically
	designed for reconstructing scenes with high geometric complexity
	or fine-scale texture. To achieve this, we introduce the confocal
	constancy property, which states that as the lens aperture varies,
	the pixel intensity of a visible in-focus scene point will vary in
	a scene-independent way, that can be predicted by prior radiometric
	lens calibration. The only requirement is that incoming radiance
	within the cone subtended by the largest aperture is nearly constant.
	First, we develop a detailed lens model that factors out the distortions
	in high resolution SLR cameras (12MP or more) with large-aperture
	lenses (e.g., f1.2). This allows us to assemble an A F aperture-focus
	image (AFI) for each pixel, that collects the undistorted measurements
	over all A apertures and F focus settings. In the AFI representation,
	confocal constancy reduces to color comparisons within regions of
	the AFI, and leads to focus metrics that can be evaluated separately
	for each pixel. We propose two such metrics and present initial reconstruction
	results for complex scenes.},
  author = {Hasinoff, Samuel and Kutulakos, Kiriakos},
  file = {:./Hasinoff2006/hasinoff-confocal-2006.pdf:PDF},
  journal = {Computer Vision â€“ ECCV 2006},
  owner = {apinzonf},
  pages = {620--634},
  timestamp = {2009.03.18},
  title = {Confocal Stereo},
  url = {http://dx.doi.org/10.1007/11744023_48},
  year = {2006}
}

@ARTICLE{1487512,
  author = {Hasinoff,, Samuel W. and Kutulakos,, Kiriakos N.},
  title = {Confocal Stereo},
  journal = {Int. J. Comput. Vision},
  year = {2009},
  volume = {81},
  pages = {82--104},
  number = {1},
  note = {3D Reconstruction},
  abstract = {We present confocal stereo, a new method for computing 3D shape by
	controlling the focus and aperture of a lens. The method is specifically
	designed for reconstructing scenes with high geometric complexity
	or fine-scale texture. To achieve this, we introduce the confocal
	constancy property, which states that as the lens aperture varies,
	the pixel intensity of a visible in-focus scene point will vary in
	a scene-independent way, that can be predicted by prior radiometric
	lens calibration. The only requirement is that incoming radiance
	within the cone subtended by the largest aperture is nearly constant.
	First, we develop a detailed lens model that factors out the distortions
	in high resolution SLR cameras (12MP or more) with large-aperture
	lenses (e.g., f1.2). This allows us to assemble an A×F aperture-focus
	image (AFI) for each pixel, that collects the undistorted measurements
	over all A apertures and F focus settings. In the AFI representation,
	confocal constancy reduces to color comparisons within regions of
	the AFI, and leads to focus metrics that can be evaluated separately
	for each pixel. We propose two such metrics and present initial reconstruction
	results for complex scenes, as well as for a scene with known ground-truth
	shape.},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1007/s11263-008-0164-2},
  file = {:./Hasinoff2006/hasinoff-confocal-draft-2008.pdf:PDF},
  issn = {0920-5691},
  owner = {apinzonf},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{Hassouna2007,
  author = {Hassouna, M.S. and Farag, A.A.},
  title = {On the Extraction of Curve Skeletons using Gradient Vector Flow},
  booktitle = {Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference
	on},
  year = {2007},
  pages = {1-8},
  month = {Oct.},
  note = {Skeleton Extraction},
  abstract = {In this paper, we propose a new variational framework for computing
	continuous curve skeletons from discrete objects that are suitable
	for structural shape representation. We have derived a new energy
	function, which is proportional to some medialness function, such
	that the minimum cost path between any two medial voxels in the shape
	is a curve skeleton. We have employed two different medialness functions;
	the Euclidean distance field and a variant of the magnitude of the
	gradient vector flow (GVF), resulting in two different energy functions.
	The first energy controls the identification of the shape topological
	nodes from which curve skeletons start, while the second one controls
	the extraction of curve skeletons. The accuracy and robustness of
	the proposed framework are validated both quantitatively and qualitatively
	against competing techniques as well as several 3D shapes of different
	complexity.},
  doi = {10.1109/ICCV.2007.4409112},
  file = {:./Hassouna2007/Hassouna_Farag_ICCV_2007.pdf:PDF},
  issn = {1550-5499},
  keywords = {computational complexity, feature extraction, image processingEuclidean
	distance field, curve skeletons extraction, discrete objects, energy
	function, energy functions, gradient vector flow, medialness function,
	shape topological nodes},
  owner = {apinzonf},
  timestamp = {2009.10.19}
}

@INPROCEEDINGS{Hassouna2005,
  author = {Hassouna, M.S. and Farag, A.A.},
  title = {Robust skeletonization using the fast marching method},
  booktitle = {Image Processing, 2005. ICIP 2005. IEEE International Conference
	on},
  year = {2005},
  volume = {1},
  pages = { I-437-40},
  month = {Sept.},
  note = {Skeleton Extraction},
  abstract = { We have recently developed a level set based-framework for computing
	medial curves or curve skeletons CS for arbitrary 2D shapes as well
	as tubular and articulated 3D objects. The proposed framework is
	robust, fully automatic, computationally efficient, and produces
	curve skeletons that are connected, centered, thin, and less sensitive
	to boundary noise. In this paper, we introduce two improvements to
	the framework in order to enhance its performance in terms of stability
	and topology preserving.},
  doi = {10.1109/ICIP.2005.1529781},
  file = {:./Hassouna2005/Hassouna2005.pdf:PDF},
  keywords = { signal processing curve skeletons, fast marching method, skeletonization},
  owner = {apinzonf},
  timestamp = {2009.10.19}
}

@ARTICLE{Hassouna2009,
  author = {M. Sabry Hassouna and Aly A. Farag},
  title = {Variational Curve Skeletons Using Gradient Vector Flow},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {2009},
  volume = {31},
  pages = {2257-2274},
  number = {12},
  note = {Skeleton Extraction},
  abstract = {Representing a 3D shape by a set of 1D curves that are locally symmetric
	with respect to its boundary (i.e., curve skeletons) is of importance
	in several machine intelligence tasks. This paper presents a fast,
	automatic, and robust variational framework for computing continuous,
	subvoxel accurate curve skeletons from volumetric objects. A reference
	point inside the object is considered a point source that transmits
	two wave fronts of different energies. The first front (\beta-front)
	converts the object into a graph, from which the object salient topological
	nodes are determined. Curve skeletons are tracked from these nodes
	along the cost field constructed by the second front (\alpha-front)
	until the point source is reached. The accuracy and robustness of
	the proposed work are validated against competing techniques as well
	as a database of 3D objects. Unlike other state-of-the-art techniques,
	the proposed framework is highly robust because it avoids locating
	and classifying skeletal junction nodes, employs a new energy that
	does not form medial surfaces, and finally extracts curve skeletons
	that correspond to the most prominent parts of the shape and hence
	are less sensitive to noise.},
  address = {Los Alamitos, CA, USA},
  doi = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2008.271},
  file = {:./Hassouna2009/TPAMI-2008-02-0089.R1.pdf:PDF},
  issn = {0162-8828},
  owner = {apinzonf},
  publisher = {IEEE Computer Society},
  timestamp = {2009.10.19}
}

@INPROCEEDINGS{Hassouna2005a,
  author = {Hassouna, M. Sabry and Farag, Aly A.},
  title = {Robust Centerline Extraction Framework Using Level Sets},
  booktitle = {CVPR '05: Proceedings of the 2005 IEEE Computer Society Conference
	on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1},
  year = {2005},
  pages = {458--465},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  note = {Skeleton Extraction},
  abstract = {In this paper, we present a novel framework for computing centerlines
	for both 2D and 3D shape analysis. The framework works as follows:
	an object centerline point is selected automatically as the point
	of global maximum Euclidean distance from the boundary, and is considered
	a point source (PS) that transmits a wave front that evolves over
	time and traverses the object domain. The front propagates at each
	object point with a speed that is proportional to its Euclidean distance
	from the boundary. The motion of the front is governed by a nonlinear
	partial differential equation whose solution is computed efficiently
	using level set methods. Initially, the PS transmits a moderate speed
	wave to explore the object domain and extract its topological information
	such as merging and extreme points. Then, it transmits a new front
	that is much faster at centerline points than non central ones. As
	a consequence, centerlines intersect the propagating fronts at those
	points of maximum positive curvature. Centerlines are computed by
	tracking them, starting from each topological point until the PS
	is reached, by solving an ordinary differential equation using an
	efficient numerical scheme. The proposed method is computationally
	inexpensive, handles efficiently objects with complex topology, and
	computes centerlines that are centered, connected, one point thick,
	and less sensitive to boundary noise. In addition, the extracted
	paths form a tree graph without additional cost. We have extensively
	validated the robustness of the proposed method both quantitatively
	and qualitatively against several 2D and 3D shapes.},
  doi = {http://dx.doi.org/10.1109/CVPR.2005.306},
  file = {:./Hassouna2005a/Centerline_CVPR_2005.pdf:PDF},
  isbn = {0-7695-2372-2},
  owner = {apinzonf},
  timestamp = {2009.10.19}
}

@INPROCEEDINGS{Hemayed2003,
  author = {Hemayed, E.E.},
  title = {A survey of camera self-calibration},
  booktitle = {Proceedings. IEEE Conference on Advanced Video and Signal Based Surveillance,
	2003.},
  year = {2003},
  pages = { 351-357},
  month = {July},
  note = {Camera Calibration Survey},
  abstract = {The paper surveys the developments of the last 10 years in the area
	of camera self-calibration. Self-calibration is an attempt to calibrate
	camera by finding intrinsic parameters that are consistent with the
	underlying projective geometry of a sequence of images. In order
	to solve this problem, the camera intrinsic constraints have been
	used separately and in conjunction with camera motion constraints
	or scene constraints. Most self-calibration algorithms are concerned
	with unknown but constant intrinsic camera parameters. Recently,
	camera self-calibration in the case of varying intrinsic camera parameters
	was also studied. We present the basic theories behind the different
	self-calibration techniques and discuss the ideas behind most of
	the self-calibration algorithms.},
  doi = {10.1109/AVSS.2003.1217942},
  file = {:./Hemayed2003/Hemayed2003.pdf:PDF},
  issn = { },
  keywords = { calibration, cameras, computer vision, geometrical optics, image
	motion analysis, image sequences camera intrinsic constraints, camera
	motion constraints, camera parameters, camera self-calibration, computer
	vision, image sequence, intrinsic parameters, projective geometry,
	scene constraints},
  owner = {apinzonf},
  timestamp = {2009.10.20}
}

@INPROCEEDINGS{HernandezEsteban2002,
  author = {Hernandez Esteban, C. and Schmitt, F.},
  title = {Multi-stereo 3D object reconstruction},
  booktitle = {3D Data Processing Visualization and Transmission},
  year = {2002},
  pages = { 159-166},
  note = {3D Reconstruction},
  abstract = {We present a method for the reconstruction of a 3D real object from
	a sequence of high-definition images. We combine two different procedures:
	a shape from silhouette technique which provides a coarse 3D initial
	model followed by a multi-stereo carving technique. We propose a
	fast but accurate method for the estimation of the carving depth
	at each vertex of the 3D mesh. The quality of the final textured
	3D reconstruction models allows us to validate the method.},
  doi = {10.1109/TDPVT.2002.1024055},
  file = {:./HernandezEsteban2002/he2002.pdf:PDF},
  journal = {3D Data Processing Visualization and Transmission, 2002. Proceedings.
	First International Symposium on},
  keywords = { computer graphics, image reconstruction, image resolution, image
	sequences, image texture, mesh generation, robot vision, stereo image
	processing 3D mesh vertex, 3D object reconstruction, 3D real object,
	carving depth estimation, coarse initial model, computer graphics,
	high-definition image sequence, multi-stereo carving, robot vision,
	shape from silhouette technique, textured 3D reconstruction models},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@ARTICLE{Holroyd2008,
  author = {Michael Holroyd and Jason Lawrence and Greg Humphreys and Todd Zickler},
  title = {A Photometric Approach for Estimating Normals and Tangents},
  journal = {ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2008)},
  year = {2008},
  volume = {27},
  pages = {133},
  number = {5},
  note = {Photometric Stereo},
  abstract = {This paper presents a novel technique for acquiring the shape of real-world
	objects with complex isotropic and anisotropic reflectance. Our method
	estimates the local normal and tangent vectors at each pixel in a
	reference view from a sequence of images taken under varying point
	lighting. We show that for many real-world materials and a restricted
	set of light positions, the 2D slice of the BRDF obtained by fixing
	the local view direction is symmetric under reflections of the halfway
	vector across the normal-tangent and normal-binormal planes. Based
	on this analysis, we develop an optimization that estimates the local
	surface frame by identifying these planes of symmetry in the measured
	BRDF. As with other photometric methods, a key benefit of our approach
	is that the input is easy to acquire and is less sensitive to calibration
	errors than stereo or multi-view techniques. Unlike prior work, our
	approach allows estimating the surface tangent in the case of anisotropic
	reflectance. We confirm the accuracy and reliability of our approach
	with analytic and measured data, present several normal and tangent
	fields acquired with our technique, and demonstrate applications
	to image relighting and appearance editing.},
  doi = {http://doi.acm.org/10.1145/1409060.1409086},
  file = {:./Holroyd2008/Holroyd08.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Hoppe1996,
  author = {Hoppe,, Hugues},
  title = {Progressive meshes},
  booktitle = {SIGGRAPH '96: Proceedings of the 23rd annual conference on Computer
	graphics and interactive techniques},
  year = {1996},
  pages = {99--108},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Other},
  abstract = {Highly detailed geometric models are rapidly becoming commonplace
	in computer graphics. These models, often represented as complex
	triangle meshes, challenge rendering performance, transmission bandwidth,
	and storage capacities. This paper introduces the progressive mesh
	(PM) representation, a new scheme for storing and transmitting arbitrary
	triangle meshes. This efficient, lossless, continuous-resolution
	representation addresses several practical problems in graphics:
	smooth geomorphing of level-of-detail approximations, progressive
	transmission, mesh compression, and selective refinement.
	
	In addition, we present a new mesh simplification procedure for constructing
	a PM representation from an arbitrary mesh. The goal of this optimization
	procedure is to preserve not just the geometry of the original mesh,
	but more importantly its overall appearance as defined by its discrete
	and scalar appearance attributes such as material identifiers, color
	values, normals, and texture coordinates. We demonstrate construction
	of the PM representation and its applications using several practical
	models.},
  doi = {http://doi.acm.org/10.1145/237170.237216},
  file = {:./Hoppe1996/pm.pdf:PDF},
  isbn = {0-89791-746-4},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Hou2007,
  author = {Shaobo Hou and Galata, A. and Caillette, F. and Thacker, N. and Bromiley,
	P.},
  title = {Real-time Body Tracking Using a Gaussian Process Latent Variable
	Model},
  booktitle = {IEEE Internat. Conf. on Computer Vision},
  year = {2007},
  pages = {1-8},
  month = {Oct.},
  note = {Motion Capture},
  abstract = {In this paper, we present a tracking framework for capturing articulated
	human motions in real-time, without the need for attaching markers
	onto the subject's body. This is achieved by first obtaining a low
	dimensional representation of the training motion data, using a nonlinear
	dimensionality reduction technique called back-constrained GPLVM.
	A prior dynamics model is then learnt from this low dimensional representation
	by partitioning the motion sequences into elementary movements using
	an unsupervised EM clustering algorithm. The temporal dependencies
	between these elementary movements are efficiently captured by a
	Variable Length Markov Model. The learnt dynamics model is used to
	bias the propagation of candidate pose feature vectors in the low
	dimensional space. By combining this with an efficient volumetric
	reconstruction algorithm, our framework can quickly evaluate each
	candidate pose against image evidence captured from multiple views.
	We present results that show our system can accurately track complex
	structured activities such as ballet dancing in real-time.},
  doi = {10.1109/ICCV.2007.4408946},
  file = {:./Hou2007/iccv2007tracking.pdf:PDF},
  issn = {1550-5499},
  journal = {Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference
	on},
  keywords = {Gaussian processes, Markov processes, image motion analysis, image
	reconstruction, image sequences, pattern clusteringGaussian process
	latent variable model, backconstrained GPLVM, human motions, low
	dimensional representation, motion sequences, nonlinear dimensionality
	reduction technique, pose feature vectors, real-time body tracking,
	training motion data, unsupervised EM clustering algorithm, variable
	length Markov model, volumetric reconstruction algorithm},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{Ishikawa2005,
  author = {Ishikawa, T. and Yamazawa, K. and Yokoya, N.},
  title = {Real-time generation of novel views of a dynamic scene using morphing
	and visual hull},
  booktitle = {Image Processing},
  year = {2005},
  volume = {1},
  pages = { I-1013-16},
  month = {Sept.},
  note = {Motion Capture},
  abstract = {Recently, generation of novel views from images acquired by multiple
	cameras has been investigated. It can be applied to telepresence
	effectively. Most conventional methods need some assumptions about
	the scene such as a static scene and limited positions of objects.
	In this paper, we propose a new method for generating novel view
	images of a dynamic scene with a wide view, which does not depend
	on the scene. The images acquired from omni-directional cameras are
	first divided into static regions and dynamic regions. The novel
	view images are then generated by applying a morphing technique to
	static regions and by computing visual hulls for dynamic regions
	in real-time. In experiments, we show that a prototype system can
	generate novel view images in real-time from live video streams.},
  doi = {10.1109/ICIP.2005.1529925},
  file = {:./Ishikawa2005/Ishikawa2005.pdf:PDF},
  journal = {Image Processing, 2005. ICIP 2005. IEEE International Conference
	on},
  keywords = { cameras, image processing, video streaming dynamic scene, morphing
	technique, omnidirectional cameras, video streams, view images, visual
	hull},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Jia2008,
  author = {Li Jia and Miao Zhenjiang and Wan Chengkai},
  title = {Markerless human body motion capture using multiple cameras},
  booktitle = {Signal Processing},
  year = {2008},
  pages = {1469-1474},
  month = {Oct.},
  note = {3D Reconstruction},
  abstract = {In this paper, we present an approach for markerless model-based full
	human-body motion capture using multi-view images as input. We extract
	volume data (voxels) representation from the silhouettes extracted
	from multiple-view video images by the method of shape from Silhouettes
	(SFS), and match our predefined human body model to the volume data.
	We construct an energy field in the volume of interest based on the
	volume data and human body model with pose parameters, and transform
	the matching to an energy minimizing problem. By dynamic graph cut,
	we get the minimum energy of certain pose parameters, and at last
	we optimize the pose parameters using Powell algorithm with a novel
	approach that uses the linear prediction guiding the optimization
	process and get the pose recovered. Through the test results on several
	video sequences of human body movements in an unaugmented office
	environment, we demonstrate the effectiveness and robustness of our
	approach.},
  doi = {10.1109/ICOSP.2008.4697410},
  file = {:./Jia2008/jia2008.pdf:PDF},
  journal = {Signal Processing, 2008. ICSP 2008. 9th International Conference
	on},
  keywords = {cameras, image motion analysis, image sequences, optimisationPowell
	algorithm, dynamic graph cut, linear prediction, markerless human
	body motion, multiple cameras, multiple-view video images, optimization
	process, pose parameter, unaugmented office environment, video sequences,
	volume data representation},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Jin2007,
  author = {Ning Jin and Mokhtarian, F.},
  title = {Image-based shape model for view-invariant human motion recognition},
  booktitle = {Advanced Video and Signal Based Surveillance},
  year = {2007},
  pages = {336-341},
  month = {Sept.},
  note = {3D Reconstruction},
  abstract = {We propose an image-based shape model for view-invariant human motion
	recognition. Image-based visual hull explicitly represents the 3D
	shape of an object, which is computed from a set of silhouettes.
	We then use the set of silhouettes to implicitly represent the visual
	hull. Due to the fact that a silhouette is the 2D projection of an
	object in the 3D world with respect to a certain camera, which is
	sensitive to the point of view, our multi-silhouette representation
	for the visual hull entails the correspondence between views. To
	guarantee the correspondence, we define a canonical multi-camera
	system and a canonical human body orientation in motions. We then
	"normalize" all the constructed visual hulls into the canonical multi-camera
	system, align them to follow the canonical orientation, and finally
	render them. The rendered views thereby satisfy the requirement of
	the correspondence. In our visual hull's representation, each silhouette
	is represented as a fixed number of sampled points on its closed
	contour, therefore, the 3D shape information is implicitly encoded
	into the concatenation of multiple 2D contours. Each motion class
	is then learned by a Hidden Markov Model (HMM) with mixture of Gaussians
	outputs. Experiments using our algorithm over some data sets give
	encouraging results.},
  doi = {10.1109/AVSS.2007.4425333},
  file = {:./Jin2007/jin2007.pdf:PDF},
  journal = {Advanced Video and Signal Based Surveillance, 2007. AVSS 2007. IEEE
	Conference on},
  keywords = {Gaussian processes, cameras, hidden Markov models, image motion analysis,
	image representation, rendering (computer graphics)3D shape information,
	Gaussian process, canonical human body orientation, canonical multi
	camera system, hidden Markov model, image-based shape model, image-based
	visual hull representation, multi silhouette representation, view-invariant
	human motion recognition},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Kampel2002,
  author = {Kampel, M. and Tosovic, S. and Sablatnig, R.},
  title = {Octree-based fusion of shape from silhouette and shape from structured
	light},
  booktitle = {3D Data Processing Visualization and Transmission, 2002. Proceedings.
	First International Symposium on},
  year = {2002},
  pages = { 754-757},
  note = {3D Reconstruction},
  abstract = { An algorithm for the automatic construction of a 3d model of archaeological
	vessels using two different 3d algorithms is presented. In archeology
	the determination of the exact volume of arbitrary vessels is of
	importance since this provides information about the manufacturer
	and the usage of the vessel. To acquire the 3d shape of objects with
	handles is complicated, since occlusions of the object's surface
	are introduced by the handle and can only be resolved by taking multiple
	views. Therefore, the 3d reconstruction is based on a sequence of
	images of the object taken from different viewpoints with different
	algorithms; shape from silhouette and shape from structured light.
	The output of both algorithms are then used to construct a single
	3d model. Results of the algorithm developed are presented for both
	synthetic and real input images.},
  doi = {10.1109/TDPVT.2002.1024154},
  file = {:./Kampel2002/IEEEXplore.pdf:PDF},
  journal = {3D Data Processing Visualization and Transmission, 2002. Proceedings.
	First International Symposium on},
  keywords = { archaeology, octrees, sensor fusion, virtual reality arbitrary vessels,
	archaeological vessels, automatic construction, images sequences,
	octree-based fusion, real input images, shape from silhouette, shape
	from structured light, synthetic images},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Katz2003,
  author = {Katz,, Sagi and Tal,, Ayellet},
  title = {Hierarchical mesh decomposition using fuzzy clustering and cuts},
  booktitle = {SIGGRAPH '03: ACM SIGGRAPH 2003 Papers},
  year = {2003},
  pages = {954--961},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Skeleton Extraction},
  abstract = {Cutting up a complex object into simpler sub-objects is a fundamental
	problem in various disciplines. In image processing, images are segmented
	while in computational geometry, solid polyhedra are decomposed.
	In recent years, in computer graphics, polygonal meshes are decomposed
	into sub-meshes. In this paper we propose a novel hierarchical mesh
	decomposition algorithm. Our algorithm computes a decomposition into
	the meaningful components of a given mesh, which generally refers
	to segmentation at regions of deep concavities. The algorithm also
	avoids over-segmentation and jaggy boundaries between the components.
	Finally, we demonstrate the utility of the algorithm in control-skeleton
	extraction.},
  doi = {http://doi.acm.org/10.1145/1201775.882369},
  file = {:./Katz2003/0325_ayt.pdf:PDF},
  isbn = {1-58113-709-5},
  location = {San Diego, California},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@INPROCEEDINGS{Khan2008,
  author = {Khan, S.M. and Shah, M.},
  title = {Reconstructing non-stationary articulated objects in monocular video
	using silhouette information},
  booktitle = {Computer Vision and Pattern Recognition},
  year = {2008},
  pages = {1-8},
  month = {June},
  note = {3D Reconstruction},
  abstract = {This paper presents an approach to reconstruct non-stationary, articulated
	objects from silhouettes obtained with a monocular video sequence.
	We introduce the concept of motion blurred scene occupancies, a direct
	analogy of motion blurred images but in a 3D object scene occupancy
	space resulting from the motion/deformation of the object. Our approach
	starts with an image based fusion step that combines color and silhouette
	information from multiple views. To this end we propose to use a
	novel construct: the temporal occupancy point (TOP), which is the
	estimated 3D scene location of a silhouette pixel and contains information
	about duration of time it is occupied. Instead of explicitly computing
	the TOP in 3D space we directly obtain itpsilas imaged(projected)
	locations in each view. This enables us to handle monocular video
	and arbitrary camera motion in scenarios where complete camera calibration
	information may not be available. The result is a set of blurred
	scene occupancy images in the corresponding views, where the values
	at each pixel correspond to the fraction of total time duration that
	the pixel observed an occupied scene location. We then use a motion
	de-blurring approach to de-blur the occupancy images. The de-blurred
	occupancy images correspond to a silhouettes of the mean/motion compensated
	object shape and are used to obtain a visual hull reconstruction
	of the object. We show promising results on challenging monocular
	datasets of deforming objects where traditional visual hull intersection
	approaches fail to reconstruct the object correctly.},
  doi = {10.1109/CVPR.2008.4587700},
  file = {:./Khan2008/Khan2008.pdf:PDF},
  issn = {1063-6919},
  journal = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference
	on},
  keywords = {image motion analysis, image restoration, image sequences3D object
	scene occupancy space, 3D scene location, camera motion, image based
	fusion step, monocular video sequence, motion blurred images, motion
	blurred scene occupancies, motion deblurring, nonstationary articulated
	object reconstruction, silhouette information, silhouette pixel,
	temporal occupancy point},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Kry2009,
  author = {Paul Kry and Lionel Rev\'eret and Fran\c{c}ois Faure and Marie-Paule
	Cani},
  title = {Modal locomotion: animating virtual characters with natural vibrations},
  booktitle = {Eurographics, , 2009},
  year = {2009},
  address = {France},
  note = {Animation 3D},
  abstract = {We present a general method to intuitively create a wide range of
	locomotion controllers for 3D legged characters. The key of our approach
	is the assumption that efficient locomotion can exploit the natural
	vibration modes of the body, where these modes are related to morphological
	parameters such as the shape, size, mass, and joint stiffness. The
	vibration modes are computed for a mechanical model of any 3D character
	with rigid bones, elastic joints, and additional constraints as desired.
	A small number of vibration modes can be selected with respect to
	their relevance to locomotion patterns and combined into a compact
	controller driven by very few parameters. We show that these controllers
	can be used in dynamic simulations of simple creatures, and for kinematic
	animations of more complex creatures of a variety of shapes and sizes.},
  file = {:./Kry2009/mleg.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@PHDTHESIS{KryPhd05,
  author = {Paul G. Kry},
  title = {Interaction Capture and Synthesis of Human Hands},
  school = {University of British Columbia},
  year = {2005},
  note = {Motion Capture},
  abstract = {This thesis addresses several issues in modelling interaction with
	human hands in computer graphics and animation. Modifying motion
	capture to satisfy the constraints of new animation is difficult
	when contact is involved because physical interaction involves energy
	or power transfer between the system of interest and the environment,
	and is a critical problem for computer animation of hands. Although
	contact force measurements provide a means of monitoring this transfer,
	motion capture as currently used for creating animation has largely
	ignored contact forces. We present a system of capturing synchronized
	motion and contact forces, called interaction capture. We transform
	interactions such as grasping into joint compliances and a nominal
	reference trajectory in an approach inspired by the equilibrium point
	hypothesis of human motor control. New interactions are synthesized
	through simulation of a quasi-static compliant articulated model
	in a dynamic environment that includes friction. This uses a novel
	position-based linear complementarity problem formulation that includes
	friction, breaking contact, and coupled compliance between contacts
	at different fingers. We present methods for reliable interaction
	capture, addressing calibration, force estimation, and synchronization.
	Additionally, although joint compliances are traditionally estimated
	with perturbation-based methods, we introduce a technique that instead
	produces estimates without perturbation. We validate our results
	with data from previous work and our own perturbation-based estimates.
	A complementary goal of this work is hand-based interaction in virtual
	environments. We present techniques for whole-hand interaction using
	the Tango, a novel sensor that performs interaction capture by measuring
	pressure images and accelerations. We approximate grasp hand-shapes
	from previously observed data through rotationally invariant comparison
	of pressure measurements. We also introduce methods involving heuristics
	and thresholds that make reliable drift-free navigation possible
	with the Tango. Lastly, rendering the skin deformations of articulated
	characters is a fundamental problem for computer animation of hands.
	We present a deformation model, called EigenSkin, which provides
	a means of rendering physically- or example-based deformation models
	at interactive rates on graphics hardware.},
  file = {:./KryPhd05/thesis.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@ARTICLE{Kry2006,
  author = {Paul G. Kry and Dinesh K. Pai},
  title = {Interaction capture and synthesis},
  journal = {ACM Trans. Graph.},
  year = {2006},
  volume = {25},
  pages = {872--880},
  number = {3},
  note = {Motion Capture},
  abstract = {Modifying motion capture to satisfy the constraints of new animation
	is difficult when contact is involved, and a critical problem for
	animation of hands. The compliance with which a character makes contact
	also reveals important aspects of the movement’s purpose. We present
	a new technique called interaction capture, for capturing these contact
	phenomena. We capture contact forces at the same time as motion,
	at a high rate, and use both to estimate a nominal reference trajectory
	and joint compliance. Unlike traditional methods, our method estimates
	joint compliance without the need for motorized perturbation devices.
	New interactions can then be synthesized by physically based simulation.
	We describe a novel position-based linear complementarity problem
	formulation that includes friction, breaking contact, and the compliant
	coupling between contacts at different fingers. The technique is
	validated using data from previous work and our own perturbation-based
	estimates.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1141911.1141969},
  file = {:./Kry2006/ics-preprint.pdf:PDF},
  issn = {0730-0301},
  owner = {apinzonf},
  publisher = {ACM Press},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Ladikos2008,
  author = {Ladikos, A. and Benhimane, S. and Navab, N.},
  title = {Efficient visual hull computation for real-time 3D reconstruction
	using CUDA},
  booktitle = {Computer Vision and Pattern Recognition Workshops},
  year = {2008},
  pages = {1-8},
  month = {June},
  note = {3D Reconstruction},
  abstract = {In this paper we present two efficient GPU-based visual hull computation
	algorithms. We compare them in terms of performance using image sets
	of varying size and different voxel resolutions. In addition, we
	present a real-time 3D reconstruction system which uses the proposed
	GPU-based reconstruction method to achieve real-time performance
	(30 fps) using 16 cameras and 4 PCs.},
  doi = {10.1109/CVPRW.2008.4563098},
  file = {:./Ladikos2008/ladikos2008.pdf:PDF},
  journal = {Computer Vision and Pattern Recognition Workshops, 2008. CVPRW '08.
	IEEE Computer Society Conference on},
  keywords = {computational geometry, image reconstruction, image resolutionCUDA,
	GPU, image sets, real-time 3D reconstruction, real-time performance,
	visual hull computation, voxel resolutions},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Landabaso2008,
  author = {Landabaso, J.-L. and Lizcano, L. and Pardas, M.},
  title = {Shape from inconsistent silhouette for free viewpoint video},
  booktitle = {Image Processing},
  year = {2008},
  pages = {213-216},
  month = {Oct.},
  note = {3D Reconstruction},
  abstract = {In this paper we present an efficient image-based rendering algorithm
	that obtains novel images from a set of views of the scene of interest.
	The approach described uses silhouette image data to compute the
	Visual Hull, the largest volume that is compatible with the silhouettes
	that delimit the objects of interest. Since the Visual Hull is not
	explicitly computed, this approach does not suffer from the quantization
	artifacts of volumetric approaches. In contrast to previous works,
	we explore how detection errors in the silhouettes affect the novel
	rendered view and propose a method to detect errors in the original
	silhouettes based on the consistency principle that states that the
	projection of the Visual Hull should exactly correspond with original
	silhouettes.},
  doi = {10.1109/ICIP.2008.4711729},
  file = {:./Landabaso2008/landabaso2008.pdf:PDF},
  issn = {1522-4880},
  journal = {Image Processing, 2008. ICIP 2008. 15th IEEE International Conference
	on},
  keywords = {rendering (computer graphics), video signal processingerror detection,
	free viewpoint video, image-based rendering algorithm, immersive
	videoconferencing system, inconsistent silhouette image, quantization
	artifacts, silhouette image data, visual hull},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@ARTICLE{Lanman2008,
  author = {Douglas Lanman and Ramesh Raskar and Amit Agrawal and Gabriel Taubin},
  title = {Shield Fields: Modeling and Capturing 3D Occluders},
  journal = {ACM Transactions on Graphics (Proc. SIGGRAPH Asia)},
  year = {2008},
  volume = {27},
  pages = {10},
  number = {5},
  note = {Other},
  abstract = {We describe a unified representation of occluders in light transport
	and photography using shield fields: the 4D attenuation function
	which acts on any light field incident on an occluder. Our key theoretical
	result is that shield fields can be used to decouple the effects
	of occluders from the incident illumination. We first describe the
	properties of shield fields in the frequency-domain and briefly analyze
	the “forward” problem of efficiently computing cast shadows. Afterwards,
	we apply the shield field signal-processing framework to make several
	new observations regarding the “inverse” problem of reconstructing
	3D occluders from cast shadows – extending previous work on shape-from-silhouette
	and visual hull methods. From this analysis we develop the first
	single-camera, single-shot approach to capture visual hulls without
	requiring moving or programmable illumination. We analyze several
	competing camera designs – ultimately leading to the development
	of a new large-format, mask-based light field camera that exploits
	optimal tiled-broadband codes for light-efficient shield field capture.
	We conclude by presenting a detailed experimental analysis of shield
	field capture and 3D occluder reconstruction.},
  file = {:./Lanman2008/shield_fields_highres.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Laszlo2005,
  author = {Joe Laszlo and Michael Neff and Karan Singh},
  title = {Predictive feedback for interactive control of physics-based characters},
  booktitle = {In Eurographics},
  year = {2005},
  note = {Other},
  abstract = {Interactive control of a physically simulated character is a challenging
	problem, due both to the complexity of controlling multiple degrees
	of freedom with lower dimensional input and because many interesting
	motions lie on the fringes of character stability. This paper addresses
	these problems using a novel technique called predictive feedback,
	where a glimpse into the near future for a few sample inputs is continuously
	presented to the animator. We discuss issues related to the spatio-temporal
	distribution of predictions so that they provide meaningful and timely
	feedback to an animator interactively controlling a physics-based
	character with simple input devices, like a mouse or keyboard. We
	propose a visual presentation of this predictive feedback in which
	control input samples are chosen in the proximity of the user’s current
	input and the predicted results are co-located with the position
	of the input necessary to achieve them. We further show how the predictive
	samples may be automatically interpolated to control aspects of the
	character’s motion, such as balance, thereby freeing the animator
	to focus on other details. The paper thus contributes a technique
	for physically simulated characters that simplifies interactive character
	control and increases the range of motion that can be performed by
	both novices and experts. Many of the presented concepts extend beyond
	our specific input device and dynamic character control setting to
	more general input tasks. Categories and Subject Descriptors (according
	to ACM CCS): I.3.3 [Computer Graphics]: Interaction, Physical simulation,
	Character animation},
  file = {:./Laszlo2005/eg05-predf-electronic.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Laurentini2003,
  author = {Laurentini, A.},
  title = {The visual hull for understanding shapes from contours: a survey},
  booktitle = {Signal Processing and Its Applications},
  year = {2003},
  volume = {1},
  pages = { 25-28 vol.1},
  month = {July},
  note = {3D Reconstruction},
  abstract = { In several practical situations the only available information for
	recognizing or reconstructing 3D objects are the object contours.
	Some recent theoretical developments put on a firm ground understanding
	3D shapes from silhouettes. In this paper we present survey of these
	developments, related to the geometric concept of visual hull.},
  doi = {10.1109/ISSPA.2003.1224631},
  file = {:./Laurentini2003/laurentini2006.pdf:PDF},
  issn = { },
  journal = {Signal Processing and Its Applications, 2003. Proceedings. Seventh
	International Symposium on},
  keywords = { image recognition, image reconstruction, object recognition 3D object
	recognizing, 3D object reconstructing, 3D shape, object contour,
	silhouette, visual hull geometric concept},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Laurentini1999,
  author = {Laurentini, A.},
  title = {The visual hull of curved objects},
  booktitle = {Computer Vision},
  year = {1999},
  volume = {1},
  pages = {356-361 vol.1},
  note = {3D Reconstruction},
  abstract = {The visual hull is a geometric tool which relates the 3D shape of
	a concave object to its silhouettes or shadows. This paper deals
	with the computation of the visual hull of objects bounded by smooth
	curved surfaces. We show that the surfaces which bound the visual
	hull are surfaces relevant for the construction of the aspect graph
	of the object, and that the algorithms for computing the aspect graph
	of curved objects can be exploited for computing their visual hull},
  doi = {10.1109/ICCV.1999.791242},
  file = {:./Laurentini1999/laurentini1999.pdf:PDF},
  journal = {Computer Vision, 1999. The Proceedings of the Seventh IEEE International
	Conference on},
  keywords = {image reconstruction, surface fittingaspect graph, concave object,
	curved objects, curved surfaces, visual hull},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@ARTICLE{Laurentini1994,
  author = {Laurentini, A.},
  title = {The visual hull concept for silhouette-based image understanding
	},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {1994},
  volume = {16},
  pages = {150-162},
  number = {2},
  month = {Feb},
  note = {3D Reconstruction},
  abstract = {Many algorithms for both identifying and reconstructing a 3-D object
	are based on the 2-D silhouettes of the object. In general, identifying
	a nonconvex object using a silhouette-based approach implies neglecting
	some features of its surface as identification clues. The same features
	cannot be reconstructed by volume intersection techniques using multiple
	silhouettes of the object. This paper addresses the problem of finding
	which parts of a nonconvex object are relevant for silhouette-based
	image understanding. For this purpose, the geometric concept of visual
	hull of a 3-D object is introduced. This is the closest approximation
	of object S that can be obtained with the volume intersection approach;
	it is the maximal object silhouette-equivalent to S, i.e., which
	can be substituted for S without affecting any silhouette. Only the
	parts of the surface of S that also lie on the surface of the visual
	hull can be reconstructed or identified using silhouette-based algorithms.
	The visual hull depends not only on the object but also on the region
	allowed to the viewpoint. Two main viewing regions result in the
	external and internal visual hull. In the former case the viewing
	region is related to the convex hull of S, in the latter it is bounded
	by S. The internal visual hull also admits an interpretation not
	related to silhouettes. Algorithms for computing visual hulls are
	presented and their complexity analyzed. In general, the visual hull
	of a 3-D planar face object turns out to be bounded by planar and
	curved patches},
  doi = {10.1109/34.273735},
  file = {:./Laurentini1994/Laurentini1994.pdf:PDF},
  issn = {0162-8828},
  keywords = {image reconstructionexternal visual hull, internal visual hull, nonconvex
	object, object identification, object reconstruction, silhouette-based
	image understanding},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Lavoue2008,
  author = {Guillaume Lavoué and Christian Wolf},
  title = {Markov Random Fields for Improving 3D Mesh Analysis and Segmentation},
  booktitle = {Eurographics 2008 Workshop on 3D Object Retrieval},
  year = {2008},
  month = apr,
  note = {Skeleton Extraction},
  abstract = {Mesh analysis and clustering have became important issues in order
	to improve the efficiency of common processingoperations like compression,
	watermarking or simplification. In this context we present a new
	method for clustering / labeling a 3D mesh given any field of scalar
	values associated with its vertices (curvature, density, roughness
	etc.). Our algorithm is based on Markov Random Fields, graphical
	probabilistic models. This Bayesian framework allows (1) to integrate
	both the attributes and the geometry in the clustering, and (2) to
	obtain an optimal global solution using only local interactions,
	due to the Markov property of the random field. We have defined new
	observation and prior models for 3D meshes, adapted from image processing
	which achieve very good results in terms of spatial coherency of
	the labeling. All model parameters are estimated, resulting in a
	fully automatic process (the only required parameter is the number
	of clusters) which works in reasonable time (several seconds).},
  file = {:./Lavoue2008/eurographics2008.pdf:PDF},
  language = {en},
  owner = {apinzonf},
  timestamp = {2009.04.03},
  url = {http://liris.cnrs.fr/publis/?id=3365}
}

@ARTICLE{Lazebnik2007,
  author = {Lazebnik, Svetlana and Furukawa, Yasutaka and Ponce, Jean},
  title = {Projective Visual Hulls},
  journal = {International Journal of Computer Vision},
  year = {2007},
  volume = {74},
  pages = {137--165},
  number = {2},
  month = aug,
  note = {3D Reconstruction},
  abstract = {Abstract&nbsp;&nbsp;This article presents a novel method for computing
	the visual hull of a solid bounded by a smooth surface and observed
	by a finite set of cameras. The visual hull is the intersection of
	the visual cones formed by back-projecting the silhouettes found
	in the corresponding images. We characterize its surface as a generalized
	polyhedron whose faces are visual cone patches; edges are intersection
	curves between two viewing cones; and vertices are frontier points
	where the intersection of two cones is singular, or intersection
	points where triples of cones meet. We use the mathematical framework
	of oriented projective differential geometry to develop an image-based
	algorithm for computing the visual hull. This algorithm works in
	a weakly calibrated settingâ€“-that is, it only requires projective
	camera matrices or, equivalently, fundamental matrices for each pair
	of cameras. The promise of the proposed algorithm is demonstrated
	with experiments on several challenging data sets and a comparison
	to another state-of-the-art method.},
  file = {:./Lazebnik2007/Lazebnik2007.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.03},
  url = {http://dx.doi.org/10.1007/s11263-006-0008-x}
}

@ARTICLE{Lee2002,
  author = {Lee,, Jehee and Chai,, Jinxiang and Reitsma,, Paul S. A. and Hodgins,,
	Jessica K. and Pollard,, Nancy S.},
  title = {Interactive control of avatars animated with human motion data},
  journal = {ACM Trans. Graph.},
  year = {2002},
  volume = {21},
  pages = {491--500},
  number = {3},
  note = {Motion Capture},
  abstract = {Real-time control of three-dimensional avatars is an important problem
	in the context of computer games and virtual environments. Avatar
	animation and control is difficult, however, because a large repertoire
	of avatar behaviors must be made available, and the user must be
	able to select from this set of behaviors, possibly with a low-dimensional
	input device. One appealing approach to obtaining a rich set of avatar
	behaviors is to collect an extended, unlabeled sequence of motion
	data appropriate to the application. In this paper, we show that
	such a motion database can be preprocessed for flexibility in behavior
	and efficient search and exploited for real-time avatar control.
	Flexibility is created by identifying plausible transitions between
	motion segments, and efficient search through the resulting graph
	structure is obtained through clustering. Three interface techniques
	are demonstrated for controlling avatar motion using this data structure:
	the user selects from a set of available choices, sketches a path
	through an environment, or acts out a desired motion in front of
	a video camera. We demonstrate the flexibility of the approach through
	four different applications and compare the avatar motion to directly
	recorded human motion.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/566654.566607},
  file = {:./Lee2002/avatar.pdf:PDF},
  issn = {0730-0301},
  owner = {apinzonf},
  publisher = {ACM},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Lei2009,
  author = {Cheng Lei and Yee-Hong Yang},
  title = {Efficient Geometric, Photometric, and Temporal Calibration of an
	Array of Unsynchronized Video Cameras},
  booktitle = {Computer and Robot Vision, 2009. CRV '09. Canadian Conference on},
  year = {2009},
  pages = {162-169},
  month = {May},
  note = {Camera Calibration},
  abstract = {Camera-arrays have become popular in many computer vision and computer
	graphics applications. Among all preprocessing steps, an efficient
	method to calibrate a large number of cameras is very much desired.
	The required calibration includes both the geometric and photometric
	calibration, which are the most common and also well studied for
	single camera. However, few existing efforts are devoted to camera
	arrays or to integrate both methods in a fully automatic way. Additionally,
	most existing camera array systems require or assume implicitly that
	all the cameras in the array are hardware-synchronized to simplify
	subsequent application-specific processing such as the calibration
	of all the cameras. While this constraint is useful, it greatly restricts
	the use of heterogeneous types of cameras and the configuration of
	cameras that could be used. In this paper, we propose a novel integrated
	and fully automatic solution for performing geometric, photometric
	and temporal calibration (synchronization) of an array of unsynchronized
	video cameras. In particular, our new method is based on the classic
	plane based calibration approach. By using a redesigned calibration
	pattern, the geometric, photometric and temporal calibrations are
	done in an integrated and extensible framework automatically. Extensive
	experimental results show that the new method is very easy to use
	and can achieve high accuracy in the calibrated parameters.},
  doi = {10.1109/CRV.2009.17},
  file = {:./Lei2009/Lei2009.pdf:PDF},
  keywords = {calibration, cameras, computer vision, synchronisationcomputer vision,
	geometric calibration, photometric calibration, temporal calibration,
	unsynchronized video camera array},
  owner = {apinzonf},
  timestamp = {2009.10.20}
}

@INPROCEEDINGS{Levet2007,
  author = {Levet,, Florian and Granier,, Xavier},
  title = {Improved skeleton extraction and surface generation for sketch-based
	modeling},
  booktitle = {GI '07: Proceedings of Graphics Interface 2007},
  year = {2007},
  pages = {27--33},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Skeleton Extraction},
  abstract = {For the generation of freeform models, sketching interfaces have raised
	an increasing interest due to their intuitive approach. It is now
	possible to infer a 3D model directly from a sketched curved. Unfortunately,
	a limit of current systems is the poor quality of the skeleton automatically
	extracted from this silhouette, leading to low quality meshes for
	the resulting objects.
	
	
	In this paper, we present new solutions that improve the surface generation
	for sketch-based modeling systems. First, we propose a new algorithm
	that extracts a smoother skeleton compared to previous approaches.
	Then, we present a new sampling scheme for the creation of good-quality
	3D mesh. Finally, we propose to use a profile curve composed of disconnected
	components in order to create models which genus is greater than
	0.},
  doi = {http://doi.acm.org/10.1145/1268517.1268524},
  file = {:./Levet2007/levet.pdf:PDF},
  isbn = {978-1-56881-337-0},
  location = {Montreal, Canada},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@INPROCEEDINGS{Li2002,
  author = {Ming Li and Schirmacher, H. and Magnor, M. and Siedel, H.-P.},
  title = {Combining stereo and visual hull information for on-line reconstruction
	and rendering of dynamic scenes},
  booktitle = {Multimedia Signal Processing},
  year = {2002},
  pages = { 9-12},
  month = {Dec.},
  note = {3D Reconstruction},
  abstract = {In this paper, we present a novel system which, combines depth-from-stereo
	and visual hull reconstruction for acquiring dynamic real-world scenes
	at interactive rates. First, we use the silhouettes from multiple
	views to construct a polyhedral visual hull is then used to limit
	the disparity range during depth-from-stereo computation. The restricted
	search range improves both speed and quality of the stereo reconstruction.
	In return, stereo information can compensate for some of the visual
	hull method, such as inability to reconstruct surface details and
	concave regions. Our system achieves a reconstruction frame rate
	of 4fps.},
  file = {:./Li2002/li2002.pdf:PDF},
  issn = { },
  journal = {Multimedia Signal Processing, 2002 IEEE Workshop on},
  keywords = { image reconstruction, rendering (computer graphics), stereo image
	processing depth-from-stereo computation, disparity range, dynamic
	scene rendering, frame rate reconstruction, interactive rates, on-line
	reconstruction, polyhedral visual hull, stereo reconstruction, visual
	hull information, visual hull reconstruction},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Li2007,
  author = {Xinju Li and Guskov, I.},
  title = {3D object recognition from range images using pyramid matching},
  booktitle = {Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference
	on},
  year = {2007},
  pages = {1-6},
  month = {Oct.},
  note = {Recognize 3D},
  abstract = {Recognition of 3D objects from different viewpoints is a difficult
	problem. In this paper, we propose a new method to recognize 3D range
	images by matching local surface descriptors. The input 3D surfaces
	are first converted into a set of local shape descriptors computed
	on surface patches defined by detected salient features. We compute
	the similarities between input 3D images by matching their descriptors
	with a pyramid kernel function. The similarity matrix of the images
	is used to train for classification using SVM, and new images can
	be recognized by comparing with the training set. The approach is
	evaluated on both synthetic and real 3D data with complex shapes.},
  doi = {10.1109/ICCV.2007.4408829},
  file = {:./Li2007/li-guskov07.pdf:PDF},
  issn = {1550-5499},
  journal = {Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference
	on},
  keywords = {image matching, learning (artificial intelligence), object recognition,
	support vector machines3D object recognition, 3D range images, SVM,
	local shape descriptors, pyramid kernel function, training set},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{Lin2008,
  author = {Huei-Yung Lin and Jing-Ren Wu},
  title = {3D reconstruction by combining shape from silhouette with stereo},
  booktitle = {Pattern Recognition},
  year = {2008},
  pages = {1-4},
  month = {Dec.},
  note = {3D Reconstruction},
  abstract = {In this paper we propose a 3D reconstruction algorithm by combining
	shape from silhouette with stereo. Visual hull of the object is first
	derived from multi-view silhouette images. Pairwise stereo matching
	for shape refinement is then accomplished using the best viewable
	images. Based on the reduced correspondence searching range constrained
	by contact points and bounding edges, significant improvement of
	visual hull is possible even if the number of cameras is limited.
	Experimental results are presented for both synthetic data and real
	scene images.},
  doi = {10.1109/ICPR.2008.4761016},
  file = {:./Lin2008/lin2008.pdf:PDF},
  issn = {1051-4651},
  journal = {Pattern Recognition, 2008. ICPR 2008. 19th International Conference
	on},
  keywords = {image matching, image reconstruction, stereo image processingmultiview
	silhouette images, object visual hull, pairwise stereo matching,
	reconstruction algorithm, shape refinement},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@ARTICLE{Liu2008,
  author = {Liu and L. and Bajaj and C. and Deasy and J. O. and Low and D. A.
	and Ju and T.},
  title = {Surface Reconstruction From Non-parallel Curve Networks},
  journal = {Computer Graphics Forum},
  year = {2008},
  volume = {27},
  pages = {155--163},
  number = {2},
  month = {April},
  note = {Modelling 3D},
  abstract = {Building surfaces from cross-section curves has wide applications
	including bio-medical modeling. Previous work in this area has mostly
	focused on connecting simple closed curves on parallel cross-sections.
	Here we consider the more general problem where input data may lie
	on non-parallel cross-sections and consist of curve networks that
	represent the segmentation of the underlying object by different
	material or tissue types (e.g., skin, muscle, bone, etc.) on each
	cross-section. The desired output is a surface network that models
	both the exterior surface and the internal partitioning of the object.
	We introduce an algorithm that is capable of handling curve networks
	of arbitrary shape and topology on cross-section planes with arbitrary
	orientations. Our algorithm is simple to implement and is guaranteed
	to produce a closed surface network that interpolates the curve network
	on each cross-section. Our method is demonstrated on both synthetic
	and bio-medical examples.},
  citeulike-article-id = {2732280},
  doi = {http://dx.doi.org/10.1111/j.1467-8659.2008.01112.x},
  file = {:./Liu2008/eg_paper_final1.pdf:PDF},
  issn = {0167-7055},
  owner = {apinzonf},
  posted-at = {2008-04-29 08:23:50},
  publisher = {Blackwell Publishing},
  timestamp = {2009.03.17},
  url = {http://dx.doi.org/10.1111/j.1467-8659.2008.01112.x}
}

@INPROCEEDINGS{Liu2006,
  author = {Xin Liu and Hongxun Yao and Guilin Yao and Wen Gao},
  title = {A Novel Volumetric Shape from Silhouette Algorithm Based on a Centripetal
	Pentahedron Model},
  booktitle = {Pattern Recognition},
  year = {2006},
  volume = {1},
  pages = {9-9},
  month = {0-0 },
  note = {3D Reconstruction},
  abstract = {In this paper we present a novel volumetric shape from silhouette
	algorithm based on a centripetal pentahedron model. The algorithm
	first partitions the space with a set of infinite triangular pyramids
	derived from a geodesic sphere. Then the pyramids are cut by silhouettes
	into a set of pentahedrons, which together constitute the centripetal
	pentahedron model of the visual hull. This process is accelerated
	by pre-computed polar silhouette graphs (PSGs) and reduced PSGs.
	Finally a mesh surface model is extracted by marching pentahedrons.
	Our algorithm has the advantages of robustness, speediness and preciseness},
  doi = {10.1109/ICPR.2006.146},
  file = {:./Liu2006/liu2006.pdf:PDF},
  issn = {1051-4651},
  journal = {Pattern Recognition, 2006. ICPR 2006. 18th International Conference
	on},
  keywords = {computational geometry, feature extraction, graph theory, image resolution,
	stereo image processingcentripetal pentahedron model, geodesic sphere,
	infinite triangular pyramids, marching pentahedrons, mesh surface
	model extraction, polar silhouette graphs, silhouette algorithm,
	space partitioning, visual hull, volumetric shape},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Ma2009,
  author = {Chi Ma and Hongyun Zhang and Duoqian Miao and XueDong Zhang},
  title = {Fingerprint Skeleton Extraction Based on Improved Principal Curve},
  booktitle = {Computer and Information Science, 2009. ICIS 2009. Eighth IEEE/ACIS
	International Conference on},
  year = {2009},
  pages = {605-610},
  month = {June},
  note = {Other},
  abstract = {In the fingerprint recognition system, skeleton extraction for low
	quality fingerprint images is an emphasis and difficulty task. Traditional
	methods are, however, susceptible to noise. In view of this, we propose
	a principal curves-based approach to alleviate this difficulty. In
	the paper, according to some characteristics of the fingerprint dataset,
	we improve the original principal graph algorithm proposed by Kegl
	to obtain principal curves, which can be served as the skeleton of
	a fingerprint. Experimental results show that our improved principal
	curve algorithm is better in efficiency and quality than the original
	algorithm. Our algorithm contains more information quantity and is
	proved to be more accurate and anti-noisy than thinning algorithm.},
  doi = {10.1109/ICIS.2009.53},
  file = {:./Ma2009/Ma2009.pdf:PDF},
  keywords = {feature extraction, fingerprint identification, graph theory, image
	thinningantinoisy image, fingerprint image recognition system, fingerprint
	skeleton extraction, image thinning algorithm, original principal
	graph algorithm, principal curve-based approach},
  owner = {apinzonf},
  timestamp = {2009.10.19}
}

@INPROCEEDINGS{Ma2003,
  author = {Ma,, Wan-Chun and Wu,, Fu-Che and Ouhyoung,, Ming},
  title = {Skeleton Extraction of 3D Objects with Radial Basis Functions},
  booktitle = {SMI '03: Proceedings of the Shape Modeling International 2003},
  year = {2003},
  pages = {207},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  note = {Skeleton Extraction},
  abstract = {Skeleton is a lower dimensional shape description of anobject. The
	requirements of a skeleton differ with applications.For example,
	object recognition requires skele-tonswith primitive shape features
	to make similarity comparison.On the other hand, surface reconstruction
	needsskeletons which contain detailed geometry information toreduce
	the approximation error in the reconstruction process.Whereas many
	previous works are concerned aboutskeleton extraction, most of these
	methods are sensitive tonoise, time consuming, or restricted to specific
	3D models.A practical approach for extracting skeletons from general3D
	models using radial basis functions (RBFs) is proposed.Skeleton generated
	with this approach conformsmore to the human perception. Given a
	3D polygonalmodel, the vertices are regarded as centers for RBF level
	setconstruction. Next, a gradient descent algorithm is appliedto
	each vertex to locate the local maxima in the RBF; thegradient is
	calculated directly from the partial derivativesof the RBF. Finally,
	with the inherited connectivity from theoriginal model, local maximum
	pairs are connected withlinks driven by the active contour model.
	The skeletonizationprocess is completed when the potential energy
	of theselinks is minimized.},
  file = {:./Ma2003/ma2003.pdf:PDF},
  isbn = {0-7695-1909-1},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@INPROCEEDINGS{Magnor2004,
  author = {Magnor,, Marcus and Goldlucke,, Bastian},
  title = {Spacetime-Coherent Geometry Reconstruction from Multiple Video Streams},
  booktitle = {3DPVT '04: Proceedings of the 3D Data Processing, Visualization,
	and Transmission, 2nd International Symposium},
  year = {2004},
  pages = {365--372},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  note = {3D Reconstruction},
  abstract = {By reconstructing time-varying geometry one frame at a time, one ignores
	the continuity of natural motion, wasting useful information about
	the underlying video-image formation process and taking into account
	temporally discontinuous reconstruction results. In 4D spacetime,
	the surface of a dynamic object describes a continuous 3D hyper-surface.
	This hyper-surface can be implicitly defined as the minimum of an
	energy functional designed to optimize photo-consistency. Based on
	an Euler-Lagrange reformulation of the problem, we find this hyper-surface
	from a handful of synchronized video recordings. The resulting object
	geometry varies smoothly over time, and intermittently invisible
	object regions are correctly interpolated from previously and/or
	future frames.},
  doi = {http://dx.doi.org/10.1109/3DPVT.2004.117},
  file = {:./Magnor2004/3dpvt04.pdf:PDF},
  isbn = {0-7695-2223-8},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Magnor2003,
  author = {Magnor, M. and Seidel, H.-P.},
  title = {Capturing the shape of a dynamic world - fast!},
  booktitle = {Shape Modeling International},
  year = {2003},
  pages = { 3-9},
  month = {May},
  note = {3D Reconstruction},
  abstract = {Acquiring online the evolving shape of a dynamic scene from a handful
	of video streams may be considered one of the most challenging, but
	at the same time also most auspicious tasks in contemporary computer
	graphics and computer vision research. The anticipation of revolutionary
	new applications such as interactive 3D television broadcasts motivates
	the ongoing work on free-viewpoint video rendering. The paper aims
	at giving a state-of-progress report on this lively research endeavor.
	Different acquisition setups and online reconstruction approaches
	are exemplified. Yielding interactive frame rates, depth map-based
	techniques, polyhedral as well as volumetric visual hull reconstruction
	approaches, and combined methods employing visual hull-guided depth
	map estimation are presented. The experience gained with these approaches
	allows us to identify future research directions towards real-time
	analysis and high-quality synthesis of dynamic, real-world scenes.},
  doi = {10.1109/SMI.2003.1199589},
  file = {:./Magnor2003/magnor2003.pdf:PDF},
  issn = { },
  journal = {Shape Modeling International, 2003},
  keywords = { computational geometry, image reconstruction, rendering (computer
	graphics), video signal processing acquisition setup, computer graphics,
	computer vision, depth map estimation, depth map-based technique,
	dynamic scene, dynamic world, evolving shape, free-viewpoint video
	rendering, high-quality synthesis, interactive 3D television broadcast,
	interactive frame rate, online reconstruction, polyhedral visual
	hull reconstruction, real-time analysis, shape capture, state-of-progress
	report, video stream, volumetric visual hull reconstruction},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@ARTICLE{Mercier2005,
  author = {B. Mercier and D. Meneveaux},
  title = {Shape from Silhouette: Image Pixels for Marching Cubes},
  journal = {Journal of WSCG'2005},
  year = {2005},
  volume = {13},
  pages = {112-118},
  month = {feb},
  note = {3D Reconstruction},
  abstract = {In this paper, we propose to use image pixels for geometry reconstruction
	with a shape from silhouette approach.
	
	We aim at estimating shape and normal for the surface of a single
	object seen through calibrated images. From the
	
	voxel-based shape obtained with the algorithm proposed by R. Szeliski
	in [18], our main contribution concerns the
	
	use of image pixels together with marching cubes for constructing
	a triangular mesh. We also provide a mean for
	
	estimating a normal inside each voxel with two different methods:
	(i) using marching cubes triangles and (ii) using
	
	only voxels. As seen in the results, our method proves accurate even
	for real objects acquired with a usual camera
	
	and an inexpensive acquisition system},
  file = {:./Mercier2005/wscg-2005.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Michel2000,
  author = {Michel,, O. and Flandrin,, P.},
  title = {Automatic extraction of time-frequency skeletons with minimal spanning
	trees},
  booktitle = {ICASSP '00: Proceedings of the Acoustics, Speech, and Signal Processing,
	2000. on IEEE International Conference},
  year = {2000},
  pages = {89--92},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  note = {Other},
  abstract = {Theoretical results have been established in non-parametric entropy
	estimation, based on asymptotic properties of minimal spanning trees
	(MST). A new application is proposed for the automatic extraction
	of time-frequency skeletons in the case of multicomponent chirp-like
	signals. The proposed method makes use of local maxima of a time-frequency
	distribution (considered as realizations of a 2D or 3D process),
	and exploits the efficiency of MSTs for density discrimination and
	clustering.},
  doi = {http://dx.doi.org/10.1109/ICASSP.2000.861871},
  file = {:./Michel2000/michel2000.pdf:PDF},
  isbn = {0-7803-6293-4},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@INPROCEEDINGS{Mikhail2006,
  author = {Mary Mikhail and Giovanni Palumbo and Jinane Mohammad and Mohamed
	El-Helaly and Aishy Amer},
  title = {An Online System for Synchronized Processing of Video and Audio Signals},
  booktitle = {Electrical and Computer Engineering, 2006. CCECE '06. Canadian Conference
	on},
  year = {2006},
  pages = {2065-2068},
  month = {May },
  note = {Synchronizing Video Cameras},
  abstract = {For many audio-visual applications, the integration and synchronization
	of audio and video signals is essential. The objective of this paper
	is to develop a system that displays the active objects in the captured
	video signal, integrated with their respective audio signals in the
	form of text. The video and audio signals are captured and processed
	separately. The signals are buffered and integrated and synchronized
	using a time-stamping technique. Time-stamps provide the timing information
	for each of the audio and video processes, the speech recognition
	and the object detection, respectively. This information is necessary
	to correlate the audio packets to the video frames. Hence, integration
	is achieved without the use of video information, such as lip movements.
	The results obtained are based on a specific implementation of the
	speech recognition module, which is determined to be the bottleneck
	process in the proposed system},
  doi = {10.1109/CCECE.2006.277564},
  file = {:./Mikhail2006/Mikhail2006.PDF:PDF},
  keywords = {audio signal processing, synchronisation, video signal processingaudio
	signal processing, audio-visual applications, online system, speech
	recognition, synchronized video signal processing, time-stamping
	technique, video frames, video information},
  owner = {apinzonf},
  timestamp = {2009.10.20}
}

@INPROCEEDINGS{Miller2007,
  author = {Miller, G. and Hilton, A.},
  title = {Safe hulls},
  booktitle = {Visual Media Production},
  year = {2007},
  pages = {1-8},
  month = {Nov.},
  note = {3D Reconstruction},
  abstract = {The visual hull is widely used as a proxy for novel view synthesis
	in computer vision. This paper introduces the safe hull, the first
	visual hull reconstruction technique to produce a surface containing
	only foreground parts. A theoretical basis underlies this novel approach
	which, unlike any previous work, can also identify phantom volumes
	attached to real objects. Using an image-based method, the visual
	hull is constructed with respect to each real view and used to identify
	safe zones in the original silhouettes. The safe zones define volumes
	known to only contain surface corresponding to a real object. The
	zones are used in a second reconstruction step to produce a surface
	without phantom volumes. Results demonstrate the effectiveness of
	this method for improving surface shape and scene realism, and its
	advantages over heuristic techniques.},
  file = {:./Miller2007/miller2007.pdf:PDF},
  journal = {Visual Media Production, 2007. IETCVMP. 4th European Conference on},
  keywords = {computer vision, image reconstructioncomputer vision, image-based
	method, phantom volumes identification, safe hull, view synthesis,
	visual hull reconstruction},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Miller2006,
  author = {Miller, G. and Hilton, A.},
  title = {Exact View-Dependent Visual Hulls},
  booktitle = {Pattern Recognition},
  year = {2006},
  volume = {1},
  pages = {107-111},
  month = {0-0 },
  note = {3D Reconstruction},
  abstract = {The visual hull is widely used to produce three dimensional models
	from multiple views, due to the reliability of the resulting surface.
	This paper presents a novel method for efficiently evaluating the
	exact view-dependent visual hull without using approximations. Methods
	for selecting intersections and ordering them via the cross ratio
	are presented. Results show the high quality of the surfaces produced
	using this method},
  doi = {10.1109/ICPR.2006.515},
  file = {:./Miller2006/miller2006.pdf:PDF},
  issn = {1051-4651},
  journal = {Pattern Recognition, 2006. ICPR 2006. 18th International Conference
	on},
  keywords = {image reconstruction, stereo image processing3D models, shape based
	reconstruction, surface reconstruction, view-dependent visual hulls},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Min2008,
  author = {Seungki Min and Jungwhan Kim and Anjin Park and Gwangjin Hong and
	Keechul Jung},
  title = {Graph-Cut Based Background Subtraction Using Visual Hull in Multiveiw
	Images},
  booktitle = {Computing: Techniques and Applications},
  year = {2008},
  pages = {372-377},
  month = {Dec.},
  note = {3D Reconstruction},
  abstract = {A graph-cut method has been successfully used in many applications
	for image segmentation. However, it needs lots of time and user intervention.
	In case of multi view image (MVI), it is especially hard to segment
	all images in a short time because of numerous images in MVI. In
	this paper, we describe a new technique for multi view image segmentation,
	which needs minimum user intervention and provides fast processing
	time. The user marks certain pixels as "target object" or "background"
	to provide a constraint for segmentation to only one of the MVI.
	The seed information is propagated to all images in the MVI. In this
	step, we can acquire tentative segment result and then apply them
	to reconstruct the 3D model which exploits the visual hull. After
	the 3D model is reconstructed, segment error that is found located
	out of foreground is eliminated. Although visual hull has a shortcoming
	that cannot represent whether the object is convex or concave, tentative
	segment result is easy to use and proven to be enough as our proposed
	method. We can acquire final segment result in a short time by integrating
	these two simple methods. According to the experiments, our method
	shows better performance in terms of processing time and minimizing
	user intervention.},
  doi = {10.1109/DICTA.2008.84},
  file = {:./Min2008/min2008.pdf:PDF},
  journal = {Computing: Techniques and Applications, 2008. DICTA '08.Digital Image},
  keywords = {graph theory, image reconstruction, image representation, image segmentation3D
	model reconstruction, graph-cut method, image segmentation, multiview
	image segmentation, target object, visual hull},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@ARTICLE{Moeslund2006,
  author = {Thomas B. Moeslund and Adrian Hilton and Volker Krüger},
  title = {A survey of advances in vision-based human motion capture and analysis},
  journal = {Computer Vision and Image Understanding},
  year = {2006},
  volume = {104},
  pages = {90 - 126},
  number = {2-3},
  note = {Survey Special Issue on Modeling People: Vision-based understanding
	of a person's shape, appearance, movement and behaviour},
  abstract = {This survey reviews advances in human motion capture and analysis
	from 2000 to 2006, following a previous survey of papers up to 2000
	[T.B. Moeslund, E. Granum, A survey of computer vision-based human
	motion capture, Computer Vision and Image Understanding, 81(3) (2001)
	231-268.]. Human motion capture continues to be an increasingly active
	research area in computer vision with over 350 publications over
	this period. A number of significant research advances are identified
	together with novel methodologies for automatic initialization, tracking,
	pose estimation, and movement recognition. Recent research has addressed
	reliable tracking and pose estimation in natural scenes. Progress
	has also been made towards automatic understanding of human actions
	and behavior. This survey reviews recent trends in video-based human
	capture and analysis, as well as discussing open problems for future
	research to achieve automatic visual analysis of human movement.},
  doi = {DOI: 10.1016/j.cviu.2006.08.002},
  file = {:./Moeslund2006/sdarticle.pdf:PDF},
  issn = {1077-3142},
  keywords = {Review},
  owner = {apinzonf},
  timestamp = {2009.03.18},
  url = {http://www.sciencedirect.com/science/article/B6WCX-4M1DB7H-1/2/8da6f6e7a8c8e07d9331bc7738c6d499}
}

@INPROCEEDINGS{Mundermann2007,
  author = {Mundermann, L. and Corazza, S. and Andriacchi, T.P.},
  title = {Accurately measuring human movement using articulated ICP with soft-joint
	constraints and a repository of articulated models},
  booktitle = {Computer Vision and Pattern Recognition},
  year = {2007},
  pages = {1-6},
  month = {June},
  note = {Motion Capture},
  abstract = {A novel approach for accurate markerless motion capture combining
	a precise tracking algorithm with a database of articulated models
	is presented. The tracking approach employs an articulated iterative
	closest point algorithm with soft-joint constraints for tracking
	body segments in visual hull sequences. The database of articulated
	models is derived from a combination of human shapes and anthropometric
	data, contains a large variety of models and closely mimics variations
	found in the human population. The database provides articulated
	models that closely match the outer appearance of the visual hulls,
	e.g. matches overall height and volume. This information is paired
	with a kinematic chain enhanced through anthropometric regression
	equations. Deviations in the kinematic chain from true joint center
	locations are compensated by the soft-joint constraints approach.
	As a result accurate and a more anatomical correct outcome is obtained
	suitable for biomechanical and clinical applications. Joint kinematics
	obtained using this approach closely matched joint kinematics obtained
	from a marker based motion capture system.},
  doi = {10.1109/CVPR.2007.383302},
  file = {:./Mundermann2007/mundermann2007.pdf:PDF},
  journal = {Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference
	on},
  keywords = {image motion analysis, image segmentation, iterative methods, regression
	analysisanthropometric regression equations, articulated ICP, articulated
	model repository, body segment tracking, human movement, iterative
	closest point algorithm, joint center locations, joint kinematics,
	motion capture system, soft-joint constraints, soft-joint constraints
	approach, tracking algorithm},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Niem1996,
  author = {Niem, W. and Steinmetz, M.},
  title = {Camera viewpoint control for the automatic reconstruction of 3D objects},
  booktitle = {Image Processing},
  year = {1996},
  volume = {3},
  pages = {655-658 vol.3},
  month = {Sep},
  note = {3D Reconstruction},
  abstract = {An algorithm for the image dependent control of the camera viewpoint
	is presented, which is applied to the automatic reconstruction of
	3D objects. For computer animation applications, “shape from silhouettes”
	using equally distributed viewpoints is an often used reconstruction
	technique. With respect to the local reconstruction errors, the use
	of equally distributed camera views is unfavourable for arbitrary
	shaped objects. For that reason, a camera viewpoint control is introduced,
	which purposefully rotates a turntable with the 3D object depending
	on the trace of the silhouette contour points over the rotation angle.
	This trace provides information about the location of object planes
	and gives a measure for the expected local 3D reconstruction errors.
	It turns out, that the new algorithm reduces the remaining 3D reconstruction
	errors up to 70% compared to algorithms without viewpoint control
	using the same number of viewpoints},
  doi = {10.1109/ICIP.1996.560580},
  file = {:./Niem1996/niem2006.pdf:PDF},
  journal = {Image Processing, 1996. Proceedings., International Conference on},
  keywords = {cameras, computer animation, image reconstruction, image segmentation,
	motion estimation, telecommunication control3D objects, 3D reconstruction
	error reduction, algorithm, automatic reconstruction, camera viewpoint
	control, computer animation applications, image dependent control,
	local 3D reconstruction errors, local reconstruction errors, object
	planes location, rotation angle, shape from silhouettes, silhouette
	contour points, turntable rotation},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Oda2006,
  author = {Oda,, Takuya and Itoh,, Yuichi and Nakai,, Wataru and Nomura,, Katsuhiro
	and Kitamura,, Yoshifumi and Kishino,, Fumio},
  title = {Interactive skeleton extraction for 3D animation using geodesic distances},
  booktitle = {SIGGRAPH '06: ACM SIGGRAPH 2006 Research posters},
  year = {2006},
  pages = {9},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Skeleton Extraction},
  abstract = {This paper proposes a method of extracting skeleton interactively
	for 3D character animation. A skeleton is automatically and interactively
	generated from the object data of 3D models in a process that consists
	of ?ve steps: 1) transformation into a low polygon model from the
	original model composed of a large number of polygons; 2) calculation
	of the sum of the geodesic distance from speci?c points to all vertices
	on the 3D model; 3) subdivision of the 3D model using the sum of
	geodesic distances; 4) generation of skeleton joints (skeleton nodes)
	on each boundary surface between those subdivision areas; and 5)
	connection of all skeleton nodes. We also propose a method for ?exible
	skeleton generation using boundary shapes and the sum of geodesic
	distances. After generating the skeleton, various animations can
	be created by interpolating key poses created from user manipulation
	of skeleton joints. Since skeletons can be generated with this method
	where speci?ed by users, users are expected to create interactively
	?exible animations of 3D models},
  doi = {http://doi.acm.org/10.1145/1179622.1179632},
  file = {:./Oda2006/oda2006.pdf:PDF},
  isbn = {1-59593-364-6},
  location = {Boston, Massachusetts},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@ARTICLE{Paris2004,
  author = {Paris,, Sylvain and Brice\, {n}o,, Hector M. and Sillion,, Fran\c{c}ois
	X.},
  title = {Capture of hair geometry from multiple images},
  journal = {ACM Trans. Graph.},
  year = {2004},
  volume = {23},
  pages = {712--719},
  number = {3},
  note = {3D Reconstruction},
  abstract = {Hair is a major feature of digital characters. Unfortunately, it has
	a complex geometry which challenges standard modeling tools. Some
	dedicated techniques exist, but creating a realistic hairstyle still
	takes hours. Complementary to user-driven methods, we here propose
	an image-based approach to capture the geometry of hair.The novelty
	of this work is that we draw information from the scattering properties
	of the hair that are normally considered a hindrance. To do so, we
	analyze image sequences from a fixed camera with a moving light source.
	We first introduce a novel method to compute the image orientation
	of the hairs from their anisotropic behavior. This method is proven
	to subsume and extend existing work while improving accuracy. This
	image orientation is then raised into a 3D orientation by analyzing
	the light reflected by the hair fibers. This part relies on minimal
	assumptions that have been proven correct in previous work.Finally,
	we show how to use several such image sequences to reconstruct the
	complete hair geometry of a real person. Results are shown to illustrate
	the fidelity of the captured geometry to the original hair. This
	technique paves the way for a new approach to digital hair generation.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1015706.1015784},
  file = {:./Paris2004/paper0120_hair_capture_ready.pdf:PDF},
  issn = {0730-0301},
  owner = {apinzonf},
  publisher = {ACM},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Park2002a,
  author = {Park,, Jeong-Sun and Oh,, Il-Seok},
  title = {Shape Decomposition and Skeleton Extraction of Character Patterns},
  booktitle = {ICPR '02: Proceedings of the 16 th International Conference on Pattern
	Recognition (ICPR'02) Volume 3},
  year = {2002},
  pages = {30411},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  note = {Other},
  abstract = {This paper proposes an approach to extract skeletons from the character
	patterns. It first decomposes the pattern into a set of near-convex
	parts and then extracts skeletons from the parts. In shape decomposition
	stage, the convex hull information is used to identify the splitting
	paths. For the skeleton extraction, an operation that ties the adjacent
	strokes by a knot is developed. Our control procedure processes a
	variety of different situations of the adjacentstrokes in a systematic
	way.},
  file = {:./Park2002a/park2002a.pdf:PDF},
  isbn = {0-7695-1695-X},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@ARTICLE{Park2006,
  author = {Park,, Sang Il and Hodgins,, Jessica K.},
  title = {Capturing and animating skin deformation in human motion},
  journal = {ACM Trans. Graph.},
  year = {2006},
  volume = {25},
  pages = {881--889},
  number = {3},
  note = {Motion Capture},
  abstract = {During dynamic activities, the surface of the human body moves in
	many subtle but visually significant ways: bending, bulging, jiggling,
	and stretching. We present a technique for capturing and animating
	those motions using a commercial motion capture system and approximately
	350 markers. Although the number of markers is significantly larger
	than that used in conventional motion capture, it is only a sparse
	representation of the true shape of the body. We supplement this
	sparse sample with a detailed, actor-specific surface model. The
	motion of the skin can then be computed by segmenting the markers
	into the motion of a set of rigid parts and a residual deformation
	(approximated first as a quadratic transformation and then with radial
	basis functions). We demonstrate the power of this approach by capturing
	flexing muscles, high frequency motions, and abrupt decelerations
	on several actors. We compare these results both to conventional
	motion capture and skinning and to synchronized video of the actors.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1141911.1141970},
  file = {:./Park2006/muscle_siggraph.pdf:PDF},
  issn = {0730-0301},
  owner = {apinzonf},
  publisher = {ACM},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Park2002,
  author = {Soon-Yong Park and Subbarao, M.},
  title = {Automatic 3D model reconstruction using voxel coding and pose integration},
  booktitle = {3D Data Processing Visualization and Transmission},
  year = {2002},
  volume = {2},
  pages = { II-533-II-536 vol.2},
  note = {3D Reconstruction},
  abstract = {Automatic reconstruction of a complete 3D model of a complex object
	is presented. The complete 3D model is reconstructed by integrating
	two 3D models which are reconstructed from different poses of the
	object. For each pose of the object, a 3D model is reconstructed
	by combining stereo image analysis, shape from silhouettes, and a
	volumetric integration technique. Stereo image analysis and shape
	from silhouettes techniques complement each other to reconstruct
	an accurate and noise-resistant 3D model. For a reliable volumetric
	integration of multiple partial shapes, a voxel coding technique
	is introduced. The voxel coding technique facilitates a selection
	of consistent partial shapes for shape integration. In order to reconstruct
	all visible surfaces of a complex object with concavities and holes,
	two 3D models from different poses of the object are reconstructed
	and integrated to obtain the complete 3D model. A voxel coding technique
	is again used during pose integration. Experimental results on a
	real object demonstrate that our approach has advantages and is effective.},
  doi = {10.1109/ICIP.2002.1040005},
  file = {:./Park2002/park2002.pdf:PDF},
  issn = {1522-4880 },
  journal = {Image Processing. 2002. Proceedings. 2002 International Conference
	on},
  keywords = { binary codes, image reconstruction, stereo image processing, virtual
	reality automatic reconstruction, complete 3D model, complex object,
	multiple partial shapes, partial shapes, poses, shape integration,
	silhouettes, stereo image analysis, volumetric integration technique,
	voxel coding technique},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Pham2007,
  author = {Pham, Q.C. and Gond, L. and Begard, J. and Allezard, N. and Sayd,
	P.},
  title = {Real-Time Posture Analysis in a Crowd using Thermal Imaging},
  booktitle = VS07,
  year = {2007},
  pages = {1-8},
  note = {Motion Capture},
  abstract = {This article describes a video-surveillance system developed within
	the ISCAPS project. Thermal imaging provides a robust solution to
	visibility change (illumination, smoke) and is a relevant technology
	for discriminating humans in complex scenes. In this article, we
	demonstrate its efficiency for posture analysis in dense groups of
	people. The objective is to automatically detect several persons
	lying down in a very crowded area. The presented method is based
	on the detection and segmentation of individuals within groups of
	people using a combination of several weak classifiers. The classification
	of extracted silhouettes enables to detect abnormal situations. This
	approach was successfully applied to the detection of terrorist gas
	attacks on railway platform and experimentally validated in the project.
	Some of the results are presented here.},
  bibsource = {http://www.visionbib.com/bibliography/people923.html#TT84401},
  file = {:./Pham2007/Pham2007.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@ARTICLE{Remondino2004,
  author = {Fabio Remondino},
  title = {3-D Reconstruction of Static Human Body Shape from Image Sequence},
  journal = {Computer Vision and Image Understanding},
  year = {2004},
  volume = {93},
  pages = {65--85},
  note = {3D Reconstruction},
  abstract = {The generation of 3-D models from uncalibrated image sequences is
	a challenging problem that has been investigated in many research
	activities in the last decade. In particular, a topic of great interest
	is the modeling of realistic humans, for animation, manufacture or
	medicine purposes. Nowadays the common approaches try to reconstruct
	the human body using specialized hardware (laser scanners) resulting
	in high costs. In this contribution a different method for the three-dimensional
	reconstruction of static human body shape from monocular image sequence
	is presented. The core of the presented work describes the calibration
	and orientation of the images, mostly based on photogrammetric techniques.
	Then the process includes also the extraction of correspondences
	on the body using a least squares matching algorithm and the reconstruction
	of the 3-D body model in point cloud form.},
  file = {:./Remondino2004/cviu04.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{Remondino2002,
  author = {Fabio Remondino},
  title = {Human Body Reconstruction from Image Sequences},
  booktitle = {Pattern Recognition (DAGM 2002), Lecture Notes in Computer Science
	2449},
  year = {2002},
  pages = {50--57},
  publisher = {Springer},
  note = {3D Reconstruction},
  abstract = {The generation of 3-D models from uncalibrated sequences is a challenging
	problem that has been investigated in many research activities in
	the last decade. In particular, a topic of great interest is the
	modeling of real humans. In this paper a method for the 3-D reconstruction
	of static human body shapes from images acquired with a video-camera
	is presented. The process includes the orientation and calibration
	of the sequence, the extraction of correspondences on the body using
	least squares matching technique and the reconstruction of the 3-D
	point cloud of the human body.},
  file = {:./Remondino2002/dagm02.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@OTHER{Remondino2003,
  note = {3D Reconstruction},
  abstract = {In this paper, we first review the approaches to recover 3D shape
	and related movements of a human and then we present an easy and
	reliable approach to recover a 3D model using just one image or monocular
	video sequence. A simplification of the perspective camera model
	is required, due to the absence of stereo view. The human figure
	is reconstructed in a skeleton form and to improve the visual quality,
	a pre-defined human model is also fitted to the recovered 3D data.},
  author = {Remondino, Fabio and Roditakis, Andreas},
  file = {:./Remondino2003/dagm03.pdf:PDF},
  journal = {Pattern Recognition},
  owner = {apinzonf},
  pages = {100--107},
  timestamp = {2009.03.18},
  title = {3D Reconstruction of Human Skeleton from Single Images or Monocular
	Video Sequences},
  url = {http://www.springerlink.com/content/bbvmju2h5uwjfw6n},
  year = {2003}
}

@ARTICLE{Reniers2008,
  author = {Reniers, Dennie and Telea, Alexandru},
  title = {Part-type Segmentation of Articulated Voxel-Shapes using the Junction
	Rule},
  journal = {Computer Graphics Forum},
  year = {2008},
  volume = {27},
  pages = {1845--1852},
  number = {7},
  note = {Skeleton Extraction},
  abstract = {We present a part-type segmentation method for articulated voxel-shapes
	based on curve skeletons. Shapes are considered to consist of several
	simpler, intersecting shapes. Our method is based on the junction
	rule: the observation that two intersecting shapes generate an additional
	junction in their joined curve-skeleton near the place of intersection.
	For each curve-skeleton point, we construct a piecewise-geodesic
	loop on the shape surface. Starting from the junctions, we search
	along the curve skeleton for points whose associated loops make for
	suitable part cuts. The segmentations are robust to noise and discretization
	artifacts, because the curve skeletonization incorporates a single
	user-parameter to filter spurious curve-skeleton branches. Furthermore,
	segment borders are smooth and minimally twisting by construction.
	We demonstrate our method on several real-world examples and compare
	it to existing part-type segmentation methods.},
  citeulike-article-id = {3496644},
  file = {:./Reniers2008/part.pdf:PDF},
  keywords = {articulated, part-type, segmentation, voxel-shapes},
  owner = {apinzonf},
  posted-at = {2008-11-08 17:05:20},
  priority = {2},
  timestamp = {2009.10.19}
}

@INPROCEEDINGS{Reniers2007,
  author = {Reniers, D. and Telea, A.},
  title = {Skeleton-based Hierarchical Shape Segmentation},
  booktitle = {Shape Modeling and Applications, 2007. SMI '07. IEEE International
	Conference on},
  year = {2007},
  pages = {179-188},
  month = {June},
  note = {Skeleton Extraction},
  abstract = {We present an effective framework for segmenting 3D shapes into meaningful
	components using the curve skeleton. Our algorithm identifies a number
	of critical points on the curve skeleton, either fully automatically
	as the junctions of the curve skeleton, or based on user input. We
	use these points to construct a partitioning of the object surface
	using geodesies. Because it is based on the curve skeleton, our segmentation
	intrinsically reflects the shape symmetry and topology. By using
	geodesies we obtain segments that have smooth, minimally twisting
	borders. Finally, we present a hierarchical segmentation of shapes
	which reflects the hierarchical structure of the curve skeleton.
	We describe a voxel-based implementation of our method which is robust
	and noise resistant, computationally efficient, able to handle shapes
	of complex topology, and which delivers level- of-detail segmentations.
	We demonstrate the framework on various real-world 3D shapes.},
  doi = {10.1109/SMI.2007.33},
  file = {:./Reniers2007/Reniers2007.pdf:PDF},
  keywords = {curve fitting, surface fittingcurve skeleton-based hierarchical shape
	segmentation, object surface partitioning},
  owner = {apinzonf},
  timestamp = {2009.10.19}
}

@ARTICLE{Rusinkiewicz2002,
  author = {Rusinkiewicz,, Szymon and Hall-Holt,, Olaf and Levoy,, Marc},
  title = {Real-time 3D model acquisition},
  journal = {ACM Trans. Graph.},
  year = {2002},
  volume = {21},
  pages = {438--446},
  number = {3},
  note = {Motion Capture},
  abstract = {The digitization of the 3D shape of real objects is a rapidly expanding
	field, with applications in entertainment, design, and archaeology.
	We propose a new 3D model acquisition system that permits the user
	to rotate an object by hand and see a continuously-updated model
	as the object is scanned. This tight feedback loop allows the user
	to find and fill holes in the model in real time, and determine when
	the object has been completely covered. Our system is based on a
	60 Hz. structured-light rangefinder, a real-time variant of ICP (iterative
	closest points) for alignment, and point-based merging and rendering
	algorithms. We demonstrate the ability of our prototype to scan objects
	faster and with greater ease than conventional model acquisition
	pipelines.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/566654.566600},
  file = {:./Rusinkiewicz2002/rt_model.pdf:PDF},
  issn = {0730-0301},
  owner = {apinzonf},
  publisher = {ACM},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Shalom2008,
  author = {Shy Shalom and Lior Shapira and Ariel Shamir and Daniel Cohen-Or},
  title = {Part Analogies in Sets of Objects},
  booktitle = {Eurographics Workshop on 3D Object Retrieval ‘08},
  year = {2008},
  note = {Skeleton Extraction},
  abstract = {Shape retrieval can benefit from analogies among similar shapes and
	parts of different objects. By partitioning an object to meaningful
	parts and finding analogous parts in other objects, sub-parts and
	partial match queries can be utilized. First by searching for similar
	parts in the context of their shape, and second by finding similarities
	even among objects that differ in their general shape and topology.
	Moreover, analogies can create the basis for semantic text-based
	searches: for instance, in this paper we demonstrate a simple annotation
	tool that carries tags of object parts from one model to many others
	using analogies. We partition 3D objects based on the shape-diameter
	function (SDF), and use it to find corresponding parts in other objects.
	We present results on finding analogies among numerous objects from
	shape repositories, and demonstrate sub-part queries using an implementation
	of a simple search and retrieval application.},
  file = {:./Shalom2008/part_analogies.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@ARTICLE{Shapira2008,
  author = {Shapira,, Lior and Shamir,, Ariel and Cohen-Or,, Daniel},
  title = {Consistent mesh partitioning and skeletonisation using the shape
	diameter function},
  journal = {Vis. Comput.},
  year = {2008},
  volume = {24},
  pages = {249--259},
  number = {4},
  note = {Skeleton Extraction},
  abstract = {Mesh partitioning and skeletonisation are fundamental for many computer
	graphics and animation techniques. Because of the close link between
	an object’s skeleton and its boundary, these two problems are in
	many cases complementary. Any partitioning of the object can assist
	in the creation of a skeleton and any segmentation of the skeleton
	can infer a partitioning of the object. In this paper, we consider
	these two problems on a wide variety of meshes, and strive to construct
	partitioning and skeletons which remain consistent across a family
	of objects, not a single one. Such families can consist of either
	a single object in multiple poses and resolutions, or multiple objects
	which have a general common shape. To achieve consistency, we base
	our algorithms on a volume-based shape-function called the shape-diameter-function
	(SDF), which remains largely oblivious to pose changes of the same
	object and maintains similar values in analogue parts of different
	objects. The SDF is a scalar function defined on the mesh surface;
	however, it expresses a measure of the diameter of the object’s volume
	in the neighborhood of each point on the surface. Using the SDF we
	are able to process and manipulate families of objects which contain
	similarities using a simple and consistent algorithm: consistently
	partitioning and creating skeletons among multiple meshes.},
  address = {Secaucus, NJ, USA},
  doi = {http://dx.doi.org/10.1007/s00371-007-0197-5},
  file = {:./Shapira2008/Shapira08.pdf:PDF},
  issn = {0178-2789},
  owner = {apinzonf},
  publisher = {Springer-Verlag New York, Inc.},
  timestamp = {2009.04.03}
}

@ARTICLE{Shen2009,
  author = {Shen,, Chunfeng and Lin,, Xueyin and Shi,, Yuanchun},
  title = {Human pose estimation from corrupted silhouettes using a sub-manifold
	voting strategy in latent variable space},
  journal = {Pattern Recogn. Lett.},
  year = {2009},
  volume = {30},
  pages = {421--431},
  number = {4},
  note = {3D Reconstruction},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/j.patrec.2008.10.009},
  file = {:./Shen2009/sdarticle.pdf:PDF},
  issn = {0167-8655},
  owner = {apinzonf},
  publisher = {Elsevier Science Inc.},
  timestamp = {2009.04.30}
}

@ARTICLE{Shin2008,
  author = {Dongjoe Shin and Tjahjadi, T.},
  title = {Local Hull-Based Surface Construction of Volumetric Data From Silhouettes},
  journal = {Image Processing, IEEE Transactions on},
  year = {2008},
  volume = {17},
  pages = {1251-1260},
  number = {8},
  month = {Aug. },
  note = {3D Reconstruction},
  abstract = {The marching cubes (MC) is a general method which can construct a
	surface of an object from its volumetric data generated using a shape
	from silhouette method. Although MC is efficient and straightforward
	to implement, a MC surface may have discontinuity even though the
	volumetric data is continuous. This is because surface construction
	is more sensitive to image noise than the construction of volumetric
	data. To address this problem, we propose a surface construction
	algorithm which aggregates local surfaces constructed by the 3-D
	convex hull algorithm. Thus, the proposed method initially classifies
	local convexities from imperfect MC vertices based on sliced volumetric
	data. Experimental results show that continuous surfaces are obtained
	from imperfect silhouette images of both convex and nonconvex objects.},
  doi = {10.1109/TIP.2008.926149},
  file = {:./Shin2008/shin2008.pdf:PDF},
  issn = {1057-7149},
  keywords = {image denoising, image reconstruction3D convex hull algorithm, image
	noise, local hull-based surface construction, marching cubes, silhouette
	method, volumetric data},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Shin2006,
  author = {Dongjoe Shin and Tardi Tjahjadi},
  title = {Triangular Mesh Generation of Octrees of Non-Convex 3D Objects},
  booktitle = {Pattern Recognition},
  year = {2006},
  volume = {3},
  pages = {950-953},
  month = {0-0 },
  note = {Other},
  abstract = {A general surface-generating algorithm, the marching cube, produces
	triangular meshes from octants where the vertices of octants are
	clearly classified into either inside or outside the object. However,
	the algorithm is ambiguous for octrees corresponding to non-convex
	objects generated using a shape from silhouette technique. This paper
	presents a methodology which involves Delaunay triangulation to generate
	surface meshes for such octrees. Since the general 3D Delaunay triangulation
	creates 3D convex hull which consists of tetrahedron meshes, we propose
	a method which applies the Delaunay algorithm locally in order to
	deal with non-convex objects. The proposed method first slices an
	octree and detects the clusters in each slice. All clusters between
	adjacent slices are linked based on a 3D probability density cube.
	The Delaunay algorithm is then applied to locally-linked clusters.
	Finally the accumulation of triangular meshes forms a final non-convex
	surface mesh},
  doi = {10.1109/ICPR.2006.1137},
  file = {:./Shin2006/shin2006.pdf:PDF},
  issn = {1051-4651},
  journal = {Pattern Recognition, 2006. ICPR 2006. 18th International Conference
	on},
  keywords = {computational geometry, mesh generation, object recognition, octrees,
	pattern clustering, probabilityDelaunay triangulation, marching cube,
	nonconvex 3D objects, octrees, probability density cube, silhouette
	technique, surface-generating algorithm, tetrahedron meshes, triangular
	mesh generation},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@ARTICLE{Shiratori2008,
  author = {Takaaki Shiratori and Jessica K. Hodgins},
  title = {Accelerometer-based User Interfaces for the Control of a Physically
	Simulated Character},
  journal = {ACM Transactions on Graphics (SIGGRAPH Asia 2008)},
  year = {2008},
  volume = {27},
  pages = {1--9},
  number = {5},
  month = aug,
  note = {Motion Capture},
  abstract = {In late 2006, Nintendo released a new game controller, the Wiimote,
	which included a three-axis accelerometer. Since then, a large variety
	of novel applications for these controllers have been developed by
	both independent and commercial developers. We add to this growing
	library with three performance interfaces that allow the user to
	control the motion of a dynamically simulated, animated character
	through the motion of his or her arms, wrists, or legs. For comparison,
	we also implement a traditional joystick/button interface. We assess
	these interfaces by having users test them on a set of tracks containing
	turns and pits. Two of the interfaces (legs and wrists) were judged
	to be more immersive and were better liked than the joystick/button
	interface by our subjects. All three of the Wiimote interfaces provided
	better control than the joystick interface based on an analysis of
	the failures seen during the user study.},
  doi = {http://doi.acm.org/10.1145/1409060.1409076},
  file = {:./Shiratori2008/SIGGRAPHAsia2008_wii.pdf:PDF},
  keywords = {Wii},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{Shu2008,
  author = {Bo Shu and Xianjie Qiu and Zhaoqi Wang},
  title = {Hardware-based camera calibration and 3D modelling under circular
	motion},
  booktitle = {Computer Vision and Pattern Recognition Workshops},
  year = {2008},
  pages = {1-6},
  month = {June},
  note = {Camera Calibration},
  abstract = {In this paper, we present a combined camera calibration and image
	based modeling method using an iterative optimization of shape from
	silhouette under circular motion. By minimizing the difference between
	the projections of reconstructed visual hull and the silhouette images
	using graphics hardware, the optimization can finally converge to
	accurate camera parameters and realistic visual hull efficiently
	and robustly. Using this method, we can automatically create photorealistic
	3D models directly from images.},
  doi = {10.1109/CVPRW.2008.4563093},
  file = {:./Shu2008/shu2008.pdf:PDF},
  journal = {Computer Vision and Pattern Recognition Workshops, 2008. CVPRW '08.
	IEEE Computer Society Conference on},
  keywords = {image motion analysis, image reconstruction, image sensors, optimisation,
	realistic images, solid modellingcircular motion, graphics hardware,
	hardware-based camera calibration, image based modeling method, iterative
	optimization, photorealistic 3D modelling, reconstructed visual hull,
	silhouette image},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Sinha2004,
  author = {Sinha, S.N. and Pollefeys, M.},
  title = {Synchronization and calibration of camera networks from silhouettes},
  booktitle = {Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International
	Conference on},
  year = {2004},
  volume = {1},
  pages = { 116-119 Vol.1},
  month = {Aug.},
  note = {Camera Calibration},
  abstract = { We propose an automatic approach to synchronize a network of uncalibrated
	and unsynchronized video cameras, and recover the complete calibration
	of all these cameras. In this paper, we extend recent work on computing
	the epipolar geometry from dynamic silhouettes, to deal with unsynchronized
	sequences and find the temporal offset between them. This is used
	to compute the fundamental matrices and the temporal offsets between
	many view-pairs in the network. Knowing the time-shifts between enough
	view-pairs allows us to robustly synchronize the whole network. The
	calibration of all the cameras is recovered from these fundamental
	matrices. The dynamic shape of the object can then be recovered using
	a visual-hull algorithm. Our method is especially useful for multi-camera
	shape-from-silhouette systems, as visual hulls can now be reconstructed
	without the need for a specific calibration session.},
  doi = {10.1109/ICPR.2004.1334021},
  file = {:./Sinha2004/Sinha2004.PDF:PDF},
  issn = {1051-4651 },
  keywords = { calibration, image reconstruction, image sequences, matrix algebra,
	synchronisation, video cameras, video signal processing camera network
	calibration, camera network synchronization, dynamic silhouettes,
	epipolar geometry, fundamental matrices, image reconstruction, multicamera
	shape, silhouette systems, temporal offsets, uncalibrated video cameras,
	unsynchronized sequences, unsynchronized video cameras, visual hull
	algorithm},
  owner = {apinzonf},
  timestamp = {2009.10.20}
}

@ARTICLE{Slabaugh2004,
  author = {Slabaugh, Gregory G. and Culbertson, W. Bruce and Malzbender, Thomas
	and Stevens, Mark R. and Schafer, Ronald W.},
  title = {Methods for Volumetric Reconstruction of Visual Scenes},
  journal = {International Journal of Computer Vision},
  year = {2004},
  volume = {57},
  pages = {179--199},
  number = {3},
  month = may,
  note = {3D Reconstruction},
  abstract = {In this paper, we present methods for 3D volumetric reconstruction
	of visual scenes photographed by multiple calibrated cameras placed
	at arbitrary viewpoints. Our goal is to generate a 3D model that
	can be rendered to synthesize new photo-realistic views of the scene.
	We improve upon existing voxel coloring/space carving approaches
	by introducing new ways to compute visibility and photo-consistency,
	as well as model infinitely large scenes. In particular, we describe
	a visibility approach that uses all possible color information from
	the photographs during reconstruction, photo-consistency measures
	that are more robust and/or require less manual intervention, and
	a volumetric warping method for application of these reconstruction
	methods to large-scale scenes.},
  file = {:./Slabaugh2004/Slabaugh2004.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.03},
  url = {http://dx.doi.org/10.1023/B:VISI.0000013093.45070.3b}
}

@INPROCEEDINGS{Slyper2008,
  author = {Ronit Slyper and Jessica Hodgins},
  title = {Action Capture with Accelerometers},
  booktitle = {2008 ACM SIGGRAPH / Eurographics Symposium on Computer Animation},
  year = {2008},
  month = jul,
  note = {Motion Capture},
  abstract = {We create a performance animation system that leverages the power
	of low-cost accelerometers, readily available motion capture databases,
	and construction techniques from e-textiles. Our system, built with
	only off-the-shelf parts, consists of five accelerometers sewn into
	a comfortable shirt that streams data to a computer. The accelerometer
	readings are continuously matched against accelerations computed
	from existing motion capture data, and an avatar is animated with
	the closest match. We evaluate our system visually and using simultaneous
	motion and accelerometer capture.},
  file = {:./Slyper2008/final.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@ARTICLE{4178157,
  author = {Starck, Jonathan and Hilton, Adrian},
  title = {Surface Capture for Performance-Based Animation},
  journal = {Computer Graphics and Applications, IEEE},
  year = {2007},
  volume = {27},
  pages = {21-31},
  number = {3},
  month = {May-June },
  note = {3D reconstruction},
  abstract = {Creating realistic animated models of people is a central task in
	digital content production. Traditionally, highly skilled artists
	and animators construct shape and appearance models for digital character.
	They then define the character's motion at each time frame or specific
	key-frames in a motion sequence to create a digital performance.
	Increasingly, producers are using motion capture technology to record
	animations from an actor's performance. This technology reduces animation
	production time and captures natural movements to create a more believable
	production. However, motion capture requires the use of specialist
	suits and markers and only records skeletal motion. It lacks the
	detailed secondary surface dynamics of cloth and hair that provide
	the visual realism of a live performance. Over the last decade, we
	have investigated studio capture technology with the objective of
	creating models of real people that accurately reflect the time-varying
	shape and appearance of the whole body with clothing. Surface capture
	is a fully automated system for capturing a human's shape and appearance
	as well as motion from multiple video cameras to create highly realistic
	animated content from an actor's performance in full wardrobe. Our
	system solves two key problems in performance capture: scene capture
	from a limited number of camera views and efficient scene representation
	for visualization},
  doi = {10.1109/MCG.2007.68},
  file = {:./SurfCap/starck07cga.pdf:PDF},
  issn = {0272-1716},
  keywords = {computer animation, data visualisation, image motion analysis, image
	sequences, realistic images, video camerasdata visualization, digital
	content production, motion sequence, multiple video cameras, realistic
	animated model, skeletal motion, surface capture},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{citeulike:582023,
  author = {Starck, J. and Hilton, A. },
  title = {Spherical Matching for Temporal Correspondence of Non-Rigid Surfaces},
  booktitle = {IEEE International Conference on Computer Vision (ICCV)},
  year = {2005},
  pages = {1387--1394},
  note = {3D Reconstruction},
  abstract = {This paper introduces spherical matching to estimate dense temporal
	correspondence of non-rigid surfaces with genus-zero topology. The
	spherical domain gives a consistent 2D parameterisation of non-rigid
	surfaces for matching. Non-rigid 3D surface correspondence is formulated
	as the recovery of a bijective mapping between two surfaces in the
	2D domain. Formulating matching as a 2D bijection guarantees a continuous
	one-to-one surface correspondence without overfolding. This overcomes
	limitations of direct estimation of non-rigid surface correspondence
	in the 3D domain. A multiple resolution coarse-to-?ne algorithm is
	introduced to robustly estimate the dense correspondence which minimises
	the disparity in shape and appearance between two surfaces. 
	
	Spherical matching is applied to derive the temporal correspondence
	between non-rigid surfaces reconstructed at successive frames from
	multiple view video sequences of people. Dense surface correspondence
	is recovered across complete motion sequences for both textured and
	uniform regions, without the requirement for a prior model of hu
	man shape or kinematic structure for tracking.},
  citeulike-article-id = {582023},
  file = {:./SurfCap/starck05iccv.pdf:PDF},
  journal = {IEEE International Conference on Computer Vision (ICCV)},
  keywords = {starck},
  owner = {apinzonf},
  posted-at = {2006-04-11 15:29:40},
  priority = {0},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{starck06volumetric,
  author = {Starck, J. and Hilton, A. and Miller, G. },
  title = {Volumetric stereo with silhouette and feature constraints},
  booktitle = {British Machine Vision Conference},
  year = {2006},
  month = {September},
  note = {3D Reconstruction},
  abstract = {This paper presents a novel volumetric reconstruction technique that
	combines shape-from-silhouette with stereo photo-consistency in a
	global optimisation that enforces feature constraints across multiple
	views. Human
	
	shape reconstruction is considered where extended regions of uniform
	appearance, complex self-occlusions and sparse feature cues represent
	a challenging problem for conventional reconstruction techniques.
	A uni?ed approach is introduced to ?rst reconstruct the occluding
	contours and left-right consistent edge contours in a scene and then
	incorporate these contour constraints in a global surface optimisation
	using graph-cuts. The proposed technique maximises photo-consistency
	on the surface, while satisfying silhouette constraints to provide
	shape in the presence of uniform surface appearance and edge feature
	constraints to align key image features across views.},
  citeulike-article-id = {1447684},
  file = {:./SurfCap/starck06bmvc.pdf:PDF},
  keywords = {3d, graphcut},
  owner = {apinzonf},
  posted-at = {2007-07-11 05:25:40},
  priority = {2},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{Starck2005,
  author = {Starck,, J. and Miller,, G. and Hilton,, A.},
  title = {Video-based character animation},
  booktitle = {SCA '05: Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium
	on Computer animation},
  year = {2005},
  pages = {49--58},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Motion Capture},
  abstract = {In this paper we introduce a video-based representation for free viewpoint
	visualization and motion control of 3D character models created from
	multiple view video sequences of real people. Previous approaches
	to video-based rendering provide no control of scene dynamics to
	manipulate, retarget, and create new 3D content from captured scenes.
	Here we contribute a new approach, combining image based reconstruction
	and video-based animation to allow controlled animation of people
	from captured multiple view video sequences. We represent a character
	as a motion graph of free viewpoint video motions for animation control.
	We introduce the use of geometry videos to represent reconstructed
	scenes of people for free viewpoint video rendering. We describe
	a novel spherical matching algorithm to derive global surface to
	surface correspondence in spherical geometry images for motion blending
	and the construction of seamless transitions between motion sequences.
	Finally, we demonstrate interactive video-based character animation
	with real-time rendering and free viewpoint visualization. This approach
	synthesizes highly realistic character animations with dynamic surface
	shape and appearance captured from multiple view video of people.},
  doi = {http://doi.acm.org/10.1145/1073368.1073375},
  file = {:./listado_inicial\\SurfCap/starck05sca.pdf:PDF},
  isbn = {1-7695-2270-X},
  location = {Los Angeles, California},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{1060250,
  author = {Sud, Avneesh and Foskey, Mark and Manocha, Dinesh},
  title = {Homotopy-preserving medial axis simplification},
  booktitle = {SPM '05: Proceedings of the 2005 ACM symposium on Solid and physical
	modeling},
  year = {2005},
  pages = {39--50},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Skeleton Extraction},
  abstract = {We present a novel algorithm to compute a simplified medial axis of
	a polyhedron. Our simplification algorithm tends to remove unstable
	features of Blum's medial axis. Moreover, our algorithm preserves
	the topological structure of the original medial axis and ensures
	that the simplified medial axis has the same homotopy type as Blum's
	medial axis. We use the separation angle formed by connecting a point
	on the medial axis to closest points on the boundary as a measure
	of the stability of the medial axis at the point. The medial axis
	is decomposed into its parts that are the sheets, seams and junctions.
	We present a stability measure of each part of the medial axis based
	on separation angles and examine the relation between the stability
	measures of adjacent parts. Our simplification algorithm uses iterative
	pruning of the parts based on efficient local tests. We have applied
	the algorithm to compute a simplified medial axis of complex models
	with tens of thousands of triangles and complex topologies.},
  doi = {http://doi.acm.org/10.1145/1060244.1060250},
  file = {:./Sud2005/sud_thma_spm05.pdf:PDF},
  isbn = {1-59593-015-9},
  location = {Cambridge, Massachusetts},
  owner = {apinzonf},
  timestamp = {2009.08.24}
}

@INPROCEEDINGS{Sumner2007,
  author = {Sumner, Robert W. and Schmid, Johannes and Pauly, Mark},
  title = {Embedded deformation for shape manipulation},
  booktitle = {SIGGRAPH '07: ACM SIGGRAPH 2007 papers},
  year = {2007},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Modelling 3D},
  abstract = {We present an algorithm that generates natural and intuitive deformations
	via direct manipulation for a wide range of shape representations
	and editing scenarios. Our method builds a space deformation represented
	by a collection of affine transformations organized in a graph structure.
	One transformation is associated with each graph node and applies
	a deformation to the nearby space. Positional constraints are specified
	on the points of an embedded object. As the user manipulates the
	constraints, a nonlinear minimization problem is solved to find optimal
	values for the affine transformations. Feature preservation is encoded
	directly in the objective function by measuring the deviation of
	each transformation from a true rotation. This algorithm addresses
	the problem of "embedded deformation" since it deforms space through
	direct manipulation of objects embedded within it, while preserving
	the embedded objects' features. We demonstrate our method by editing
	meshes, polygon soups, mesh animations, and animated particle systems.},
  citeulike-article-id = {2515442},
  doi = {http://dx.doi.org/10.1145/1275808.1276478},
  file = {:./Sumner2007/sumner_2007_EDS.pdf:PDF},
  issn = {0730-0301},
  keywords = {registration},
  owner = {apinzonf},
  posted-at = {2008-03-11 15:52:32},
  priority = {2},
  timestamp = {2009.03.17},
  url = {http://dx.doi.org/10.1145/1275808.1276478}
}

@INPROCEEDINGS{Sundareswara2005,
  author = {Rashmi Sundareswara and Schrater, P.R.},
  title = {Bayesian modelling of camera calibration and reconstruction},
  booktitle = {3-D Digital Imaging and Modeling, 2005. 3DIM 2005. Fifth International
	Conference on},
  year = {2005},
  pages = { 394-401},
  month = {June},
  note = {Camera Calibration},
  abstract = { Camera calibration methods, whether implicit or explicit, are a critical
	part of most 3D vision systems. These methods involve estimation
	of a model for the camera that produced the visual input, and subsequently
	to infer the 3D structure that gave rise to the input. However, in
	these systems the error in calibration is typically unknown, or if
	known, the effect of calibration error on subsequent processing (e.g.
	3D reconstruction) is not accounted for. In this paper, we propose
	a Bayesian camera calibration method that explicitly computes calibration
	error, and we show how knowledge of this error can be used to improve
	the accuracy of subsequent processing. What distinguishes the work
	is the explicit computation of a posterior distribution on unknown
	camera parameters, rather than just a best estimate. Marginalizing
	(averaging) subsequent estimates by this posterior is shown to reduce
	reconstruction error over calibration approaches that rely on a single
	best estimate. The method is made practical using sampling techniques,
	that require only the evaluation of the calibration error function
	and the specification of priors. Samples with their corresponding
	probability weights can be used to produce better estimates of the
	camera parameters. Moreover, these samples can be directly used to
	improve estimates that rely on calibration information, like 3D reconstruction.
	We evaluate our method using simulated data for a structure from
	motion problem, in which the same point matches are used to calibrate
	the camera, estimate the motion, and reconstruct the 3D geometry.
	Our results show improved reconstruction over non-linear Camera calibration
	methods like the Maximum Likelihood estimate. Additionally, this
	approach scales much better in the face of increasingly noisy point
	matches.},
  doi = {10.1109/3DIM.2005.24},
  file = {:./Sundareswara2005/Sundareswara2005.pdf:PDF},
  issn = {1550-6185 },
  keywords = { Bayes methods, belief networks, calibration, cameras, computational
	geometry, image reconstruction, maximum likelihood estimation, motion
	estimation, solid modelling Bayesian modelling, calibration error,
	camera calibration, image reconstruction, maximum likelihood estimation,
	motion estimation, noisy point matches},
  owner = {apinzonf},
  timestamp = {2009.10.20}
}

@ARTICLE{Surazhsky2005,
  author = {Surazhsky,, Vitaly and Surazhsky,, Tatiana and Kirsanov,, Danil and
	Gortler,, Steven J. and Hoppe,, Hugues},
  title = {Fast exact and approximate geodesics on meshes},
  journal = {ACM Trans. Graph.},
  year = {2005},
  volume = {24},
  pages = {553--560},
  number = {3},
  note = {Modelling 3D},
  abstract = {The computation of geodesic paths and distances on triangle meshes
	is a common operation in many computer graphics applications. We
	present several practical algorithms for computing such geodesics
	from a source point to one or all other points efficiently. First,
	we describe an implementation of the exact "single source, all destination"
	algorithm presented by Mitchell, Mount, and Papadimitriou (MMP).
	We show that the algorithm runs much faster in practice than suggested
	by worst case analysis. Next, we extend the algorithm with a merging
	operation to obtain computationally efficient and accurate approximations
	with bounded error. Finally, to compute the shortest path between
	two given points, we use a lower-bound property of our approximate
	geodesic algorithm to efficiently prune the frontier of the MMP algorithm.
	thereby obtaining an exact solution even more quickly.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1073204.1073228},
  file = {:./Surazhsky2005/geodesics.pdf:PDF},
  issn = {0730-0301},
  owner = {apinzonf},
  publisher = {ACM},
  timestamp = {2009.04.30}
}

@ARTICLE{Svensson2002,
  author = {S. Svensson and I. Nyström and G. Sanniti di Baja},
  title = {Curve skeletonization of surface-like objects in 3D images guided
	by voxel classification},
  journal = {Pattern Recognition Letters},
  year = {2002},
  volume = {23},
  pages = {1419 - 1426},
  number = {12},
  note = {Skeleton Extraction},
  abstract = {Skeletonization is a way to reduce dimensionality of digital objects.
	Here, we present an algorithm that computes the curve skeleton of
	a surface-like object in a 3D image, i.e., an object that in one
	of the three dimensions is at most two-voxel thick. A surface-like
	object consists of surfaces and curves crossing each other. Its curve
	skeleton is a 1D set centred within the surface-like object and with
	preserved topological properties. It can be useful to achieve a qualitative
	shape representation of the object with reduced dimensionality. The
	basic idea behind our algorithm is to detect the curves and the junctions
	between different surfaces and prevent their removal as they retain
	the most significant shape representation.},
  doi = {DOI: 10.1016/S0167-8655(02)00102-2},
  file = {:./Svensson2002/sdarticle.pdf:PDF},
  issn = {0167-8655},
  keywords = {Curve skeleton},
  owner = {apinzonf},
  timestamp = {2009.08.25},
  url = {http://www.sciencedirect.com/science/article/B6V15-45J91MV-8/2/dbac3094e925ba869a16d7801fc00b81}
}

@BOOK{Taddei2007,
  title = {Leonardo da Vinci's robots: New mechanics and new automata found
	in codices},
  publisher = {Leonardo3},
  year = {2007},
  editor = {Prodotti editoriali},
  author = {Mario Taddei},
  note = {Other},
  owner = {apinzonf},
  timestamp = {2009.10.01}
}

@ARTICLE{Tagliasacchi2009,
  author = {Tagliasacchi, Andrea and Zhang, Hao and Cohen-Or, Daniel},
  title = {Curve skeleton extraction from incomplete point cloud},
  journal = {ACM Trans. Graph.},
  year = {2009},
  volume = {28},
  pages = {1--9},
  number = {3},
  note = {Skeleton Extraction},
  abstract = {We present an algorithm for curve skeleton extraction from imperfect
	point clouds where large portions of the data may be missing. Our
	construction is primarily based on a novel notion of generalized
	rotational symmetry axis (ROSA) of an oriented point set. Specifically,
	given a subset S of oriented points, we introduce a variational definition
	for an oriented point that is most rotationally symmetric with respect
	to S. Our formulation effectively utilizes normal information to
	compensate for the missing data and leads to robust curve skeleton
	computation over regions of a shape that are generally cylindrical.
	We present an iterative algorithm via planar cuts to compute the
	ROSA of a point cloud. This is complemented by special handling of
	non-cylindrical joint regions to obtain a centered, topologically
	clean, and complete 1D skeleton. We demonstrate that quality curve
	skeletons can be extracted from a variety of shapes captured by incomplete
	point clouds. Finally, we show how our algorithm assists in shape
	completion under these challenges by developing a skeleton-driven
	point cloud completion scheme.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1531326.1531377},
  file = {:./Tagliasacchi2009/sig09_rosa.pdf:PDF},
  issn = {0730-0301},
  owner = {apinzonf},
  publisher = {ACM},
  timestamp = {2009.10.21}
}

@INPROCEEDINGS{Theobalt2004,
  author = {Theobalt, Christian and de Aguiar, Edilson and Magnor, Marcus and
	Theisel, Holger and Seidel, Hans-Peter},
  title = {Marker-free Kinematic Skeleton Estimation from Sequences of Volume
	Data},
  booktitle = {ACM Symposium on Virtual Reality Software and Technology (VRST 2004)},
  year = {2004},
  editor = {Lau, Rynson and Baciu, George},
  pages = {57--64},
  address = {Hong Kong, China},
  month = {November},
  organization = {Association of Computing Machinery (ACM)},
  publisher = {ACM},
  note = {Skeleton Extraction},
  abstract = {For realistic animation of an artificial character a body model that
	represents the character's kinematic structure is required. Hierarchical
	skeleton models are widely used which represent bodies as chains
	of bones with interconnecting joints. In video motion capture, animation
	parameters are derived from the performance of a subject in the real
	world. For this acquisition procedure too, a kinematic body model
	is required. Typically, the generation of such a model for tracking
	and animation is, at best, a semi-automatic process. We present a
	novel approach that estimates a hierarchical skeleton model of an
	arbitrary moving subject from sequences of voxel data that were reconstructed
	from multi-view video footage. Our method does not require a-priori
	information about the body structure. We demonstrate its performance
	using synthetic and real data.},
  file = {:./Theobalt2004/deAguiar_vrst2004.pdf:PDF},
  isbn = {1-58113-907-1},
  owner = {apinzonf},
  timestamp = {2009.03.18}
}

@TECHREPORT{Theobalt2005,
  author = {Theobalt, Christian and Ahmed, Naveed and de Aguiar, Edilson and
	Ziegler, Gernot and Lensch, Hendrik P. A. and Magnor, Marcus and
	Seidel, Hans-Peter},
  title = {Joint Motion and Reflectance Capture for Creating Relightable 3D
	Videos},
  institution = {Max-Planck-Institut fuer Informatik},
  year = {2005},
  type = {Research Report},
  number = {MPI-I-2005-4-004},
  address = {Saarbruecken, Germany},
  month = {April},
  note = {Motion Capture},
  abstract = {3D Videos of Human Actors can be faithfully reconstructed from multiple
	synchronized video streams by means of a model-based analysis-by-synthesis
	approach. The reconstructed videos play back in real-time and the
	virtual viewpoint onto the scene can be arbitrarily changed. By this
	means authentically animated, photo-realistically and view-dependently
	textured models of real people can be created that look real under
	fixed illumination conditions. To import real-world characters into
	virtual environments, however, also surface reflectance properties
	must be known. We have thus developed a video-based modeling approach
	that captures human motion as well as reflectance characteristics
	from a handful of synchronized video recordings. The presented method
	[1][2][3] is able to recover spatially varying reflectance properties
	of clothes by exploiting the time-varying orientation of each surface
	point with respect to camera and light direction. The resulting model
	description enables us to match animated subject appearance to different
	lighting conditions, as well as to interchange surface attributes
	among different people, e.g. for virtual dressing.},
  file = {:./Theobalt2005/deAguiar_tr2005.pdf:PDF},
  owner = {apinzonf},
  pages = {17},
  timestamp = {2009.03.18}
}

@INPROCEEDINGS{Thormahlen2008,
  author = {Thorm\"{a}hlen,, Thorsten and Seidel,, Hans-Peter},
  title = {3D-modeling by ortho-image generation from image sequences},
  booktitle = {SIGGRAPH '08: ACM SIGGRAPH 2008 papers},
  year = {2008},
  pages = {1--5},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Modeling 3D},
  abstract = {This paper introduces an approach to performance animation that employs
	video cameras and a small set of retro-reflective markers to create
	a low-cost, easy-to-use system that might someday be practical for
	home use. The low-dimensional control signals from the user's performance
	are supplemented by a database of pre-recorded human motion. At run
	time, the system automatically learns a series of local models from
	a set of motion capture examples that are a close match to the marker
	locations captured by the cameras. These local models are then used
	to reconstruct the motion of the user as a full-body animation. We
	demonstrate the power of this approach with real-time control of
	six different behaviors using two video cameras and a small set of
	retro-reflective markers. We compare the resulting animation to animation
	from commercial motion capture equipment with a full set of markers.},
  doi = {http://doi.acm.org/10.1145/1399504.1360685},
  file = {:./Thormahlen2008/Siggraph08_orthoimage.pdf:PDF},
  location = {Los Angeles, California},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Tierny2008,
  author = {Tierny, J. and Vandeborre, J.-P. and Daoudi, M.},
  title = {Fast and precise kinematic skeleton extraction of 3D dynamic meshes},
  booktitle = {Pattern Recognition},
  year = {2008},
  pages = {1-4},
  month = {Dec.},
  note = {Skeleton Extraction},
  abstract = {Shape skeleton extraction is a fundamental pre-processing task in
	shape-based pattern recognition. This paper presents a new algorithm
	for fast and precise extraction of kinematic skeletons of 3D dynamic
	surface meshes. Unlike previous approaches, surface motions are characterized
	by the mesh edge-length deviation induced by its transformation through
	time. Then a static skeleton extraction algorithm based on Reeb graphs
	exploits this latter information to extract the kinematic skeleton.
	This hybrid static and dynamic shape analysis enables the precise
	detection of objectspsila articulations as well as shape topological
	transitions corresponding to possibly-articulated immobile objectspsila
	features. Experiments show that the proposed algorithm is faster
	than previous techniques and still achieves better accuracy.},
  doi = {10.1109/ICPR.2008.4761011},
  file = {:./Tierny2008/IEEEXplortierny2008.pdf:PDF},
  issn = {1051-4651},
  journal = {Pattern Recognition, 2008. ICPR 2008. 19th International Conference
	on},
  keywords = {computational geometry, graph theory, mesh generation, pattern recognition3D
	dynamic meshes, 3D dynamic surface meshes, Reeb graphs, dynamic shape
	analysis, fast kinematic skeleton extraction, mesh edge-length deviation,
	possibly-articulated immobile objects features, precise kinematic
	skeleton extraction, preprocessing task, shape skeleton extraction,
	shape topological transitions, shape-based pattern recognition, static
	shape analysis, static skeleton extraction algorithm, surface motions},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@ARTICLE{Tierny2008a,
  author = {Tierny, Julien and Vandeborre, Jean-Philippe and Daoudi, Mohamed},
  title = {Enhancing 3D mesh topological skeletons with discrete contour constrictions},
  journal = {The Visual Computer},
  year = {2008},
  volume = {24},
  pages = {155--172},
  number = {3},
  month = mar,
  note = {Skeleton Extraction},
  abstract = {Abstract&nbsp;&nbsp;This paper describes a unified and fully automatic
	algorithm for Reeb graph construction and simplification as well
	as constriction approximation on triangulated surfaces.},
  file = {:./Tierny2008a/Tierny2008a.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.03},
  url = {http://dx.doi.org/10.1007/s00371-007-0181-0}
}

@ARTICLE{Turaga2009,
  author = {Turaga,, Pavan and Veeraraghavan,, Ashok and Chellappa,, Rama},
  title = {Unsupervised view and rate invariant clustering of video sequences},
  journal = {Comput. Vis. Image Underst.},
  year = {2009},
  volume = {113},
  pages = {353--371},
  number = {3},
  note = {Motion Capture},
  abstract = {Videos play an ever increasing role in our everyday lives with applications
	ranging from news, entertainment, scientific research, security and
	surveillance. Coupled with the fact that cameras and storage media
	are becoming less expensive, it has resulted in people producing
	more video content than ever before. This necessitates the development
	of efficient indexing and retrieval algorithms for video data. Most
	state-of-the-art techniques index videos according to the global
	content in the scene such as color, texture, brightness, etc. In
	this paper, we discuss the problem of activity-based indexing of
	videos. To address the problem, first we describe activities as a
	cascade of dynamical systems which significantly enhances the expressive
	power of the model while retaining many of the computational advantages
	of using dynamical models. Second, we also derive methods to incorporate
	view and rate-invariance into these models so that similar actions
	are clustered together irrespective of the viewpoint or the rate
	of execution of the activity. We also derive algorithms to learn
	the model parameters from a video stream and demonstrate how a single
	video sequence may be clustered into different clusters where each
	cluster represents an activity. Experimental results for five different
	databases show that the clusters found by the algorithm correspond
	to semantically meaningful activities.},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/j.cviu.2008.08.009},
  file = {:./Turaga2009/VidClusterCVIU.pdf:PDF},
  issn = {1077-3142},
  owner = {apinzonf},
  publisher = {Elsevier Science Inc.},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Tuytelaars2004,
  author = {Tuytelaars, T. and Van Gool, L.},
  title = {Synchronizing video sequences},
  booktitle = {Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings
	of the 2004 IEEE Computer Society Conference on},
  year = {2004},
  volume = {1},
  pages = { I-762-I-768 Vol.1},
  month = {June-2 July},
  note = {Synchronizing Video Cameras},
  abstract = { We present a novel method for automatically synchronizing two video
	sequences of the same event. Unlike previously proposed methods,
	we do not put any restrictive constraints on the scene nor on the
	camera motions: our method can deal with independently moving cameras,
	wide baseline conditions, and general 3D scenes. It starts from five
	point correspondences throughout the video sequences, that are provided
	using wide baseline matching and tracking techniques. It is efficient,
	in that it can be implemented in a non-combinatorial way. The feasibility
	of the method is demonstrated by preliminary experimental results.},
  doi = {10.1109/CVPR.2004.1315108},
  file = {:./Tuytelaars2004/Tuytelaars2004.pdf:PDF},
  issn = {1063-6919 },
  keywords = { image matching, image sequences, synchronisation, tracking, video
	signal processing 3D scenes, camera motions, moving cameras, restrictive
	constraints, tracking techniques, video sequence synchronization,
	wide baseline conditions, wide baseline matching},
  owner = {apinzonf},
  timestamp = {2009.10.20}
}

@ARTICLE{Unal2007,
  author = {Unal, G. and Yezzi, A. and Soatto, S. and Slabaugh, G.},
  title = {A Variational Approach to Problems in Calibration of Multiple Cameras},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {2007},
  volume = {29},
  pages = {1322-1338},
  number = {8},
  month = {Aug. },
  note = {Camera Calibration},
  abstract = {This paper addresses the problem of calibrating camera parameters
	using variational methods. One problem addressed is the severe lens
	distortion in low-cost cameras. For many computer vision algorithms
	aiming at reconstructing reliable representations of 3D scenes, the
	camera distortion effects will lead to inaccurate 3D reconstructions
	and geometrical measurements if not accounted for. A second problem
	is the color calibration problem caused by variations in camera responses
	that result in different color measurements and affects the algorithms
	that depend on these measurements. We also address the extrinsic
	camera calibration that estimates relative poses and orientations
	of multiple cameras in the system and the intrinsic camera calibration
	that estimates focal lengths and the skew parameters of the cameras.
	To address these calibration problems, we present multiview stereo
	techniques based on variational methods that utilize partial and
	ordinary differential equations. Our approach can also be considered
	as a coordinated refinement of camera calibration parameters. To
	reduce computational complexity of such algorithms, we utilize prior
	knowledge on the calibration object, making a piecewise smooth surface
	assumption, and evolve the pose, orientation, and scale parameters
	of such a 3D model object without requiring a 2D feature extraction
	from camera views. We derive the evolution equations for the distortion
	coefficients, the color calibration parameters, the extrinsic and
	intrinsic parameters of the cameras, and present experimental results.},
  doi = {10.1109/TPAMI.2007.1035},
  file = {:./Unal2007/Unal2007.pdf:PDF},
  issn = {0162-8828},
  keywords = {calibration, cameras, computational complexity, computer vision, feature
	extraction, image colour analysis, image reconstruction, image representation,
	partial differential equations, pose estimation, stereo image processing,
	variational techniques3D scene, color calibration, computational
	complexity, computer vision, feature extraction, image reconstruction,
	image representation, lens distortion, multiple camera calibration,
	multiview stereo technique, ordinary differential equation, partial
	differential equation, piecewise smooth surface assumption, pose
	estimation, variational method},
  owner = {apinzonf},
  timestamp = {2009.10.20}
}

@INPROCEEDINGS{Verroust1999,
  author = {Verroust, A. and Lazarus, F.},
  title = {Extracting skeletal curves from 3D scattered data},
  booktitle = {International Conference on Shape Modeling and Applications, 1999.},
  year = {1999},
  pages = {194-201},
  month = {Mar},
  note = {Skeleton Extraction},
  abstract = {We introduce a method for extracting skeletal curves from an unorganized
	collection of scattered data points lying on a surface. These curves
	may have a tree like structure to capture branching shapes such as
	blood vessels. The skeletal curves can be used for different applications
	ranging from surface reconstruction to object recognition},
  doi = {10.1109/SMA.1999.749340},
  file = {:./Verroust1999/Verroust1999.pdf:PDF},
  journal = {Shape Modeling and Applications, 1999. Proceedings. Shape Modeling
	International '99. International Conference on},
  keywords = {curve fitting, image reconstruction, surface fitting3D scattered data,
	object recognition, scattered data points, skeletal curves, surface
	reconstruction},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@ARTICLE{Vlasic2008,
  author = {Vlasic,, Daniel and Baran,, Ilya and Matusik,, Wojciech and Popovi\'{c},,
	Jovan},
  title = {Articulated mesh animation from multi-view silhouettes},
  journal = {ACM Trans. Graph.},
  year = {2008},
  volume = {27},
  pages = {1--9},
  number = {3},
  note = {3D Reconstruction},
  abstract = {Details in mesh animations are difficult to generate but they have
	great impact on visual quality. In this work, we demonstrate a practical
	software system for capturing such details from multi-view video
	recordings. Given a stream of synchronized video images that record
	a human performance from multiple viewpoints and an articulated template
	of the performer, our system captures the motion of both the skeleton
	and the shape. The output mesh animation is enhanced with the details
	observed in the image silhouettes. For example, a performance in
	casual loose-fitting clothes will generate mesh animations with flowing
	garment motions. We accomplish this with a fast pose tracking method
	followed by nonrigid deformation of the template to fit the silhouettes.
	The entire process takes less than sixteen seconds per frame and
	requires no markers or texture cues. Captured meshes are in full
	correspondence making them readily usable for editing operations
	including texturing, deformation transfer, and deformation model
	learning.},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1360612.1360696},
  file = {:./Vlasic2008/vlasic-2008-ama.pdf:PDF},
  issn = {0730-0301},
  owner = {apinzonf},
  publisher = {ACM},
  timestamp = {2009.03.17}
}

@ARTICLE{Wang2003,
  author = {Jessica Junlin Wang and Sameer Singh},
  title = {Video Analysis of Human Dynamics - a Survey},
  journal = {Real Time Imaging},
  year = {2003},
  volume = {9},
  pages = {321--346},
  note = {Motion Capture survey},
  abstract = {Video analysis of human dynamics is an important area of research
	devoted to detecting people and understanding their dynamic physical
	behavior in a complex environment that can be used for biometric
	applications. This paper provides a detailed survey of the various
	studies in areas related to the tracking of people and body parts
	such as face, hands, fingers, legs, etc., and modeling behavior using
	motion analysis.},
  file = {:./Wang2003/pann_SS_088.PDF:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@ARTICLE{Wang2008,
  author = {Wang,, Yu-Shuen and Lee,, Tong-Yee},
  title = {Curve-Skeleton Extraction Using Iterative Least Squares Optimization},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  year = {2008},
  volume = {14},
  pages = {926--936},
  number = {4},
  note = {Skeleton Extraction},
  abstract = {A curve skeleton is a compact representation of 3D objects and has
	numerous applications. It can be used to describe an object¡¦s geometry
	and topology. In this paper, we introduce a novel approach for computing
	curve skeletons for volumetric representations of the input models.
	Our algorithm consists of three major steps: 1) using iterative least
	squares optimization to shrink models and, at the same time, preserving
	their geometries and topologies; 2) extracting curve skeletons through
	the thinning algorithm; and 3) pruning unnecessary branches based
	on shrinking ratios. The proposed method is less sensitive to noise
	on the surface of models and can generate smoother skeletons. In
	addition, our shrinking algorithm requires little computation, since
	the optimization system can be factorized and stored in the pre-computational
	step. We demonstrate several extracted skeletons that help evaluate
	our algorithm. We also experimentally compare the proposed method
	with other well-known methods. Experimental results show advantages
	when using our method over other techniques.},
  address = {Piscataway, NJ, USA},
  doi = {http://dx.doi.org/10.1109/TVCG.2008.38},
  file = {:./Wang2008/wang2008.pdf:PDF},
  issn = {1077-2626},
  owner = {apinzonf},
  publisher = {IEEE Educational Activities Department},
  timestamp = {2009.04.03}
}

@ARTICLE{Wren1997,
  author = {Wren, C. R. and Azarbayejani, A. and Darrell, T. and Pentland, A.
	P.},
  title = {Pfinder: real-time tracking of the human body},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {1997},
  volume = {19},
  pages = {780--785},
  number = {7},
  note = {Motion Capture},
  abstract = {Pfinder is a real-time system for tracking people and interpreting
	their behavior. It runs at 10 Hz on a standard SGI Indy computer,
	and has performed reliably on thousands of people in many different
	physical locations. The system uses a multiclass statistical model
	of color and shape to obtain a 2D representation of head and hands
	in a wide range of viewing conditions. Pfinder has been successfully
	used in a wide range of applications including wireless interfaces,
	video databases, and low-bandwidth coding},
  citeulike-article-id = {802361},
  file = {:./Wren1997/Wren1997.pdf:PDF},
  keywords = {blob, detection, model, shape},
  owner = {apinzonf},
  posted-at = {2007-09-21 06:19:17},
  priority = {2},
  timestamp = {2009.04.30},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=598236}
}

@MISC{Wren2004,
  author = {Christopher R. Wren and Ph. D},
  title = {Perception for Human Motion Understanding},
  howpublished = {Innovations in Machine Intelligence \& Robot Perception},
  year = {2004},
  note = {Other},
  abstract = {The fact that people are embodied places powerful contraints on their
	motion. By leveraging these constraints, we can build systems to
	perceive human motion that are fast and robust. More importantly,
	by understanding how these constraint systems relate to one another,
	and to the perceptual process itself, we can make progress toward
	building systems that interpret, not just capture, human motion.},
  file = {:./Wren2004/TR2004-108.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@ARTICLE{Xu2004,
  author = {Xu,, Guoliang},
  title = {Discrete Laplace-Beltrami operators and their convergence},
  journal = {Comput. Aided Geom. Des.},
  year = {2004},
  volume = {21},
  pages = {767--784},
  number = {8},
  note = {Skeleton Extraction},
  abstract = {The convergence property of the discrete Laplace–Beltrami operators
	is the foundation of convergence analysis of the numerical simulation
	process of some geometric partial differential equations which involve
	the operator. In this paper we propose several simple discretization
	schemes of Laplace–Beltrami operators over triangulated surfaces.
	Convergence results for these discrete Laplace–Beltrami operators
	are established under various conditions. Numerical results that
	support the theoretical analysis are given. Application examples
	of the proposed discrete Laplace–Beltrami operators in surface processing
	and modelling are also presented},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.cagd.2004.07.007},
  file = {:./Xu2004/science.pdf:PDF},
  issn = {0167-8396},
  owner = {apinzonf},
  publisher = {Elsevier Science Publishers B. V.},
  timestamp = {2009.04.30}
}

@INPROCEEDINGS{Xu2004a,
  author = {Guoliang Xu},
  title = {Convergent discrete Laplace-Beltrami operators over triangular surfaces},
  booktitle = {Geometric Modeling and Processing},
  year = {2004},
  pages = { 195-204},
  note = {Skeleton Extraction},
  abstract = { The convergence property of the discrete Laplace-Beltrami operators
	is the foundation of convergence analysis of the numerical simulation
	process of some geometric partial differential equations which involve
	the operator. In this paper we propose several simple discretization
	schemes of Laplace-Beltrami operators over triangulated surfaces.
	Convergence results for these discrete Laplace-Beltrami operators
	are established under various conditions. Numerical results that
	support the theoretical analysis are given. Application examples
	of the proposed discrete Laplace-Beltrami operators in surface processing
	and modelling are also presented.},
  doi = {10.1109/GMAP.2004.1290041},
  file = {:./Xu2004a/Xu2004a.pdf:PDF},
  issn = { },
  journal = {Geometric Modeling and Processing, 2004. Proceedings},
  keywords = { computational geometry, convergence of numerical methods, mathematical
	operators, partial differential equations, solid modelling convergence
	analysis, convergent Laplace-Beltrami operators, discrete Laplace-Beltrami
	operators, discretization schemes, geometric partial differential
	equations, numerical simulation, surface modelling, surface processing,
	surface triangulation, triangular surfaces},
  owner = {apinzonf},
  timestamp = {2009.04.30}
}

@ARTICLE{Xu2009,
  author = {Kai Xu and Hao Zhang and Andrea Tagliasacchi and Ligang Liu and Guo
	Li and Min Meng and Yueshan Xiong},
  title = {Partial Intrinsic Reflectional Symmetry of 3D Shapes},
  journal = {ACM Transactions on Graphics, (Proceedings SIGGRAPH Asia 2009)},
  year = {2009},
  volume = {28},
  pages = {15},
  number = {5},
  note = {Mesh Analisis},
  abstract = {While many 3D objects exhibit various forms of global symmetries,
	prominent intrinsic symmetries which exist only on parts of an object
	are also well recognized. Such partial symmetries are often seen
	as more natural compared to a global one, especially on a composite
	shape. We introduce algorithms to extract partial intrinsic reflectional
	symmetries (PIRS) of a 3D shape. Given a closed 2-manifold mesh,
	we develop a voting scheme to obtain an intrinsic reflectional symmetry
	axis (IRSA) transform, which computes a scalar field over the mesh
	so as to accentuate prominent IRSAs of the shape. We then extract
	a set of explicit IRSA curves on the shape based on a refined measure
	of local reflectional symmetry support along a curve. The iterative
	refinement procedure combines IRSA-induced region growing and region-constrained
	symmetry support refinement to improve accuracy and address potential
	issues due to rotational symmetries in the shape. We show how the
	extracted IRSA curves can be incorporated into a conventional mesh
	segmentation scheme so that the implied symmetry cues can be utilized
	to obtain more meaningful results. We also demonstrate the use of
	IRSA curves for symmetry-driven part repair.},
  file = {:./Xu2009/siga09_pirs.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.10.21}
}

@INPROCEEDINGS{Xu2006,
  author = {Qiaoyu Xu and Dong Ye and Rensheng Che and Yan Huang},
  title = {Accurate Camera Calibration with New Minimizing Function},
  booktitle = {Robotics and Biomimetics, 2006. ROBIO '06. IEEE International Conference
	on},
  year = {2006},
  pages = {779-784},
  month = {Dec.},
  note = {Camera Calibration},
  abstract = {Camera calibration has been studied extensively in computer vision
	and photogrammetry. But almost all the camera calibration techniques
	iterate with the general minimizing function by minimizing the discrepancy
	between the real position in pixels of a 2D image point and the calculated
	projection of the 3D object point on the image plane. Though the
	imaging distance errors are equal, the spatial anti-projection distance
	errors are not identical at different distance before the camera.
	As far as vision measurement system, its final object is to obtain
	the accurate space coordinate of the measured point. Theoretically,
	the space point should on the optical ray generated by its projection
	image point and the center of camera. To satisfy the special request
	of vision measurement system for camera calibration parameters, we
	present a valid camera calibration method based on new minimizing
	function using high precision virtual stereo calibration pattern,
	which is formed by moving an infrared light-emitting diode (IR LED)
	feature point with CMM on pre-defined paths. Radial distortion and
	decentering distortion are molded. The proposed technique consists
	of linear optimization parameter estimation and nonlinear refinement,
	which is carried out by minimizing the distance of all the 3D space
	points from the corresponding optical ray generated by their projections
	image points and the center of camera. Simulated data and real data
	are both shown that the calibration precision of the proposed method
	is better than that of the general minimizing the distance between
	the imaged points and the modeled projections. This method considerable
	reduces the distance of all the 3D space points from the corresponding
	optical ray generated from their projections image points and the
	center of camera, enhances the precision of camera calibration parameters,
	and improves the precision of the vision measurement system.},
  doi = {10.1109/ROBIO.2006.340312},
  file = {:./Xu2006/Xu2006.pdf:PDF},
  keywords = {calibration, cameras, computer vision, stereo image processing3D space
	points, camera calibration parameters, computer vision, decentering
	distortion, image points, infrared light-emitting diode feature point,
	linear optimization parameter estimation, minimizing function, nonlinear
	refinement, optical ray, photogrammetry, radial distortion, virtual
	stereo calibration pattern, vision measurement system},
  owner = {apinzonf},
  timestamp = {2009.10.20}
}

@ARTICLE{Xue2009,
  author = {Xue,, Xinwei and Henderson,, Thomas C.},
  title = {Feature fusion for basic behavior unit segmentation from video sequences},
  journal = {Robot. Auton. Syst.},
  year = {2009},
  volume = {57},
  pages = {239--248},
  number = {3},
  note = {Other},
  abstract = {It has become increasingly popular to study animal behaviors with
	the assistance of video recordings. An automated video processing
	and behavior analysis system is desired to replace the traditional
	manual annotation. We propose a framework for automatic video based
	behavior analysis systems, which consists of four major modules:
	behavior modeling, feature extraction from video sequences, basic
	behavior unit (BBU) discovery and complex behavior recognition. BBU
	discovery is performed based on features extracted from video sequences,
	hence the fusion of multiple dimensional features is very important.
	In this paper, we explore the application of feature fusion techniques
	to BBU discovery with one and multiple cameras. We applied the vector
	fusion (SBP) method, a multi-variate vector visualization technique,
	in fusing the features obtained from a single camera. This technique
	reduces the multiple dimensional data into two dimensional (SBP)
	space, and the spatial and temporal analysis in SBP space can help
	discover the underlying data groups. Then we present a simple feature
	fusion technique for BBU discovery from multiple cameras with the
	affinity graph method. Finally, we present encouraging results on
	a physical system and a synthetic mouse-in-a-cage scenario from one,
	two, and three cameras. The feature fusion methods in this paper
	are simple yet effective.},
  address = {Amsterdam, The Netherlands, The Netherlands},
  doi = {http://dx.doi.org/10.1016/j.robot.2008.10.018},
  file = {:./Xue2009/ras08.pdf:PDF},
  issn = {0921-8890},
  owner = {apinzonf},
  publisher = {North-Holland Publishing Co.},
  timestamp = {2009.04.01}
}

@ARTICLE{Yamazaki2008,
  author = {Yamazaki, Shuntaro and Narasimhan, Srinivasa and Baker, Simon and
	Kanade, Takeo},
  title = {The Theory and Practice of Coplanar Shadowgram Imaging forÂ Acquiring
	Visual Hulls of Intricate Objects},
  journal = {International Journal of Computer Vision},
  year = {2008},
  volume = {1},
  pages = {--},
  note = {3D Reconstruction},
  abstract = {Abstract&nbsp;&nbsp;Acquiring 3D models of intricate objects (like
	tree branches, bicycles and insects) is a challenging task due to
	severe self-occlusions, repeated thin structures, and surface discontinuities.
	In theory, a shape-from-silhouettes (SFS) approach can overcome these
	difficulties and reconstruct visual hulls that are close to the actual
	shapes, regardless of the complexity of the object. In practice,
	however, SFS is highly sensitive to errors in silhouette contours
	and the calibration of the imaging system, and has therefore not
	been used for obtaining accurate shapes with a large number of views.
	In this work, we present a practical approach to SFS using a novel
	technique called coplanar shadowgram imaging that allows us to use
	dozens to even hundreds of views for visual hull reconstruction.
	A point light source is moved around an object and the shadows (silhouettes)
	cast onto a single background plane are imaged. We characterize this
	imaging system in terms of image projection, reconstruction ambiguity,
	epipolar geometry, and shape and source recovery. The coplanarity
	of the shadowgrams yields unique geometric properties that are not
	possible in traditional multi-view camera-based imaging systems.
	These properties allow us to derive a robust and automatic algorithm
	to recover the visual hull of an object and the 3D positions of the
	light source simultaneously, regardless of the complexity of the
	object. We demonstrate the acquisition of several intricate shapes
	with severe occlusions and thin structures, using 50 to 120 views.},
  file = {:./Yamazaki2008/Yamazaki2008.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.03},
  url = {http://dx.doi.org/10.1007/s11263-008-0170-4}
}

@ARTICLE{Yamazaki2009,
  author = {Yamazaki,, Shuntaro and Narasimhan,, Srinivasa G. and Baker,, Simon
	and Kanade,, Takeo},
  title = {The Theory and Practice of Coplanar Shadowgram Imaging for Acquiring
	Visual Hulls of Intricate Objects},
  journal = {Int. J. Comput. Vision},
  year = {2009},
  volume = {81},
  pages = {259--280},
  number = {3},
  note = {3D Reconstruction},
  abstract = {Acquiring 3D models of intricate objects (like tree branches, bicycles
	and insects) is a challenging task due to severe self-occlusions,
	repeated thin structures, and surface discontinuities. In theory,
	a shape-from-silhouettes (SFS) approach can overcome these difficulties
	and reconstruct visual hulls that are close to the actual shapes,
	regardless of the complexity of the object. In practice, however,
	SFS is highly sensitive to errors in silhouette contours and the
	calibration of the imaging system, and has therefore not been used
	for obtaining accurate shapes with a large number of views. In this
	work, we present a practical approach to SFS using a novel technique
	called coplanar shadowgram imaging that allows us to use dozens to
	even hundreds of views for visual hull reconstruction. A point light
	source is moved around an object and the shadows (silhouettes) cast
	onto a single background plane are imaged. We characterize this imaging
	system in terms of image projection, reconstruction ambiguity, epipolar
	geometry, and shape and source recovery. The coplanarity of the shadowgrams
	yields unique geometric properties that are not possible in traditional
	multi-view camera-based imaging systems. These properties allow us
	to derive a robust and automatic algorithm to recover the visual
	hull of an object and the 3D positions of the light source simultaneously,
	regardless of the complexity of the object. We demonstrate the acquisition
	of several intricate shapes with severe occlusions and thin structures,
	using 50 to 120 views.},
  address = {Hingham, MA, USA},
  doi = {http://dx.doi.org/10.1007/s11263-008-0170-4},
  file = {:./Yamazaki2009/the-ijcv-08.pdf:PDF},
  issn = {0920-5691},
  owner = {apinzonf},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Yan2008,
  author = {Pingkun Yan and Khan, S.M. and Shah, M.},
  title = {Learning 4D action feature models for arbitrary view action recognition},
  booktitle = {Computer Vision and Pattern Recognition},
  year = {2008},
  pages = {1-7},
  month = {June},
  note = {Motion Capture},
  abstract = {In this paper we present a novel approach using a 4D (x,y,z,t) action
	feature model (4D-AFM) for recognizing actions from arbitrary views.
	The 4D-AFM elegantly encodes shape and motion of actors observed
	from multiple views. The modeling process starts with reconstructing
	3D visual hulls of actors at each time instant. Spatiotemporal action
	features are then computed in each view by analyzing the differential
	geometric properties of spatio-temporal volumes (3D STVs) generated
	by concatenating the actorpsilas silhouette over the course of the
	action (x, y, t). These features are mapped to the sequence of 3D
	visual hulls over time (4D) to build the initial 4D-AFM. Actions
	are recognized based on the scores of matching action features from
	the input videos to the model points of 4D-AFMs by exploiting pairwise
	interactions of features. Promising recognition results have been
	demonstrated on the multi-view IXMAS dataset using both single and
	multi-view input videos.},
  doi = {10.1109/CVPR.2008.4587737},
  file = {:./Yan2008/yan2008.pdf:PDF},
  issn = {1063-6919},
  journal = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference
	on},
  keywords = {image coding, image matching, image recognition, image sequences,
	video signal processing3D visual hulls, 4D action feature models,
	4D-AFM, arbitrary view action recognition, multiview input videos,
	spatiotemporal action features, spatiotemporal volumes},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{You2005,
  author = {You,, Xinge and Fang,, Bin and Tang,, Yuan Yan},
  title = {Wavelet-Based Approach for Skeleton Extraction},
  booktitle = {WACV-MOTION '05: Proceedings of the Seventh IEEE Workshops on Application
	of Computer Vision (WACV/MOTION'05) - Volume 1},
  year = {2005},
  pages = {228--233},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  note = {Skeleton Extraction},
  abstract = {We propose a novel wavelet-based approach to extract skeleton of ribbon-like
	shapes based on a new concept called Wavelet-based Local Modulus
	Maxima Symmetry (WLMMS). The development of the new approach benefits
	from the desirable properties of the constructed new wavelet function.
	Based on the proposed WLMMS, initial skeleton of the regular region
	of ribbon-like shape are computed. Special attention is given to
	development of a new amendment technique which is called interpolation
	compensation. It is used to to remove artifacts of the initial skeletons
	and compute the skeletons in the singular region of the shape. Experimental
	results show that the proposed approach is not only capable of extracting
	precisely the skeleton of the ribbon-like shape with the low computational
	cost, but also robust against noise. And the proposed algorithm is
	applicable to both binary and gray scale image, as most traditional
	methods fail to do.},
  doi = {http://dx.doi.org/10.1109/ACVMOT.2005.125},
  file = {:./You2005/you2005.pdf:PDF},
  isbn = {0-7695-2271-8-1},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@ARTICLE{Yue2008,
  author = {Zhanfeng Yue and Chellappa, R.},
  title = {Synthesis of Silhouettes and Visual Hull Reconstruction for Articulated
	Humans},
  journal = {Multimedia, IEEE Transactions on},
  year = {2008},
  volume = {10},
  pages = {1565-1577},
  number = {8},
  month = {Dec. },
  note = {3D Reconstruction},
  abstract = {In this paper, we propose a complete framework for improved synthesis
	and understanding of the human pose from a limited number of silhouette
	images. It combines the active image-based visual hull (IBVH) algorithm
	and a contour-based body part segmentation technique. We derive a
	simple, approximate algorithm to decide the extrinsic parameters
	of a virtual camera, and synthesize the turntable image collection
	of the person using the IBVH algorithm by actively moving the virtual
	camera on a properly computed circular trajectory around the person.
	Using the turning function distance as the silhouette similarity
	measurement, this approach can be used to generate the desired pose-normalized
	images for recognition applications. In order to overcome the inability
	of the visual hull (VH) method to reconstruct concave regions, we
	propose a contour-based human body part localization algorithm to
	segment the silhouette images into convex body parts. The body parts
	observed from the virtual view are generated separately from the
	corresponding body parts observed from the input views and then assembled
	together for a more accurate VH reconstruction. Furthermore, the
	obtained turntable image collection helps to improve the body part
	segmentation and identification process. By using the inner distance
	shape context (IDSC) measurement, we are able to estimate the body
	part locations more accurately from a synthesized view where we can
	localize the body part more precisely. Experiments show that the
	proposed algorithm can greatly improve body part segmentation and
	hence shape reconstruction results.},
  doi = {10.1109/TMM.2008.2007321},
  file = {:./Yue2008/yue2008.pdf:PDF},
  issn = {1520-9210},
  keywords = {approximation theory, cameras, edge detection, image reconstruction,
	image segmentation, pose estimation, shape recognition, virtual realityactive
	image, approximate algorithm, articulated human pose, circular trajectory
	computation, contour-based body part segmentation technique, human
	body part localization algorithm, inner distance shape context measurement,
	silhouette image synthesis, silhouette similarity measurement, turning
	function distance, turntable image collection, virtual camera, visual
	hull reconstruction},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Yue2003,
  author = {Zhanfeng Yue and Liang Zhao and Chellappa, R.},
  title = {View synthesis of articulating humans using visual hull},
  booktitle = {Multimedia and Expo},
  year = {2003},
  volume = {1},
  pages = { I-489-92 vol.1},
  month = {July},
  note = {3D reconstruction},
  abstract = { In this paper, we present a method, which combines image-based visual
	hull and human body part segmentation for overcoming the inability
	of the visual hull method to reconstruct concave regions. The virtual
	silhouette image corresponding to the given viewing direction is
	first produced with image-based visual hull. Human body part localization
	technique is used to segment the input images and the rendered virtual
	silhouette image into convex body parts. The body parts in the virtual
	view are generated separately from the corresponding body parts in
	the input views and then assembled together. The previously rendered
	silhouette image is used to locate the corresponding body parts in
	input views and avoid the unconnected or squeezed regions in the
	assembled final view. Experiments show that this method can improve
	the reconstruction of concave regions for human postures and texture
	mapping.},
  doi = {10.1109/ICME.2003.1220961},
  file = {:./Yue2003/yue2003.pdf:PDF},
  issn = { },
  journal = {Multimedia and Expo, 2003. ICME '03. Proceedings. 2003 International
	Conference on},
  keywords = { gesture recognition, image motion analysis, image reconstruction,
	image segmentation, image texture convex body parts, human body part
	segmentation, human postures, image-based visual hull, texture mapping,
	view synthesis, virtual silhouette image},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@INPROCEEDINGS{Zhang2009,
  author = {Zhang,, Long and He,, Ying and Xie,, Xuexiang and Chen,, Wei},
  title = {Laplacian lines for real-time shape illustration},
  booktitle = {I3D '09: Proceedings of the 2009 symposium on Interactive 3D graphics
	and games},
  year = {2009},
  pages = {129--136},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {Other},
  abstract = {This paper presents a novel object-space line drawing algorithm that
	can depict shape with view dependent feature lines in real-time.
	Strongly inspired by the Laplacian-of-Gaussian (LoG) edge detector
	in image processing, we define Laplacian Lines as the zero-crossing
	points of the Laplacian of the surface illumination. Compared to
	other view dependent features, Laplacian lines are computationally
	efficient because most expensive computations can be pre-processed.
	Thus, Laplacian lines are very promising for interactively illustrating
	large-scale models.},
  doi = {http://doi.acm.org/10.1145/1507149.1507170},
  file = {:./Zhang2009/l3d_ll.pdf:PDF},
  isbn = {978-1-60558-429-4},
  location = {Boston, Massachusetts},
  owner = {apinzonf},
  timestamp = {2009.04.01}
}

@INPROCEEDINGS{Zhang2004,
  author = {Li Zhang and Noah Snavely and Brian Curless and Steven M. Seitz},
  title = {Spacetime Faces: High-Resolution Capture for Modeling and Animation},
  booktitle = {ACM Annual Conference on Computer Graphics},
  year = {2004},
  pages = {548-558},
  month = {August},
  note = {3D Reconstruction},
  abstract = {We present an end-to-end system that goes from video sequences to
	high resolution, editable, dynamically controllable face models.
	The capture system employs synchronized video cameras and structured
	light projectors to record videos of a moving face from multiple
	viewpoints. A novel spacetime stereo algorithm is introduced to compute
	depth maps accurately and overcome over-fitting deficiencies in prior
	work. A new template fitting and tracking procedure fills in missing
	data and yields point correspondence across the entire sequence without
	using markers. We demonstrate a data-driven, interactive method for
	inverse kinematics that draws on the large set of fitted templates
	and allows for posing new expressions by dragging surface points
	directly. Finally, we describe new tools that model the dynamics
	in the input sequence to enable new animations, created via key-framing
	or texture-synthesis techniques.},
  file = {:./Zhang2004/paper.pdf:PDF},
  location = {Los Angeles, CA},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@INPROCEEDINGS{Zhang2008,
  author = {L. Zhang and N. Subramaniam and R. Lin and S. K. Nayar and R. Raskar},
  title = {Capturing Images with Sparse Informational Pixels using Projected
	3D Tags},
  booktitle = {Proceedings of IEEE Virtual Reality},
  year = {2008},
  month = {Mar},
  note = {Characteristic points},
  abstract = {In this paper, we propose a novel imaging system that enables the
	capture of photos and videos with sparse informational pixels. Our
	system is based on the projection and detection of 3D optical tags.
	We use an infrared (IR) projector to project temporally-coded (blinking)
	dots onto selected points in a scene. These tags are invisible to
	the human eye, but appear as clearly visible time-varying codes to
	an IR photosensor. As a proof of concept, we have built a prototype
	camera system (consisting of co-located visible and IR sensors) to
	simultaneously capture visible and IR images. When a user takes an
	image of a tagged scene using such a camera system, all the scene
	tags that are visible from the system's viewpoint are detected. In
	addition, tags that lie in the field of view but are occluded, and
	ones that lie just outside the field of view, are also automatically
	generated for the image. Associated with each tagged pixel is its
	3D location and the identity of the object that the tag falls on.
	Our system can interface with conventional image recognition methods
	for efficient scene authoring, enabling objects in an image to be
	robustly identified using cheap cameras, minimal computations, and
	no domain knowledge. We demonstrate several applications of our system,
	including, photo-browsing, e-commerce, augmented reality, and objection
	localization.},
  file = {:./Zhang2008/Zhang_VR08.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.03.17}
}

@ARTICLE{Zhang1999,
  author = {Ruo Zhang and Ping-sing Tsai and James Edwin Cryer and Mubarak Shah},
  title = {Shape from Shading: A survey},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year = {1999},
  volume = {21},
  pages = {690--706},
  note = {3D Reconstruction survey},
  abstract = {AbstractÐSince the first shape-from-shading (SFS) technique was developed
	by Horn in the early 1970s, many different approaches have emerged.
	In this paper, six well-known SFS algorithms are implemented and
	compared. The performance of the algorithms was analyzed on synthetic
	images using mean and standard deviation of depth (Z) error, mean
	of surface gradient (p, q) error, and CPU timing. Each algorithm
	works well for certain images, but performs poorly for others. In
	general, minimization approaches are more robust, while the other
	approaches are faster. The implementation of these algorithms in
	C and images used in this paper are available by anonymous ftp under
	the pub/tech_paper/survey directory at eustis.cs.ucf.edu (132.170.108.42).
	These are also part of the electronic version of paper. Index TermsÐ
	Shape from shading, analysis of algorithms, Lambertian model, survey
	of shape from shading algorithms. 1},
  file = {:./Zhang1999/Zhang_Tsai_Cryer_Shah_PAMI1999.pdf:PDF},
  owner = {apinzonf},
  timestamp = {2009.04.03}
}

@INPROCEEDINGS{Zhou2008,
  author = {Jie Zhou and Hai Chen and Yue Chen},
  title = {Reconstruction of the Visual Hull with Modified Ray-tracing and Fast
	Slice-based Surface Extraction},
  booktitle = {Young Computer Scientists},
  year = {2008},
  pages = {907-912},
  month = {Nov.},
  note = {3D Reconstruction},
  abstract = {This paper presents a novel method for constructing a surface mesh
	from silhouettes estimated from image sequences. We implement a modified
	ray-tracing algorithm with an epipolar-line examination to obtain
	the surface vertices and investigate surface topology information
	by a slice-based surface extraction algorithm. In the ray tracing
	stage, a 2D-vector-based sandwich test is designed to predict the
	results of intersection, while culling only needs sequence calculations.
	Both theoretical analysis and experiment results show that our method
	is significantly faster than the original ray-tracing algorithm without
	losing accuracy.},
  doi = {10.1109/ICYCS.2008.422},
  file = {:./Zhou2008/zhou2008.pdf:PDF},
  journal = {Young Computer Scientists, 2008. ICYCS 2008. The 9th International
	Conference for},
  keywords = {computational geometry, feature extraction, image reconstruction,
	image sequences, mesh generation, ray tracing, surface fitting2D
	vector-based sandwich test, epipolar-line examination, image sequence,
	ray tracing, slice-based surface extraction, surface mesh construction,
	surface topology information, visual hull reconstruction},
  owner = {apinzonf},
  timestamp = {2009.04.02}
}

@ARTICLE{Zou2009,
  author = {Beiji Zou and Shu Chen and Cao Shi and Umugwaneza Marie Providence},
  title = {Automatic reconstruction of 3D human motion pose from uncalibrated
	monocular video sequences based on markerless human motion tracking},
  journal = {Pattern Recognition},
  year = {2009},
  volume = {In Press, Corrected Proof},
  pages = { - },
  note = {Motion Capture},
  abstract = {We present a method to reconstruct human motion pose from uncalibrated
	monocular video sequences based on the morphing appearance model
	matching. The human pose estimation is made by integrated human joint
	tracking with pose reconstruction in depth-first order. Firstly,
	the Euler angles of joint are estimated by inverse kinematics based
	on human skeleton constrain. Then, the coordinates of pixels in the
	body segments in the scene are determined by forward kinematics,
	by projecting these pixels in the scene onto the image plane under
	the assumption of perspective projection to obtain the region of
	morphing appearance model in the image. Finally, the human motion
	pose can be reconstructed by histogram matching. The experimental
	results show that this method can obtain favorable reconstruction
	results on a number of complex human motion sequences.},
  doi = {DOI: 10.1016/j.patcog.2008.12.024},
  file = {:./Zou2009/sdarticle.pdf:PDF},
  issn = {0031-3203},
  keywords = {3D human motion reconstruction},
  owner = {apinzonf},
  timestamp = {2009.03.18},
  url = {http://www.sciencedirect.com/science/article/B6V14-4VB01R5-2/2/efb5a08b5ccd91dc3ddc2f8c7b367a50}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

